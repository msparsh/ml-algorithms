{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58cc05bf",
   "metadata": {},
   "source": [
    "# Logistic Regression (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e60a231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a72321",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self):\n",
    "        \"\"\"To add globals if required to make model persistent.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def sigmoid_dot(self,X, W, b):\n",
    "        \"\"\"Returns sigmoid of W.X + b\"\"\"\n",
    "        return 1 / (1 + np.exp(-(np.dot(X,W) + b)))\n",
    "    \n",
    "    def update(self,X,y,y_,W,b,alpha):\n",
    "        \"\"\"Updates W,b for each x in X once\"\"\"\n",
    "        m,n = X.shape\n",
    "        \n",
    "        for i in range(m):\n",
    "            dJ_dW = np.zeros(n)\n",
    "            dJ_db = 0\n",
    "    \n",
    "            for j in range(n):\n",
    "                dJ_dW[j] += (y[i]-y_[i])*X[i][j]\n",
    "            dJ_db = np.sum(y[i] - y_[i])\n",
    "            \n",
    "            W += alpha*dJ_dW\n",
    "            b += alpha*dJ_db\n",
    "        return W,b \n",
    "    def cost(self,y,y_):\n",
    "        \"\"\"Returns Logistic Cost\"\"\"\n",
    "        m = y.shape[0]\n",
    "        c = 0\n",
    "        \n",
    "        for i in range(m):\n",
    "            c += y[i] * np.log(y_[i]) + (1-y[i])* np.log(1-y_[i])\n",
    "        return c/(-m)\n",
    "    def fit(self,X,y,iterations = 1000, alpha=0.000001):\n",
    "        \"\"\"Returns W,b after updating for the no. of iterations\"\"\"\n",
    "        m,n = X.shape\n",
    "        W = np.zeros(n)\n",
    "        b = 0\n",
    "\n",
    "        k = 0\n",
    "        while k <= iterations:\n",
    "            y_ = self.sigmoid_dot(X, W, b)\n",
    "            W,b = self.update(X,y,y_,W,b,alpha)\n",
    "            print(f\"Iteration: {k}\", f\"Cost{self.cost(y,y_)}\",f\"Acc: {accuracy_score(y, y_.round())}\")\n",
    "            k+=1\n",
    "        return W,b\n",
    "    def predict(self,X,W,b):\n",
    "        \"\"\"Returns rounded predictions. Might need to fix.\"\"\"\n",
    "        s = 1 / (1 + np.exp(-(np.dot(X,W) + b)))\n",
    "        return s.round()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2a4513",
   "metadata": {},
   "source": [
    "# Dataset Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b00a7",
   "metadata": {},
   "source": [
    "Multilabel Dataset. Using 2 targets at a time as Model is Binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4569395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ddfcd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Iteration: 0 Cost0.6931471805599458 Acc: 0.5\n",
      "Iteration: 1 Cost1.1269459090992318 Acc: 0.5\n",
      "Iteration: 2 Cost5.312408597810158 Acc: 0.5\n",
      "Iteration: 3 Cost4.160251836441491 Acc: 0.5\n",
      "Iteration: 4 Cost2.136199851741234 Acc: 0.5\n",
      "Iteration: 5 Cost6.031755474190515 Acc: 0.5\n",
      "Iteration: 6 Cost0.4003978523691909 Acc: 0.84\n",
      "Iteration: 7 Cost0.8270492484296191 Acc: 0.5\n",
      "Iteration: 8 Cost4.631420014835914 Acc: 0.5\n",
      "Iteration: 9 Cost0.8911037254871731 Acc: 0.5\n",
      "Iteration: 10 Cost4.697881598158821 Acc: 0.5\n",
      "Iteration: 11 Cost0.6288161967298236 Acc: 0.64\n",
      "Iteration: 12 Cost3.36376963547413 Acc: 0.5\n",
      "Iteration: 13 Cost1.907299931430857 Acc: 0.5\n",
      "Iteration: 14 Cost5.200626220853119 Acc: 0.5\n",
      "Iteration: 15 Cost0.23938780929454012 Acc: 0.94\n",
      "Iteration: 16 Cost0.28276405108727243 Acc: 0.84\n",
      "Iteration: 17 Cost0.6496746874335471 Acc: 0.67\n",
      "Iteration: 18 Cost2.867066714876029 Acc: 0.5\n",
      "Iteration: 19 Cost1.8721755947668874 Acc: 0.5\n",
      "Iteration: 20 Cost4.666098248738516 Acc: 0.5\n",
      "Iteration: 21 Cost0.2476529160948394 Acc: 0.94\n",
      "Iteration: 22 Cost0.4278131807105952 Acc: 0.78\n",
      "Iteration: 23 Cost1.125289297215762 Acc: 0.56\n",
      "Iteration: 24 Cost3.564976663496296 Acc: 0.5\n",
      "Iteration: 25 Cost0.6610069330155095 Acc: 0.67\n",
      "Iteration: 26 Cost1.9473067909789936 Acc: 0.5\n",
      "Iteration: 27 Cost1.699490868063948 Acc: 0.5\n",
      "Iteration: 28 Cost3.7498804897110514 Acc: 0.5\n",
      "Iteration: 29 Cost0.3772657085519303 Acc: 0.79\n",
      "Iteration: 30 Cost0.6932893391677988 Acc: 0.65\n",
      "Iteration: 31 Cost1.044123618727473 Acc: 0.64\n",
      "Iteration: 32 Cost2.3177849433265765 Acc: 0.5\n",
      "Iteration: 33 Cost0.9283877845352135 Acc: 0.67\n",
      "Iteration: 34 Cost1.832042854091562 Acc: 0.57\n",
      "Iteration: 35 Cost0.9702304815385656 Acc: 0.67\n",
      "Iteration: 36 Cost1.7308441060422808 Acc: 0.6\n",
      "Iteration: 37 Cost0.873864305786569 Acc: 0.67\n",
      "Iteration: 38 Cost1.3894378042429136 Acc: 0.6\n",
      "Iteration: 39 Cost0.8357031058213917 Acc: 0.67\n",
      "Iteration: 40 Cost1.203847841236679 Acc: 0.65\n",
      "Iteration: 41 Cost0.7574792945696557 Acc: 0.73\n",
      "Iteration: 42 Cost0.984964384003831 Acc: 0.65\n",
      "Iteration: 43 Cost0.6585178002653653 Acc: 0.73\n",
      "Iteration: 44 Cost0.7734239327659835 Acc: 0.78\n",
      "Iteration: 45 Cost0.5375334364514393 Acc: 0.79\n",
      "Iteration: 46 Cost0.5691108015984123 Acc: 0.78\n",
      "Iteration: 47 Cost0.40649083489039756 Acc: 0.84\n",
      "Iteration: 48 Cost0.3874007755855365 Acc: 0.84\n",
      "Iteration: 49 Cost0.28786856283599005 Acc: 0.84\n",
      "Iteration: 50 Cost0.2529540056450391 Acc: 0.84\n",
      "Iteration: 51 Cost0.20648870121338303 Acc: 0.94\n",
      "Iteration: 52 Cost0.18657668890729667 Acc: 0.92\n",
      "Iteration: 53 Cost0.17443038542736605 Acc: 0.94\n",
      "Iteration: 54 Cost0.16994979059079882 Acc: 0.94\n",
      "Iteration: 55 Cost0.16812221743599737 Acc: 0.94\n",
      "Iteration: 56 Cost0.1674877822070839 Acc: 0.94\n",
      "Iteration: 57 Cost0.16725581712822563 Acc: 0.94\n",
      "Iteration: 58 Cost0.1671748851275718 Acc: 0.94\n",
      "Iteration: 59 Cost0.16714596030743065 Acc: 0.94\n",
      "Iteration: 60 Cost0.16713571250836964 Acc: 0.94\n",
      "Iteration: 61 Cost0.16713198450102523 Acc: 0.94\n",
      "Iteration: 62 Cost0.16713056776680613 Acc: 0.94\n",
      "Iteration: 63 Cost0.16712996268581004 Acc: 0.94\n",
      "Iteration: 64 Cost0.16712964455770668 Acc: 0.94\n",
      "Iteration: 65 Cost0.1671294279412482 Acc: 0.94\n",
      "Iteration: 66 Cost0.1671292477256449 Acc: 0.94\n",
      "Iteration: 67 Cost0.16712908097139273 Acc: 0.94\n",
      "Iteration: 68 Cost0.16712891961425627 Acc: 0.94\n",
      "Iteration: 69 Cost0.16712876081391578 Acc: 0.94\n",
      "Iteration: 70 Cost0.16712860356828352 Acc: 0.94\n",
      "Iteration: 71 Cost0.16712844752101927 Acc: 0.94\n",
      "Iteration: 72 Cost0.16712829254273145 Acc: 0.94\n",
      "Iteration: 73 Cost0.16712813858375103 Acc: 0.94\n",
      "Iteration: 74 Cost0.16712798562242415 Acc: 0.94\n",
      "Iteration: 75 Cost0.1671278336469587 Acc: 0.94\n",
      "Iteration: 76 Cost0.16712768264904868 Acc: 0.94\n",
      "Iteration: 77 Cost0.16712753262164032 Acc: 0.94\n",
      "Iteration: 78 Cost0.16712738355814552 Acc: 0.94\n",
      "Iteration: 79 Cost0.16712723545216782 Acc: 0.94\n",
      "Iteration: 80 Cost0.16712708829740552 Acc: 0.94\n",
      "Iteration: 81 Cost0.16712694208761708 Acc: 0.94\n",
      "Iteration: 82 Cost0.16712679681660914 Acc: 0.94\n",
      "Iteration: 83 Cost0.1671266524782328 Acc: 0.94\n",
      "Iteration: 84 Cost0.16712650906638135 Acc: 0.94\n",
      "Iteration: 85 Cost0.16712636657498886 Acc: 0.94\n",
      "Iteration: 86 Cost0.16712622499803115 Acc: 0.94\n",
      "Iteration: 87 Cost0.16712608432952403 Acc: 0.94\n",
      "Iteration: 88 Cost0.16712594456352367 Acc: 0.94\n",
      "Iteration: 89 Cost0.16712580569412658 Acc: 0.94\n",
      "Iteration: 90 Cost0.1671256677154686 Acc: 0.94\n",
      "Iteration: 91 Cost0.1671255306217254 Acc: 0.94\n",
      "Iteration: 92 Cost0.16712539440711116 Acc: 0.94\n",
      "Iteration: 93 Cost0.1671252590658799 Acc: 0.94\n",
      "Iteration: 94 Cost0.16712512459232315 Acc: 0.94\n",
      "Iteration: 95 Cost0.16712499098077185 Acc: 0.94\n",
      "Iteration: 96 Cost0.16712485822559395 Acc: 0.94\n",
      "Iteration: 97 Cost0.1671247263211965 Acc: 0.94\n",
      "Iteration: 98 Cost0.1671245952620227 Acc: 0.94\n",
      "Iteration: 99 Cost0.16712446504255396 Acc: 0.94\n",
      "Iteration: 100 Cost0.16712433565730866 Acc: 0.94\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = load_iris()[\"data\"][50:150,3:4]\n",
    "y = load_iris()[\"target\"][50:150] - 1\n",
    "print(y)\n",
    "m = LogisticRegression()\n",
    "W,b = m.fit(X,y,100, 0.09)\n",
    "m.predict(X, W,b) == y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c357bef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Iteration: 0 Cost0.6931471805599458 Acc: 0.5\n",
      "Iteration: 1 Cost0.5432873995412423 Acc: 0.5\n",
      "Iteration: 2 Cost0.4450248741511941 Acc: 0.65\n",
      "Iteration: 3 Cost0.4949464613294696 Acc: 0.55\n",
      "Iteration: 4 Cost0.1193149001279605 Acc: 1.0\n",
      "Iteration: 5 Cost0.09823044288075038 Acc: 1.0\n",
      "Iteration: 6 Cost0.08885616799548934 Acc: 1.0\n",
      "Iteration: 7 Cost0.08179336310192577 Acc: 1.0\n",
      "Iteration: 8 Cost0.07588392708986069 Acc: 1.0\n",
      "Iteration: 9 Cost0.070860585840634 Acc: 1.0\n",
      "Iteration: 10 Cost0.06653351369193493 Acc: 1.0\n",
      "Iteration: 11 Cost0.06276394330631305 Acc: 1.0\n",
      "Iteration: 12 Cost0.05944801562444214 Acc: 1.0\n",
      "Iteration: 13 Cost0.05650640630731758 Acc: 1.0\n",
      "Iteration: 14 Cost0.053877451841523843 Acc: 1.0\n",
      "Iteration: 15 Cost0.05151246964212519 Acc: 1.0\n",
      "Iteration: 16 Cost0.04937249533663458 Acc: 1.0\n",
      "Iteration: 17 Cost0.047425959846503975 Acc: 1.0\n",
      "Iteration: 18 Cost0.04564700438780991 Acc: 1.0\n",
      "Iteration: 19 Cost0.04401423758282883 Acc: 1.0\n",
      "Iteration: 20 Cost0.042509804754730283 Acc: 1.0\n",
      "Iteration: 21 Cost0.04111868141067606 Acc: 1.0\n",
      "Iteration: 22 Cost0.0398281302049575 Acc: 1.0\n",
      "Iteration: 23 Cost0.03862727878826311 Acc: 1.0\n",
      "Iteration: 24 Cost0.03750678819589607 Acc: 1.0\n",
      "Iteration: 25 Cost0.03645858984660844 Acc: 1.0\n",
      "Iteration: 26 Cost0.03547567510034975 Acc: 1.0\n",
      "Iteration: 27 Cost0.03455192548356587 Acc: 1.0\n",
      "Iteration: 28 Cost0.033681974674576017 Acc: 1.0\n",
      "Iteration: 29 Cost0.03286109550770921 Acc: 1.0\n",
      "Iteration: 30 Cost0.03208510684513023 Acc: 1.0\n",
      "Iteration: 31 Cost0.03135029634505386 Acc: 1.0\n",
      "Iteration: 32 Cost0.03065335603886863 Acc: 1.0\n",
      "Iteration: 33 Cost0.029991328297915853 Acc: 1.0\n",
      "Iteration: 34 Cost0.029361560280240718 Acc: 1.0\n",
      "Iteration: 35 Cost0.028761665339373695 Acc: 1.0\n",
      "Iteration: 36 Cost0.028189490180663045 Acc: 1.0\n",
      "Iteration: 37 Cost0.027643086787445755 Acc: 1.0\n",
      "Iteration: 38 Cost0.02712068832534071 Acc: 1.0\n",
      "Iteration: 39 Cost0.02662068837999359 Acc: 1.0\n",
      "Iteration: 40 Cost0.026141623000575227 Acc: 1.0\n",
      "Iteration: 41 Cost0.025682155114916137 Acc: 1.0\n",
      "Iteration: 42 Cost0.02524106095744605 Acc: 1.0\n",
      "Iteration: 43 Cost0.02481721821199488 Acc: 1.0\n",
      "Iteration: 44 Cost0.02440959562098729 Acc: 1.0\n",
      "Iteration: 45 Cost0.02401724385298134 Acc: 1.0\n",
      "Iteration: 46 Cost0.023639287453640922 Acc: 1.0\n",
      "Iteration: 47 Cost0.02327491773255732 Acc: 1.0\n",
      "Iteration: 48 Cost0.022923386460921843 Acc: 1.0\n",
      "Iteration: 49 Cost0.02258400027382818 Acc: 1.0\n",
      "Iteration: 50 Cost0.022256115686635325 Acc: 1.0\n",
      "Iteration: 51 Cost0.02193913464791789 Acc: 1.0\n",
      "Iteration: 52 Cost0.02163250056253739 Acc: 1.0\n",
      "Iteration: 53 Cost0.021335694727636363 Acc: 1.0\n",
      "Iteration: 54 Cost0.021048233132194286 Acc: 1.0\n",
      "Iteration: 55 Cost0.02076966357743734 Acc: 1.0\n",
      "Iteration: 56 Cost0.020499563081044708 Acc: 1.0\n",
      "Iteration: 57 Cost0.020237535532921277 Acc: 1.0\n",
      "Iteration: 58 Cost0.019983209574433988 Acc: 1.0\n",
      "Iteration: 59 Cost0.019736236676550965 Acc: 1.0\n",
      "Iteration: 60 Cost0.019496289395369203 Acc: 1.0\n",
      "Iteration: 61 Cost0.019263059786140912 Acc: 1.0\n",
      "Iteration: 62 Cost0.01903625795918228 Acc: 1.0\n",
      "Iteration: 63 Cost0.018815610763014034 Acc: 1.0\n",
      "Iteration: 64 Cost0.01860086058179114 Acc: 1.0\n",
      "Iteration: 65 Cost0.01839176423556954 Acc: 1.0\n",
      "Iteration: 66 Cost0.018188091973251476 Acc: 1.0\n",
      "Iteration: 67 Cost0.01798962654918483 Acc: 1.0\n",
      "Iteration: 68 Cost0.017796162375390043 Acc: 1.0\n",
      "Iteration: 69 Cost0.017607504742252048 Acc: 1.0\n",
      "Iteration: 70 Cost0.017423469101288398 Acc: 1.0\n",
      "Iteration: 71 Cost0.017243880404274485 Acc: 1.0\n",
      "Iteration: 72 Cost0.017068572493606063 Acc: 1.0\n",
      "Iteration: 73 Cost0.016897387539303046 Acc: 1.0\n",
      "Iteration: 74 Cost0.016730175518527405 Acc: 1.0\n",
      "Iteration: 75 Cost0.016566793733899247 Acc: 1.0\n",
      "Iteration: 76 Cost0.016407106367265317 Acc: 1.0\n",
      "Iteration: 77 Cost0.016250984065899095 Acc: 1.0\n",
      "Iteration: 78 Cost0.016098303558402707 Acc: 1.0\n",
      "Iteration: 79 Cost0.01594894729784419 Acc: 1.0\n",
      "Iteration: 80 Cost0.01580280312989187 Acc: 1.0\n",
      "Iteration: 81 Cost0.015659763983918634 Acc: 1.0\n",
      "Iteration: 82 Cost0.015519727585234608 Acc: 1.0\n",
      "Iteration: 83 Cost0.015382596186772648 Acc: 1.0\n",
      "Iteration: 84 Cost0.015248276318704672 Acc: 1.0\n",
      "Iteration: 85 Cost0.015116678554598455 Acc: 1.0\n",
      "Iteration: 86 Cost0.014987717292850254 Acc: 1.0\n",
      "Iteration: 87 Cost0.01486131055223422 Acc: 1.0\n",
      "Iteration: 88 Cost0.014737379780513562 Acc: 1.0\n",
      "Iteration: 89 Cost0.014615849675143924 Acc: 1.0\n",
      "Iteration: 90 Cost0.014496648015185819 Acc: 1.0\n",
      "Iteration: 91 Cost0.014379705503609681 Acc: 1.0\n",
      "Iteration: 92 Cost0.014264955619251327 Acc: 1.0\n",
      "Iteration: 93 Cost0.014152334477730606 Acc: 1.0\n",
      "Iteration: 94 Cost0.014041780700705504 Acc: 1.0\n",
      "Iteration: 95 Cost0.013933235292880144 Acc: 1.0\n",
      "Iteration: 96 Cost0.013826641526234286 Acc: 1.0\n",
      "Iteration: 97 Cost0.013721944830981783 Acc: 1.0\n",
      "Iteration: 98 Cost0.013619092692803541 Acc: 1.0\n",
      "Iteration: 99 Cost0.013518034555937659 Acc: 1.0\n",
      "Iteration: 100 Cost0.013418721731735942 Acc: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = load_iris()[\"data\"][0:100,3:4]\n",
    "y = load_iris()[\"target\"][0:100]\n",
    "\n",
    "print(y)\n",
    "m = LogisticRegression()\n",
    "W,b = m.fit(X,y,100, 0.09)\n",
    "m.predict(X, W,b) == y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb732a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
