{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55fa8fd",
   "metadata": {},
   "source": [
    "# Learning Implementation for Stochastic Linear Regression\n",
    "with regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22de211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ea21577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b171ba73",
   "metadata": {},
   "source": [
    "# Observations:\n",
    "* Reacts better to large bias than BatchGD\n",
    "* Faster maybe\n",
    "* If features have noncompareable sizes then bigger feature gets more weight\n",
    "* Runs 1 step after last print  \n",
    "\n",
    "\n",
    "# Query:\n",
    "* Should bias update be multiplied by lr\n",
    "* What diff does dividing by m makes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195ef49",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbf4b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2squared(W):\n",
    "    return np.sum(W**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dda341eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def added_cost(Lambda,W,m):\n",
    "    return Lambda*l2squared(W)/(2*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8150986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for alpha and its multiplication with the reg term\n",
    "def single_update(i,X,y,y_,W,b,alpha,Lambda):\n",
    "    m,n = X.shape\n",
    "    dJ_dW = np.zeros(n)\n",
    "    for j in range(n):\n",
    "        dJ_dW[j] += (y[i]-y_[i])*X[i][j]  - Lambda*W[j]\n",
    "    dJ_db = y[i]-y_[i]\n",
    "    \n",
    "    W += dJ_dW*alpha/m\n",
    "    b += dJ_db*alpha/m\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1820eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_LinearRegression(X,y, iterations = 100,alpha = 0.000001,Lambda=0.0001, output_limit=10):\n",
    "    \"\"\"Returns W,b after updating iterations times.\n",
    "\n",
    "    iterations: int, default=100\n",
    "        Number of complete iterations through X\n",
    "        \n",
    "    alpha: float, default=0.000001\n",
    "        Constant Learning Rate\n",
    "    \n",
    "    Lambda: float, default=0.0001\n",
    "        Rate for l2 Regularization\n",
    "        \n",
    "    output_limit: int, default=10\n",
    "        Number of iterations to show\n",
    "    \n",
    "    \"\"\"\n",
    "    if output_limit<=0:\n",
    "        print(\"Choose natural output limit!\")\n",
    "        return None, None\n",
    "    m,n = X.shape\n",
    "    W = np.zeros(n)\n",
    "    b = np.float128(0)\n",
    "    y_ = np.matmul(X,W) +b\n",
    "    \n",
    "    try:\n",
    "        for k in range(iterations+1):\n",
    "            if k % (iterations//output_limit) == 0:\n",
    "                print(f\"({k//(iterations//output_limit)}/{output_limit}) > Iteration: {k}\",\n",
    "                      f\"Cost: {mean_squared_error(y,y_) + added_cost(Lambda,W,m) }\",\n",
    "                      f\"   Weights: {W}\",\n",
    "                      f\"Bias: {b:.4f}\"\n",
    "                     )\n",
    "            #print(f\"Iteration: {k}\", f\"Cost: {mean_squared_error(y,y_)}\", f\"Weights: {W}\",f\"Bias: {b}\")\n",
    "            for i in range(m):\n",
    "                W,b = single_update(i,X,y,y_,W,b,alpha,Lambda)\n",
    "                y_ = np.matmul(X,W) + b\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"\\nTerminated! Returned: Weights: {W}, Bias: {b}\")\n",
    "        return W,b\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eba465",
   "metadata": {},
   "source": [
    "## Running Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a62bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[x, x**2] for x in (np.random.random(500))*10])\n",
    "y = np.array([5.5*x + 2004.88*x2  + np.random.randint(0,5) for (x,x2) in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "963ae765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0/20) > Iteration: 0 Cost: 7467993065.090451    Weights: [0. 0.] Bias: 0.0000\n",
      "(1/20) > Iteration: 50 Cost: 219.55285744323575    Weights: [  23.0028 2003.2854] Bias: -38.4740\n",
      "(2/20) > Iteration: 100 Cost: 78.76187122152155    Weights: [  15.915  2003.9394] Bias: -22.0461\n",
      "(3/20) > Iteration: 150 Cost: 29.22126565479466    Weights: [  11.6814 2004.33  ] Bias: -12.2300\n",
      "(4/20) > Iteration: 200 Cost: 11.962393345499098    Weights: [   9.1519 2004.5633] Bias: -6.3649\n",
      "(5/20) > Iteration: 250 Cost: 6.056103504055336    Weights: [   7.6405 2004.7027] Bias: -2.8607\n",
      "(6/20) > Iteration: 300 Cost: 4.099967523397469    Weights: [   6.7375 2004.7861] Bias: -0.7669\n",
      "(7/20) > Iteration: 350 Cost: 3.4926805838300172    Weights: [   6.1979 2004.8358] Bias: 0.4841\n",
      "(8/20) > Iteration: 400 Cost: 3.330279348200866    Weights: [   5.8756 2004.8656] Bias: 1.2316\n",
      "(9/20) > Iteration: 450 Cost: 3.3048044575858078    Weights: [   5.6829 2004.8833] Bias: 1.6782\n",
      "(10/20) > Iteration: 500 Cost: 3.315129309639066    Weights: [   5.5679 2004.894 ] Bias: 1.9450\n",
      "(11/20) > Iteration: 550 Cost: 3.3304180121311453    Weights: [   5.4991 2004.9003] Bias: 2.1045\n",
      "(12/20) > Iteration: 600 Cost: 3.3428085359267    Weights: [   5.458  2004.9041] Bias: 2.1997\n",
      "(13/20) > Iteration: 650 Cost: 3.351374004992435    Weights: [   5.4335 2004.9064] Bias: 2.2566\n",
      "(14/20) > Iteration: 700 Cost: 3.356906703916666    Weights: [   5.4188 2004.9077] Bias: 2.2906\n",
      "(15/20) > Iteration: 750 Cost: 3.360360558321217    Weights: [   5.41   2004.9085] Bias: 2.3110\n",
      "(16/20) > Iteration: 800 Cost: 3.3624770800960566    Weights: [   5.4048 2004.909 ] Bias: 2.3231\n",
      "(17/20) > Iteration: 850 Cost: 3.3637605576142366    Weights: [   5.4017 2004.9093] Bias: 2.3304\n",
      "(18/20) > Iteration: 900 Cost: 3.364534161438798    Weights: [   5.3998 2004.9095] Bias: 2.3347\n",
      "(19/20) > Iteration: 950 Cost: 3.3649987875961513    Weights: [   5.3987 2004.9096] Bias: 2.3373\n",
      "(20/20) > Iteration: 1000 Cost: 3.365277255872766    Weights: [   5.398  2004.9096] Bias: 2.3388\n"
     ]
    }
   ],
   "source": [
    "with np.printoptions(precision=4):\n",
    "    W,b = SGD_LinearRegression(X,y, 1000,0.1,output_limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08ea7fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1987.56, NNZs: 2, Bias: 26.871619, T: 500, Avg. loss: 23808331.908949\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1985.52, NNZs: 2, Bias: 17.364635, T: 1000, Avg. loss: 59705.282037\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1985.99, NNZs: 2, Bias: 8.737986, T: 1500, Avg. loss: 50181.794766\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1991.39, NNZs: 2, Bias: 1.177860, T: 2000, Avg. loss: 40471.488317\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1993.50, NNZs: 2, Bias: -5.674495, T: 2500, Avg. loss: 32078.222206\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1989.40, NNZs: 2, Bias: -11.730139, T: 3000, Avg. loss: 24611.183832\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1994.76, NNZs: 2, Bias: -16.928706, T: 3500, Avg. loss: 19807.526063\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1993.19, NNZs: 2, Bias: -21.541027, T: 4000, Avg. loss: 15105.164373\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1993.13, NNZs: 2, Bias: -25.573859, T: 4500, Avg. loss: 12108.753623\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1995.70, NNZs: 2, Bias: -29.160280, T: 5000, Avg. loss: 9991.935819\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1996.70, NNZs: 2, Bias: -32.324116, T: 5500, Avg. loss: 7917.634884\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1996.04, NNZs: 2, Bias: -35.141234, T: 6000, Avg. loss: 6313.777114\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1996.20, NNZs: 2, Bias: -37.521706, T: 6500, Avg. loss: 4862.007423\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1998.00, NNZs: 2, Bias: -39.632998, T: 7000, Avg. loss: 4073.456715\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1998.01, NNZs: 2, Bias: -41.469191, T: 7500, Avg. loss: 3152.643598\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1998.25, NNZs: 2, Bias: -43.078052, T: 8000, Avg. loss: 2605.044016\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1999.33, NNZs: 2, Bias: -44.469493, T: 8500, Avg. loss: 2163.645306\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1999.97, NNZs: 2, Bias: -45.652116, T: 9000, Avg. loss: 1717.801381\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1999.80, NNZs: 2, Bias: -46.650718, T: 9500, Avg. loss: 1295.476830\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 2000.65, NNZs: 2, Bias: -47.551040, T: 10000, Avg. loss: 1213.357102\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 2000.89, NNZs: 2, Bias: -48.279220, T: 10500, Avg. loss: 933.849357\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 2000.99, NNZs: 2, Bias: -48.917778, T: 11000, Avg. loss: 826.240383\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 2000.75, NNZs: 2, Bias: -49.452241, T: 11500, Avg. loss: 680.602720\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 2001.53, NNZs: 2, Bias: -49.858705, T: 12000, Avg. loss: 575.658668\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2001.38, NNZs: 2, Bias: -50.201002, T: 12500, Avg. loss: 507.828284\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 2001.73, NNZs: 2, Bias: -50.494902, T: 13000, Avg. loss: 466.327578\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2001.97, NNZs: 2, Bias: -50.700152, T: 13500, Avg. loss: 398.142173\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 2001.90, NNZs: 2, Bias: -50.849998, T: 14000, Avg. loss: 352.706608\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 2002.59, NNZs: 2, Bias: -50.955018, T: 14500, Avg. loss: 334.354653\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2002.24, NNZs: 2, Bias: -51.013766, T: 15000, Avg. loss: 298.197420\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2002.64, NNZs: 2, Bias: -51.014168, T: 15500, Avg. loss: 274.953930\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2002.58, NNZs: 2, Bias: -51.004181, T: 16000, Avg. loss: 263.601664\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2002.38, NNZs: 2, Bias: -50.957038, T: 16500, Avg. loss: 241.574872\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2002.48, NNZs: 2, Bias: -50.886204, T: 17000, Avg. loss: 237.357051\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2002.50, NNZs: 2, Bias: -50.803254, T: 17500, Avg. loss: 231.871700\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2002.84, NNZs: 2, Bias: -50.691890, T: 18000, Avg. loss: 222.334712\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2002.93, NNZs: 2, Bias: -50.560237, T: 18500, Avg. loss: 216.309961\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2002.82, NNZs: 2, Bias: -50.420462, T: 19000, Avg. loss: 212.169923\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2002.80, NNZs: 2, Bias: -50.272847, T: 19500, Avg. loss: 208.717558\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2002.97, NNZs: 2, Bias: -50.098492, T: 20000, Avg. loss: 198.360436\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2002.98, NNZs: 2, Bias: -49.919551, T: 20500, Avg. loss: 196.996749\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2002.84, NNZs: 2, Bias: -49.724116, T: 21000, Avg. loss: 186.445894\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2003.06, NNZs: 2, Bias: -49.529252, T: 21500, Avg. loss: 190.126957\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2002.97, NNZs: 2, Bias: -49.325133, T: 22000, Avg. loss: 185.329707\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2003.11, NNZs: 2, Bias: -49.124739, T: 22500, Avg. loss: 188.303716\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2002.95, NNZs: 2, Bias: -48.913179, T: 23000, Avg. loss: 182.550152\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2002.96, NNZs: 2, Bias: -48.690855, T: 23500, Avg. loss: 177.470394\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2003.15, NNZs: 2, Bias: -48.458387, T: 24000, Avg. loss: 174.190544\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2002.96, NNZs: 2, Bias: -48.234905, T: 24500, Avg. loss: 171.238382\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2003.28, NNZs: 2, Bias: -47.996765, T: 25000, Avg. loss: 171.139905\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2003.16, NNZs: 2, Bias: -47.768432, T: 25500, Avg. loss: 168.820294\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2003.31, NNZs: 2, Bias: -47.528188, T: 26000, Avg. loss: 165.856842\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2003.20, NNZs: 2, Bias: -47.289038, T: 26500, Avg. loss: 163.691764\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2003.08, NNZs: 2, Bias: -47.053076, T: 27000, Avg. loss: 163.270430\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2003.22, NNZs: 2, Bias: -46.816594, T: 27500, Avg. loss: 163.806687\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2003.26, NNZs: 2, Bias: -46.575418, T: 28000, Avg. loss: 159.555445\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2003.28, NNZs: 2, Bias: -46.335620, T: 28500, Avg. loss: 157.513620\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2003.41, NNZs: 2, Bias: -46.089404, T: 29000, Avg. loss: 155.846870\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2003.42, NNZs: 2, Bias: -45.849522, T: 29500, Avg. loss: 155.623946\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2003.31, NNZs: 2, Bias: -45.615489, T: 30000, Avg. loss: 155.058245\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2003.44, NNZs: 2, Bias: -45.372902, T: 30500, Avg. loss: 151.637923\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2003.38, NNZs: 2, Bias: -45.135476, T: 31000, Avg. loss: 150.845923\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2003.33, NNZs: 2, Bias: -44.895798, T: 31500, Avg. loss: 147.632002\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2003.44, NNZs: 2, Bias: -44.650858, T: 32000, Avg. loss: 145.733298\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2003.29, NNZs: 2, Bias: -44.409396, T: 32500, Avg. loss: 144.600690\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2003.25, NNZs: 2, Bias: -44.170521, T: 33000, Avg. loss: 143.098007\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2003.40, NNZs: 2, Bias: -43.922719, T: 33500, Avg. loss: 140.299717\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2003.36, NNZs: 2, Bias: -43.682252, T: 34000, Avg. loss: 137.560440\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2003.35, NNZs: 2, Bias: -43.447644, T: 34500, Avg. loss: 138.869805\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2003.34, NNZs: 2, Bias: -43.216745, T: 35000, Avg. loss: 137.576505\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2003.42, NNZs: 2, Bias: -42.983282, T: 35500, Avg. loss: 135.718924\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2003.24, NNZs: 2, Bias: -42.755453, T: 36000, Avg. loss: 134.416205\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2003.39, NNZs: 2, Bias: -42.520480, T: 36500, Avg. loss: 133.957127\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2003.32, NNZs: 2, Bias: -42.294976, T: 37000, Avg. loss: 131.901497\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2003.51, NNZs: 2, Bias: -42.065428, T: 37500, Avg. loss: 132.415621\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2003.38, NNZs: 2, Bias: -41.834911, T: 38000, Avg. loss: 128.603317\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 2003.43, NNZs: 2, Bias: -41.605114, T: 38500, Avg. loss: 127.706301\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 2003.34, NNZs: 2, Bias: -41.378795, T: 39000, Avg. loss: 127.445938\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 2003.34, NNZs: 2, Bias: -41.154687, T: 39500, Avg. loss: 126.116703\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 2003.37, NNZs: 2, Bias: -40.923251, T: 40000, Avg. loss: 123.293037\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 2003.46, NNZs: 2, Bias: -40.702689, T: 40500, Avg. loss: 123.017189\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 2003.44, NNZs: 2, Bias: -40.483444, T: 41000, Avg. loss: 122.660687\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 2003.44, NNZs: 2, Bias: -40.261174, T: 41500, Avg. loss: 120.348381\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 2003.46, NNZs: 2, Bias: -40.030388, T: 42000, Avg. loss: 117.054573\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 2003.48, NNZs: 2, Bias: -39.806760, T: 42500, Avg. loss: 116.837899\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 2003.47, NNZs: 2, Bias: -39.582732, T: 43000, Avg. loss: 114.123452\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 2003.48, NNZs: 2, Bias: -39.361381, T: 43500, Avg. loss: 114.091402\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 2003.45, NNZs: 2, Bias: -39.146482, T: 44000, Avg. loss: 114.337567\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 2003.49, NNZs: 2, Bias: -38.933578, T: 44500, Avg. loss: 113.787219\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 2003.52, NNZs: 2, Bias: -38.724260, T: 45000, Avg. loss: 111.771934\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 2003.45, NNZs: 2, Bias: -38.513393, T: 45500, Avg. loss: 110.265199\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 2003.68, NNZs: 2, Bias: -38.290918, T: 46000, Avg. loss: 108.035055\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 2003.50, NNZs: 2, Bias: -38.082218, T: 46500, Avg. loss: 107.909846\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 2003.51, NNZs: 2, Bias: -37.871089, T: 47000, Avg. loss: 106.315603\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 2003.56, NNZs: 2, Bias: -37.659023, T: 47500, Avg. loss: 105.429799\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 2003.63, NNZs: 2, Bias: -37.458112, T: 48000, Avg. loss: 105.888566\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 2003.51, NNZs: 2, Bias: -37.252627, T: 48500, Avg. loss: 102.522327\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 2003.59, NNZs: 2, Bias: -37.047058, T: 49000, Avg. loss: 103.018015\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 2003.63, NNZs: 2, Bias: -36.843973, T: 49500, Avg. loss: 102.246014\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 2003.66, NNZs: 2, Bias: -36.638758, T: 50000, Avg. loss: 100.979039\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 2003.56, NNZs: 2, Bias: -36.439753, T: 50500, Avg. loss: 100.964739\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 2003.58, NNZs: 2, Bias: -36.240236, T: 51000, Avg. loss: 99.625456\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 2003.57, NNZs: 2, Bias: -36.041854, T: 51500, Avg. loss: 98.688933\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 2003.67, NNZs: 2, Bias: -35.837262, T: 52000, Avg. loss: 95.662770\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 2003.53, NNZs: 2, Bias: -35.640468, T: 52500, Avg. loss: 95.404140\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 2003.62, NNZs: 2, Bias: -35.442133, T: 53000, Avg. loss: 95.833045\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 2003.60, NNZs: 2, Bias: -35.247321, T: 53500, Avg. loss: 94.577464\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 2003.59, NNZs: 2, Bias: -35.051782, T: 54000, Avg. loss: 92.363649\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 2003.50, NNZs: 2, Bias: -34.855483, T: 54500, Avg. loss: 91.396264\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 2003.61, NNZs: 2, Bias: -34.652147, T: 55000, Avg. loss: 89.070950\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 2003.70, NNZs: 2, Bias: -34.451801, T: 55500, Avg. loss: 88.639026\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 2003.54, NNZs: 2, Bias: -34.267371, T: 56000, Avg. loss: 88.680641\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 2003.62, NNZs: 2, Bias: -34.075146, T: 56500, Avg. loss: 88.443936\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 2003.63, NNZs: 2, Bias: -33.885471, T: 57000, Avg. loss: 86.974928\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 2003.57, NNZs: 2, Bias: -33.701352, T: 57500, Avg. loss: 87.025384\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 2003.55, NNZs: 2, Bias: -33.514227, T: 58000, Avg. loss: 85.722970\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 2003.68, NNZs: 2, Bias: -33.323086, T: 58500, Avg. loss: 84.363391\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 2003.65, NNZs: 2, Bias: -33.137155, T: 59000, Avg. loss: 83.298738\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 2003.72, NNZs: 2, Bias: -32.949204, T: 59500, Avg. loss: 82.405128\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 2003.68, NNZs: 2, Bias: -32.770402, T: 60000, Avg. loss: 82.389894\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 2003.71, NNZs: 2, Bias: -32.583874, T: 60500, Avg. loss: 80.316714\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 2003.83, NNZs: 2, Bias: -32.399740, T: 61000, Avg. loss: 80.153083\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 2003.61, NNZs: 2, Bias: -32.225439, T: 61500, Avg. loss: 79.874304\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 2003.57, NNZs: 2, Bias: -32.046620, T: 62000, Avg. loss: 78.372507\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 2003.74, NNZs: 2, Bias: -31.863850, T: 62500, Avg. loss: 77.490099\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 2003.68, NNZs: 2, Bias: -31.686524, T: 63000, Avg. loss: 77.305388\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 2003.78, NNZs: 2, Bias: -31.509239, T: 63500, Avg. loss: 76.694840\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 2003.72, NNZs: 2, Bias: -31.336498, T: 64000, Avg. loss: 75.382238\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 2003.68, NNZs: 2, Bias: -31.160252, T: 64500, Avg. loss: 74.076534\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 2003.81, NNZs: 2, Bias: -30.986998, T: 65000, Avg. loss: 74.323332\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 2003.70, NNZs: 2, Bias: -30.814970, T: 65500, Avg. loss: 72.855065\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 2003.69, NNZs: 2, Bias: -30.644900, T: 66000, Avg. loss: 72.437837\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 2003.75, NNZs: 2, Bias: -30.472947, T: 66500, Avg. loss: 71.877755\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 2003.75, NNZs: 2, Bias: -30.299469, T: 67000, Avg. loss: 70.627711\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 2003.73, NNZs: 2, Bias: -30.131786, T: 67500, Avg. loss: 70.725495\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 2003.80, NNZs: 2, Bias: -29.959459, T: 68000, Avg. loss: 68.998091\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 2003.74, NNZs: 2, Bias: -29.794720, T: 68500, Avg. loss: 69.047970\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 2003.77, NNZs: 2, Bias: -29.630786, T: 69000, Avg. loss: 69.126241\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 2003.72, NNZs: 2, Bias: -29.464696, T: 69500, Avg. loss: 67.412946\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 2003.83, NNZs: 2, Bias: -29.299950, T: 70000, Avg. loss: 67.925661\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 2003.78, NNZs: 2, Bias: -29.137626, T: 70500, Avg. loss: 65.894973\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 2003.74, NNZs: 2, Bias: -28.968710, T: 71000, Avg. loss: 64.095928\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 2003.80, NNZs: 2, Bias: -28.802425, T: 71500, Avg. loss: 64.425678\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 2003.85, NNZs: 2, Bias: -28.638007, T: 72000, Avg. loss: 63.909921\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 145\n",
      "Norm: 2003.84, NNZs: 2, Bias: -28.478388, T: 72500, Avg. loss: 63.689365\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 146\n",
      "Norm: 2003.74, NNZs: 2, Bias: -28.319425, T: 73000, Avg. loss: 62.357153\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 147\n",
      "Norm: 2003.83, NNZs: 2, Bias: -28.157504, T: 73500, Avg. loss: 62.078146\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 148\n",
      "Norm: 2003.79, NNZs: 2, Bias: -27.997738, T: 74000, Avg. loss: 61.263777\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 149\n",
      "Norm: 2003.95, NNZs: 2, Bias: -27.837595, T: 74500, Avg. loss: 60.751575\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 150\n",
      "Norm: 2003.83, NNZs: 2, Bias: -27.682522, T: 75000, Avg. loss: 60.853964\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 151\n",
      "Norm: 2003.82, NNZs: 2, Bias: -27.527859, T: 75500, Avg. loss: 60.040193\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 152\n",
      "Norm: 2003.96, NNZs: 2, Bias: -27.373708, T: 76000, Avg. loss: 59.845052\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 153\n",
      "Norm: 2003.99, NNZs: 2, Bias: -27.220510, T: 76500, Avg. loss: 58.621635\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 154\n",
      "Norm: 2003.89, NNZs: 2, Bias: -27.065067, T: 77000, Avg. loss: 57.338258\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 155\n",
      "Norm: 2004.01, NNZs: 2, Bias: -26.910372, T: 77500, Avg. loss: 57.031732\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 156\n",
      "Norm: 2003.89, NNZs: 2, Bias: -26.762023, T: 78000, Avg. loss: 57.005194\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 157\n",
      "Norm: 2003.95, NNZs: 2, Bias: -26.610963, T: 78500, Avg. loss: 56.116497\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 2003.87, NNZs: 2, Bias: -26.464088, T: 79000, Avg. loss: 55.964642\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 159\n",
      "Norm: 2003.98, NNZs: 2, Bias: -26.311171, T: 79500, Avg. loss: 54.856612\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 160\n",
      "Norm: 2003.95, NNZs: 2, Bias: -26.161273, T: 80000, Avg. loss: 53.951919\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 161\n",
      "Norm: 2003.92, NNZs: 2, Bias: -26.011579, T: 80500, Avg. loss: 53.447724\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 162\n",
      "Norm: 2003.93, NNZs: 2, Bias: -25.862759, T: 81000, Avg. loss: 53.217761\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 163\n",
      "Norm: 2003.98, NNZs: 2, Bias: -25.717292, T: 81500, Avg. loss: 52.732304\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 164\n",
      "Norm: 2003.94, NNZs: 2, Bias: -25.573091, T: 82000, Avg. loss: 52.569316\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 165\n",
      "Norm: 2003.86, NNZs: 2, Bias: -25.430869, T: 82500, Avg. loss: 51.902919\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 166\n",
      "Norm: 2004.01, NNZs: 2, Bias: -25.285174, T: 83000, Avg. loss: 51.547138\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 167\n",
      "Norm: 2003.98, NNZs: 2, Bias: -25.141909, T: 83500, Avg. loss: 50.501699\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 168\n",
      "Norm: 2003.88, NNZs: 2, Bias: -24.997874, T: 84000, Avg. loss: 50.088882\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 169\n",
      "Norm: 2003.92, NNZs: 2, Bias: -24.858591, T: 84500, Avg. loss: 50.321299\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 170\n",
      "Norm: 2003.95, NNZs: 2, Bias: -24.717660, T: 85000, Avg. loss: 49.445825\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 171\n",
      "Norm: 2003.95, NNZs: 2, Bias: -24.581418, T: 85500, Avg. loss: 49.618363\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 172\n",
      "Norm: 2003.88, NNZs: 2, Bias: -24.440366, T: 86000, Avg. loss: 47.869103\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 173\n",
      "Norm: 2003.94, NNZs: 2, Bias: -24.301878, T: 86500, Avg. loss: 48.114947\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 174\n",
      "Norm: 2003.99, NNZs: 2, Bias: -24.160566, T: 87000, Avg. loss: 47.364340\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 175\n",
      "Norm: 2003.95, NNZs: 2, Bias: -24.022255, T: 87500, Avg. loss: 46.647995\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 176\n",
      "Norm: 2004.00, NNZs: 2, Bias: -23.882089, T: 88000, Avg. loss: 45.710127\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 177\n",
      "Norm: 2003.96, NNZs: 2, Bias: -23.748031, T: 88500, Avg. loss: 46.215151\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 178\n",
      "Norm: 2004.01, NNZs: 2, Bias: -23.612833, T: 89000, Avg. loss: 45.528909\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 179\n",
      "Norm: 2004.03, NNZs: 2, Bias: -23.478734, T: 89500, Avg. loss: 45.173986\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 180\n",
      "Norm: 2003.96, NNZs: 2, Bias: -23.342881, T: 90000, Avg. loss: 44.279876\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 181\n",
      "Norm: 2004.01, NNZs: 2, Bias: -23.209146, T: 90500, Avg. loss: 44.637559\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 182\n",
      "Norm: 2003.97, NNZs: 2, Bias: -23.073559, T: 91000, Avg. loss: 42.903965\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 183\n",
      "Norm: 2003.99, NNZs: 2, Bias: -22.943547, T: 91500, Avg. loss: 43.361781\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 184\n",
      "Norm: 2004.03, NNZs: 2, Bias: -22.810901, T: 92000, Avg. loss: 42.786686\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 185\n",
      "Norm: 2004.10, NNZs: 2, Bias: -22.678118, T: 92500, Avg. loss: 42.562256\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 186\n",
      "Norm: 2003.96, NNZs: 2, Bias: -22.550723, T: 93000, Avg. loss: 41.755982\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 187\n",
      "Norm: 2004.11, NNZs: 2, Bias: -22.416179, T: 93500, Avg. loss: 41.157098\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 188\n",
      "Norm: 2004.04, NNZs: 2, Bias: -22.288356, T: 94000, Avg. loss: 41.278964\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 189\n",
      "Norm: 2004.11, NNZs: 2, Bias: -22.155571, T: 94500, Avg. loss: 40.225717\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 190\n",
      "Norm: 2004.13, NNZs: 2, Bias: -22.028316, T: 95000, Avg. loss: 40.231301\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 191\n",
      "Norm: 2004.07, NNZs: 2, Bias: -21.899610, T: 95500, Avg. loss: 38.961994\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 192\n",
      "Norm: 2004.00, NNZs: 2, Bias: -21.773276, T: 96000, Avg. loss: 39.225569\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 193\n",
      "Norm: 2004.06, NNZs: 2, Bias: -21.645549, T: 96500, Avg. loss: 38.609915\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 194\n",
      "Norm: 2004.07, NNZs: 2, Bias: -21.522927, T: 97000, Avg. loss: 38.816828\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 195\n",
      "Norm: 2004.09, NNZs: 2, Bias: -21.397670, T: 97500, Avg. loss: 38.201988\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 196\n",
      "Norm: 2004.11, NNZs: 2, Bias: -21.273019, T: 98000, Avg. loss: 37.759097\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 197\n",
      "Norm: 2004.07, NNZs: 2, Bias: -21.151345, T: 98500, Avg. loss: 37.369632\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 198\n",
      "Norm: 2004.07, NNZs: 2, Bias: -21.028605, T: 99000, Avg. loss: 36.845437\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 199\n",
      "Norm: 2004.10, NNZs: 2, Bias: -20.905148, T: 99500, Avg. loss: 36.272007\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 200\n",
      "Norm: 2004.03, NNZs: 2, Bias: -20.787989, T: 100000, Avg. loss: 36.544457\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 201\n",
      "Norm: 2004.06, NNZs: 2, Bias: -20.666094, T: 100500, Avg. loss: 35.871929\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 202\n",
      "Norm: 2004.16, NNZs: 2, Bias: -20.544679, T: 101000, Avg. loss: 35.389240\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 203\n",
      "Norm: 2004.12, NNZs: 2, Bias: -20.428613, T: 101500, Avg. loss: 35.498330\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 204\n",
      "Norm: 2004.09, NNZs: 2, Bias: -20.310123, T: 102000, Avg. loss: 34.938646\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 205\n",
      "Norm: 2004.10, NNZs: 2, Bias: -20.193125, T: 102500, Avg. loss: 34.582750\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 206\n",
      "Norm: 2004.09, NNZs: 2, Bias: -20.076927, T: 103000, Avg. loss: 34.440303\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 207\n",
      "Norm: 2004.13, NNZs: 2, Bias: -19.959125, T: 103500, Avg. loss: 33.749372\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 208\n",
      "Norm: 2004.04, NNZs: 2, Bias: -19.844163, T: 104000, Avg. loss: 33.398398\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 209\n",
      "Norm: 2004.10, NNZs: 2, Bias: -19.726128, T: 104500, Avg. loss: 32.848554\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 210\n",
      "Norm: 2004.11, NNZs: 2, Bias: -19.613208, T: 105000, Avg. loss: 32.699054\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 211\n",
      "Norm: 2004.14, NNZs: 2, Bias: -19.500098, T: 105500, Avg. loss: 32.928768\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 212\n",
      "Norm: 2004.18, NNZs: 2, Bias: -19.383976, T: 106000, Avg. loss: 31.884403\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 213\n",
      "Norm: 2004.22, NNZs: 2, Bias: -19.269824, T: 106500, Avg. loss: 31.639781\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 214\n",
      "Norm: 2004.09, NNZs: 2, Bias: -19.159962, T: 107000, Avg. loss: 31.420466\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 215\n",
      "Norm: 2004.12, NNZs: 2, Bias: -19.046528, T: 107500, Avg. loss: 31.183749\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 216\n",
      "Norm: 2004.14, NNZs: 2, Bias: -18.937569, T: 108000, Avg. loss: 31.122720\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 217\n",
      "Norm: 2004.12, NNZs: 2, Bias: -18.827769, T: 108500, Avg. loss: 30.777243\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 218\n",
      "Norm: 2004.25, NNZs: 2, Bias: -18.715760, T: 109000, Avg. loss: 30.191642\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 219\n",
      "Norm: 2004.14, NNZs: 2, Bias: -18.608427, T: 109500, Avg. loss: 29.843419\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 220\n",
      "Norm: 2004.13, NNZs: 2, Bias: -18.496134, T: 110000, Avg. loss: 28.878718\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 221\n",
      "Norm: 2004.18, NNZs: 2, Bias: -18.389718, T: 110500, Avg. loss: 29.745643\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 222\n",
      "Norm: 2004.13, NNZs: 2, Bias: -18.285108, T: 111000, Avg. loss: 29.451988\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 223\n",
      "Norm: 2004.15, NNZs: 2, Bias: -18.176239, T: 111500, Avg. loss: 28.745478\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 224\n",
      "Norm: 2004.17, NNZs: 2, Bias: -18.070133, T: 112000, Avg. loss: 28.443517\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 225\n",
      "Norm: 2004.15, NNZs: 2, Bias: -17.965262, T: 112500, Avg. loss: 28.422496\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 226\n",
      "Norm: 2004.18, NNZs: 2, Bias: -17.857526, T: 113000, Avg. loss: 27.965549\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 227\n",
      "Norm: 2004.15, NNZs: 2, Bias: -17.751728, T: 113500, Avg. loss: 27.490929\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 228\n",
      "Norm: 2004.17, NNZs: 2, Bias: -17.647268, T: 114000, Avg. loss: 27.468160\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 229\n",
      "Norm: 2004.23, NNZs: 2, Bias: -17.542051, T: 114500, Avg. loss: 27.214694\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 230\n",
      "Norm: 2004.23, NNZs: 2, Bias: -17.438061, T: 115000, Avg. loss: 27.064591\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 231\n",
      "Norm: 2004.19, NNZs: 2, Bias: -17.333691, T: 115500, Avg. loss: 26.123802\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 232\n",
      "Norm: 2004.11, NNZs: 2, Bias: -17.232650, T: 116000, Avg. loss: 26.271451\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 233\n",
      "Norm: 2004.18, NNZs: 2, Bias: -17.127825, T: 116500, Avg. loss: 25.785882\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 234\n",
      "Norm: 2004.23, NNZs: 2, Bias: -17.026107, T: 117000, Avg. loss: 25.879514\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 235\n",
      "Norm: 2004.18, NNZs: 2, Bias: -16.930254, T: 117500, Avg. loss: 26.083357\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 236\n",
      "Norm: 2004.20, NNZs: 2, Bias: -16.828094, T: 118000, Avg. loss: 25.221687\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 237\n",
      "Norm: 2004.19, NNZs: 2, Bias: -16.729464, T: 118500, Avg. loss: 25.102185\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 238\n",
      "Norm: 2004.19, NNZs: 2, Bias: -16.632734, T: 119000, Avg. loss: 24.963195\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 239\n",
      "Norm: 2004.26, NNZs: 2, Bias: -16.532280, T: 119500, Avg. loss: 24.426251\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 240\n",
      "Norm: 2004.25, NNZs: 2, Bias: -16.433699, T: 120000, Avg. loss: 24.112522\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 241\n",
      "Norm: 2004.14, NNZs: 2, Bias: -16.338100, T: 120500, Avg. loss: 24.035223\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 242\n",
      "Norm: 2004.22, NNZs: 2, Bias: -16.242166, T: 121000, Avg. loss: 24.167478\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 243\n",
      "Norm: 2004.17, NNZs: 2, Bias: -16.147200, T: 121500, Avg. loss: 23.473805\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 244\n",
      "Norm: 2004.28, NNZs: 2, Bias: -16.047631, T: 122000, Avg. loss: 23.496658\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 245\n",
      "Norm: 2004.20, NNZs: 2, Bias: -15.950465, T: 122500, Avg. loss: 22.869835\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 246\n",
      "Norm: 2004.23, NNZs: 2, Bias: -15.857928, T: 123000, Avg. loss: 23.307946\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 247\n",
      "Norm: 2004.24, NNZs: 2, Bias: -15.761100, T: 123500, Avg. loss: 22.652352\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 248\n",
      "Norm: 2004.33, NNZs: 2, Bias: -15.664461, T: 124000, Avg. loss: 22.394709\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 249\n",
      "Norm: 2004.22, NNZs: 2, Bias: -15.570528, T: 124500, Avg. loss: 22.031596\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 250\n",
      "Norm: 2004.19, NNZs: 2, Bias: -15.474863, T: 125000, Avg. loss: 21.584513\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 251\n",
      "Norm: 2004.24, NNZs: 2, Bias: -15.380197, T: 125500, Avg. loss: 21.655144\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 252\n",
      "Norm: 2004.31, NNZs: 2, Bias: -15.286672, T: 126000, Avg. loss: 21.749305\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 253\n",
      "Norm: 2004.22, NNZs: 2, Bias: -15.194843, T: 126500, Avg. loss: 21.161911\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 254\n",
      "Norm: 2004.25, NNZs: 2, Bias: -15.102838, T: 127000, Avg. loss: 21.148347\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 255\n",
      "Norm: 2004.35, NNZs: 2, Bias: -15.009718, T: 127500, Avg. loss: 20.642635\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 256\n",
      "Norm: 2004.26, NNZs: 2, Bias: -14.920146, T: 128000, Avg. loss: 20.613849\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 257\n",
      "Norm: 2004.23, NNZs: 2, Bias: -14.830902, T: 128500, Avg. loss: 20.275614\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 258\n",
      "Norm: 2004.25, NNZs: 2, Bias: -14.743497, T: 129000, Avg. loss: 20.595576\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 259\n",
      "Norm: 2004.34, NNZs: 2, Bias: -14.653607, T: 129500, Avg. loss: 20.201989\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 260\n",
      "Norm: 2004.27, NNZs: 2, Bias: -14.569196, T: 130000, Avg. loss: 20.180927\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 261\n",
      "Norm: 2004.32, NNZs: 2, Bias: -14.480528, T: 130500, Avg. loss: 19.514383\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 262\n",
      "Norm: 2004.31, NNZs: 2, Bias: -14.396363, T: 131000, Avg. loss: 19.930661\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 263\n",
      "Norm: 2004.31, NNZs: 2, Bias: -14.310371, T: 131500, Avg. loss: 19.487656\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 264\n",
      "Norm: 2004.26, NNZs: 2, Bias: -14.226595, T: 132000, Avg. loss: 19.485472\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 265\n",
      "Norm: 2004.27, NNZs: 2, Bias: -14.138771, T: 132500, Avg. loss: 18.699071\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 266\n",
      "Norm: 2004.33, NNZs: 2, Bias: -14.054570, T: 133000, Avg. loss: 19.134251\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 267\n",
      "Norm: 2004.32, NNZs: 2, Bias: -13.969619, T: 133500, Avg. loss: 18.920616\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 268\n",
      "Norm: 2004.27, NNZs: 2, Bias: -13.886773, T: 134000, Avg. loss: 18.565872\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 269\n",
      "Norm: 2004.29, NNZs: 2, Bias: -13.803487, T: 134500, Avg. loss: 18.619652\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 270\n",
      "Norm: 2004.36, NNZs: 2, Bias: -13.719799, T: 135000, Avg. loss: 18.310490\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 271\n",
      "Norm: 2004.35, NNZs: 2, Bias: -13.636032, T: 135500, Avg. loss: 17.959306\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 272\n",
      "Norm: 2004.34, NNZs: 2, Bias: -13.553909, T: 136000, Avg. loss: 17.998678\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 273\n",
      "Norm: 2004.36, NNZs: 2, Bias: -13.472704, T: 136500, Avg. loss: 17.860574\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 274\n",
      "Norm: 2004.31, NNZs: 2, Bias: -13.387553, T: 137000, Avg. loss: 17.141654\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 275\n",
      "Norm: 2004.38, NNZs: 2, Bias: -13.304327, T: 137500, Avg. loss: 17.095641\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 276\n",
      "Norm: 2004.40, NNZs: 2, Bias: -13.222846, T: 138000, Avg. loss: 16.969827\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 277\n",
      "Norm: 2004.35, NNZs: 2, Bias: -13.143073, T: 138500, Avg. loss: 17.130301\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 278\n",
      "Norm: 2004.37, NNZs: 2, Bias: -13.061611, T: 139000, Avg. loss: 16.652098\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 279\n",
      "Norm: 2004.38, NNZs: 2, Bias: -12.981952, T: 139500, Avg. loss: 16.674624\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 280\n",
      "Norm: 2004.38, NNZs: 2, Bias: -12.904034, T: 140000, Avg. loss: 16.702038\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 281\n",
      "Norm: 2004.43, NNZs: 2, Bias: -12.824911, T: 140500, Avg. loss: 16.279779\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 282\n",
      "Norm: 2004.40, NNZs: 2, Bias: -12.745434, T: 141000, Avg. loss: 16.029137\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 283\n",
      "Norm: 2004.41, NNZs: 2, Bias: -12.667435, T: 141500, Avg. loss: 16.042932\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 284\n",
      "Norm: 2004.38, NNZs: 2, Bias: -12.588626, T: 142000, Avg. loss: 15.669667\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 285\n",
      "Norm: 2004.39, NNZs: 2, Bias: -12.508141, T: 142500, Avg. loss: 15.356156\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 286\n",
      "Norm: 2004.41, NNZs: 2, Bias: -12.432184, T: 143000, Avg. loss: 15.655708\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 287\n",
      "Norm: 2004.39, NNZs: 2, Bias: -12.355423, T: 143500, Avg. loss: 15.448305\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 288\n",
      "Norm: 2004.40, NNZs: 2, Bias: -12.277315, T: 144000, Avg. loss: 15.018371\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 289\n",
      "Norm: 2004.40, NNZs: 2, Bias: -12.202712, T: 144500, Avg. loss: 15.248298\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 290\n",
      "Norm: 2004.37, NNZs: 2, Bias: -12.128393, T: 145000, Avg. loss: 15.088085\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 291\n",
      "Norm: 2004.37, NNZs: 2, Bias: -12.052321, T: 145500, Avg. loss: 14.748860\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 292\n",
      "Norm: 2004.40, NNZs: 2, Bias: -11.977025, T: 146000, Avg. loss: 14.603921\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 293\n",
      "Norm: 2004.42, NNZs: 2, Bias: -11.903272, T: 146500, Avg. loss: 14.605034\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 294\n",
      "Norm: 2004.41, NNZs: 2, Bias: -11.828200, T: 147000, Avg. loss: 14.329506\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 295\n",
      "Norm: 2004.40, NNZs: 2, Bias: -11.753398, T: 147500, Avg. loss: 14.094976\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 296\n",
      "Norm: 2004.38, NNZs: 2, Bias: -11.679139, T: 148000, Avg. loss: 14.028332\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 297\n",
      "Norm: 2004.38, NNZs: 2, Bias: -11.608330, T: 148500, Avg. loss: 14.038452\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 298\n",
      "Norm: 2004.41, NNZs: 2, Bias: -11.534561, T: 149000, Avg. loss: 13.670164\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 299\n",
      "Norm: 2004.40, NNZs: 2, Bias: -11.464034, T: 149500, Avg. loss: 13.815543\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 300\n",
      "Norm: 2004.38, NNZs: 2, Bias: -11.391824, T: 150000, Avg. loss: 13.506940\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 301\n",
      "Norm: 2004.42, NNZs: 2, Bias: -11.320189, T: 150500, Avg. loss: 13.627651\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 302\n",
      "Norm: 2004.43, NNZs: 2, Bias: -11.248464, T: 151000, Avg. loss: 13.323473\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 303\n",
      "Norm: 2004.39, NNZs: 2, Bias: -11.177792, T: 151500, Avg. loss: 13.079160\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 304\n",
      "Norm: 2004.38, NNZs: 2, Bias: -11.110389, T: 152000, Avg. loss: 13.251473\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 305\n",
      "Norm: 2004.41, NNZs: 2, Bias: -11.041049, T: 152500, Avg. loss: 13.116386\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 306\n",
      "Norm: 2004.40, NNZs: 2, Bias: -10.969986, T: 153000, Avg. loss: 12.643460\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 307\n",
      "Norm: 2004.43, NNZs: 2, Bias: -10.901476, T: 153500, Avg. loss: 12.783440\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 308\n",
      "Norm: 2004.47, NNZs: 2, Bias: -10.831540, T: 154000, Avg. loss: 12.616324\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 309\n",
      "Norm: 2004.42, NNZs: 2, Bias: -10.764909, T: 154500, Avg. loss: 12.538319\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 310\n",
      "Norm: 2004.46, NNZs: 2, Bias: -10.694915, T: 155000, Avg. loss: 12.334417\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 311\n",
      "Norm: 2004.48, NNZs: 2, Bias: -10.625785, T: 155500, Avg. loss: 12.032385\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 312\n",
      "Norm: 2004.44, NNZs: 2, Bias: -10.560134, T: 156000, Avg. loss: 12.203159\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 313\n",
      "Norm: 2004.44, NNZs: 2, Bias: -10.493016, T: 156500, Avg. loss: 12.004138\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 314\n",
      "Norm: 2004.47, NNZs: 2, Bias: -10.425627, T: 157000, Avg. loss: 11.793623\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 315\n",
      "Norm: 2004.46, NNZs: 2, Bias: -10.358722, T: 157500, Avg. loss: 11.802149\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 316\n",
      "Norm: 2004.41, NNZs: 2, Bias: -10.290587, T: 158000, Avg. loss: 11.430930\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 317\n",
      "Norm: 2004.42, NNZs: 2, Bias: -10.224596, T: 158500, Avg. loss: 11.481141\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 318\n",
      "Norm: 2004.44, NNZs: 2, Bias: -10.158856, T: 159000, Avg. loss: 11.348672\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 319\n",
      "Norm: 2004.47, NNZs: 2, Bias: -10.094735, T: 159500, Avg. loss: 11.385708\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 320\n",
      "Norm: 2004.42, NNZs: 2, Bias: -10.031198, T: 160000, Avg. loss: 11.156186\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 321\n",
      "Norm: 2004.47, NNZs: 2, Bias: -9.967803, T: 160500, Avg. loss: 11.414301\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 322\n",
      "Norm: 2004.45, NNZs: 2, Bias: -9.903389, T: 161000, Avg. loss: 10.990728\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 323\n",
      "Norm: 2004.46, NNZs: 2, Bias: -9.839997, T: 161500, Avg. loss: 10.932267\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 324\n",
      "Norm: 2004.41, NNZs: 2, Bias: -9.778240, T: 162000, Avg. loss: 10.739966\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 325\n",
      "Norm: 2004.49, NNZs: 2, Bias: -9.715169, T: 162500, Avg. loss: 10.843224\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 326\n",
      "Norm: 2004.45, NNZs: 2, Bias: -9.653406, T: 163000, Avg. loss: 10.611444\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 327\n",
      "Norm: 2004.47, NNZs: 2, Bias: -9.589583, T: 163500, Avg. loss: 10.520057\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 328\n",
      "Norm: 2004.47, NNZs: 2, Bias: -9.526311, T: 164000, Avg. loss: 10.383554\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 329\n",
      "Norm: 2004.47, NNZs: 2, Bias: -9.464942, T: 164500, Avg. loss: 10.391795\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 330\n",
      "Norm: 2004.46, NNZs: 2, Bias: -9.404399, T: 165000, Avg. loss: 10.228905\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 331\n",
      "Norm: 2004.44, NNZs: 2, Bias: -9.341682, T: 165500, Avg. loss: 9.931241\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 332\n",
      "Norm: 2004.48, NNZs: 2, Bias: -9.280324, T: 166000, Avg. loss: 10.154152\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 333\n",
      "Norm: 2004.50, NNZs: 2, Bias: -9.220914, T: 166500, Avg. loss: 10.103299\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 334\n",
      "Norm: 2004.52, NNZs: 2, Bias: -9.162170, T: 167000, Avg. loss: 10.099123\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 335\n",
      "Norm: 2004.52, NNZs: 2, Bias: -9.103081, T: 167500, Avg. loss: 9.821920\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 336\n",
      "Norm: 2004.52, NNZs: 2, Bias: -9.044578, T: 168000, Avg. loss: 9.764549\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 337\n",
      "Norm: 2004.48, NNZs: 2, Bias: -8.985330, T: 168500, Avg. loss: 9.655163\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 338\n",
      "Norm: 2004.50, NNZs: 2, Bias: -8.925610, T: 169000, Avg. loss: 9.473507\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 339\n",
      "Norm: 2004.50, NNZs: 2, Bias: -8.865875, T: 169500, Avg. loss: 9.454111\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 340\n",
      "Norm: 2004.48, NNZs: 2, Bias: -8.806842, T: 170000, Avg. loss: 9.347112\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 341\n",
      "Norm: 2004.51, NNZs: 2, Bias: -8.747756, T: 170500, Avg. loss: 9.214143\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 342\n",
      "Norm: 2004.50, NNZs: 2, Bias: -8.689691, T: 171000, Avg. loss: 9.139512\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 343\n",
      "Norm: 2004.49, NNZs: 2, Bias: -8.633804, T: 171500, Avg. loss: 9.185368\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 344\n",
      "Norm: 2004.56, NNZs: 2, Bias: -8.575699, T: 172000, Avg. loss: 9.156563\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 345\n",
      "Norm: 2004.55, NNZs: 2, Bias: -8.518815, T: 172500, Avg. loss: 9.032055\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 346\n",
      "Norm: 2004.53, NNZs: 2, Bias: -8.461834, T: 173000, Avg. loss: 8.914627\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 347\n",
      "Norm: 2004.50, NNZs: 2, Bias: -8.405782, T: 173500, Avg. loss: 8.757789\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 348\n",
      "Norm: 2004.51, NNZs: 2, Bias: -8.348889, T: 174000, Avg. loss: 8.783009\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 349\n",
      "Norm: 2004.49, NNZs: 2, Bias: -8.293975, T: 174500, Avg. loss: 8.617223\n",
      "Total training time: 0.37 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 350\n",
      "Norm: 2004.54, NNZs: 2, Bias: -8.238684, T: 175000, Avg. loss: 8.620471\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 351\n",
      "Norm: 2004.53, NNZs: 2, Bias: -8.184552, T: 175500, Avg. loss: 8.540189\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 352\n",
      "Norm: 2004.53, NNZs: 2, Bias: -8.129029, T: 176000, Avg. loss: 8.492905\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 353\n",
      "Norm: 2004.55, NNZs: 2, Bias: -8.073202, T: 176500, Avg. loss: 8.340800\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 354\n",
      "Norm: 2004.55, NNZs: 2, Bias: -8.019555, T: 177000, Avg. loss: 8.326819\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 355\n",
      "Norm: 2004.53, NNZs: 2, Bias: -7.965601, T: 177500, Avg. loss: 8.181931\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 356\n",
      "Norm: 2004.54, NNZs: 2, Bias: -7.909784, T: 178000, Avg. loss: 7.943551\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 357\n",
      "Norm: 2004.54, NNZs: 2, Bias: -7.857192, T: 178500, Avg. loss: 8.074603\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 358\n",
      "Norm: 2004.54, NNZs: 2, Bias: -7.804351, T: 179000, Avg. loss: 7.957375\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 359\n",
      "Norm: 2004.55, NNZs: 2, Bias: -7.749735, T: 179500, Avg. loss: 7.858712\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 360\n",
      "Norm: 2004.54, NNZs: 2, Bias: -7.698157, T: 180000, Avg. loss: 7.818309\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 361\n",
      "Norm: 2004.51, NNZs: 2, Bias: -7.647070, T: 180500, Avg. loss: 7.741681\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 362\n",
      "Norm: 2004.55, NNZs: 2, Bias: -7.595359, T: 181000, Avg. loss: 7.775240\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 363\n",
      "Norm: 2004.55, NNZs: 2, Bias: -7.544547, T: 181500, Avg. loss: 7.759950\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 364\n",
      "Norm: 2004.55, NNZs: 2, Bias: -7.491987, T: 182000, Avg. loss: 7.444557\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 365\n",
      "Norm: 2004.55, NNZs: 2, Bias: -7.440112, T: 182500, Avg. loss: 7.369366\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 366\n",
      "Norm: 2004.55, NNZs: 2, Bias: -7.389993, T: 183000, Avg. loss: 7.459415\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 367\n",
      "Norm: 2004.56, NNZs: 2, Bias: -7.339649, T: 183500, Avg. loss: 7.324702\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 368\n",
      "Norm: 2004.53, NNZs: 2, Bias: -7.289269, T: 184000, Avg. loss: 7.255847\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 369\n",
      "Norm: 2004.55, NNZs: 2, Bias: -7.239490, T: 184500, Avg. loss: 7.192578\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 370\n",
      "Norm: 2004.55, NNZs: 2, Bias: -7.189877, T: 185000, Avg. loss: 7.172278\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 371\n",
      "Norm: 2004.57, NNZs: 2, Bias: -7.140272, T: 185500, Avg. loss: 7.136923\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 372\n",
      "Norm: 2004.61, NNZs: 2, Bias: -7.089440, T: 186000, Avg. loss: 7.075700\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 373\n",
      "Norm: 2004.58, NNZs: 2, Bias: -7.039902, T: 186500, Avg. loss: 6.964090\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 374\n",
      "Norm: 2004.61, NNZs: 2, Bias: -6.989706, T: 187000, Avg. loss: 6.918781\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 375\n",
      "Norm: 2004.61, NNZs: 2, Bias: -6.939782, T: 187500, Avg. loss: 6.756428\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 376\n",
      "Norm: 2004.60, NNZs: 2, Bias: -6.891457, T: 188000, Avg. loss: 6.767480\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 377\n",
      "Norm: 2004.57, NNZs: 2, Bias: -6.844314, T: 188500, Avg. loss: 6.791674\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 378\n",
      "Norm: 2004.57, NNZs: 2, Bias: -6.796107, T: 189000, Avg. loss: 6.622508\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 379\n",
      "Norm: 2004.57, NNZs: 2, Bias: -6.749128, T: 189500, Avg. loss: 6.685284\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 380\n",
      "Norm: 2004.56, NNZs: 2, Bias: -6.701764, T: 190000, Avg. loss: 6.476573\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 381\n",
      "Norm: 2004.59, NNZs: 2, Bias: -6.653902, T: 190500, Avg. loss: 6.474808\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 382\n",
      "Norm: 2004.60, NNZs: 2, Bias: -6.607216, T: 191000, Avg. loss: 6.496760\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 383\n",
      "Norm: 2004.55, NNZs: 2, Bias: -6.561166, T: 191500, Avg. loss: 6.352670\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 384\n",
      "Norm: 2004.57, NNZs: 2, Bias: -6.515087, T: 192000, Avg. loss: 6.333653\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 385\n",
      "Norm: 2004.58, NNZs: 2, Bias: -6.468691, T: 192500, Avg. loss: 6.336315\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 386\n",
      "Norm: 2004.59, NNZs: 2, Bias: -6.421515, T: 193000, Avg. loss: 6.178261\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 387\n",
      "Norm: 2004.56, NNZs: 2, Bias: -6.375995, T: 193500, Avg. loss: 6.204614\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 388\n",
      "Norm: 2004.58, NNZs: 2, Bias: -6.331946, T: 194000, Avg. loss: 6.196823\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 389\n",
      "Norm: 2004.62, NNZs: 2, Bias: -6.287083, T: 194500, Avg. loss: 6.192893\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 390\n",
      "Norm: 2004.59, NNZs: 2, Bias: -6.243533, T: 195000, Avg. loss: 6.052038\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 391\n",
      "Norm: 2004.59, NNZs: 2, Bias: -6.197148, T: 195500, Avg. loss: 5.940350\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 392\n",
      "Norm: 2004.58, NNZs: 2, Bias: -6.153261, T: 196000, Avg. loss: 6.020860\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 393\n",
      "Norm: 2004.59, NNZs: 2, Bias: -6.109564, T: 196500, Avg. loss: 5.953419\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 394\n",
      "Norm: 2004.57, NNZs: 2, Bias: -6.064954, T: 197000, Avg. loss: 5.776553\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 395\n",
      "Norm: 2004.58, NNZs: 2, Bias: -6.022147, T: 197500, Avg. loss: 5.808380\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 396\n",
      "Norm: 2004.62, NNZs: 2, Bias: -5.978307, T: 198000, Avg. loss: 5.765633\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 397\n",
      "Norm: 2004.62, NNZs: 2, Bias: -5.934397, T: 198500, Avg. loss: 5.651828\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 398\n",
      "Norm: 2004.62, NNZs: 2, Bias: -5.890955, T: 199000, Avg. loss: 5.634849\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 399\n",
      "Norm: 2004.61, NNZs: 2, Bias: -5.848147, T: 199500, Avg. loss: 5.547124\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 400\n",
      "Norm: 2004.61, NNZs: 2, Bias: -5.805031, T: 200000, Avg. loss: 5.501391\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 401\n",
      "Norm: 2004.59, NNZs: 2, Bias: -5.760684, T: 200500, Avg. loss: 5.467037\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 402\n",
      "Norm: 2004.61, NNZs: 2, Bias: -5.718148, T: 201000, Avg. loss: 5.555897\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 403\n",
      "Norm: 2004.60, NNZs: 2, Bias: -5.677311, T: 201500, Avg. loss: 5.445163\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 404\n",
      "Norm: 2004.60, NNZs: 2, Bias: -5.636038, T: 202000, Avg. loss: 5.352651\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 405\n",
      "Norm: 2004.64, NNZs: 2, Bias: -5.593683, T: 202500, Avg. loss: 5.282223\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 406\n",
      "Norm: 2004.64, NNZs: 2, Bias: -5.552235, T: 203000, Avg. loss: 5.225200\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 407\n",
      "Norm: 2004.66, NNZs: 2, Bias: -5.511253, T: 203500, Avg. loss: 5.170999\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 408\n",
      "Norm: 2004.64, NNZs: 2, Bias: -5.471072, T: 204000, Avg. loss: 5.144553\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 409\n",
      "Norm: 2004.62, NNZs: 2, Bias: -5.429326, T: 204500, Avg. loss: 5.134947\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 410\n",
      "Norm: 2004.63, NNZs: 2, Bias: -5.389968, T: 205000, Avg. loss: 5.176632\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 411\n",
      "Norm: 2004.62, NNZs: 2, Bias: -5.350194, T: 205500, Avg. loss: 4.985552\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 412\n",
      "Norm: 2004.63, NNZs: 2, Bias: -5.309607, T: 206000, Avg. loss: 5.041491\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 413\n",
      "Norm: 2004.64, NNZs: 2, Bias: -5.270680, T: 206500, Avg. loss: 5.028366\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 414\n",
      "Norm: 2004.62, NNZs: 2, Bias: -5.230310, T: 207000, Avg. loss: 4.884131\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 415\n",
      "Norm: 2004.64, NNZs: 2, Bias: -5.190876, T: 207500, Avg. loss: 4.888540\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 416\n",
      "Norm: 2004.64, NNZs: 2, Bias: -5.152389, T: 208000, Avg. loss: 4.908465\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 417\n",
      "Norm: 2004.65, NNZs: 2, Bias: -5.113943, T: 208500, Avg. loss: 4.838462\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 418\n",
      "Norm: 2004.63, NNZs: 2, Bias: -5.075132, T: 209000, Avg. loss: 4.757975\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 419\n",
      "Norm: 2004.63, NNZs: 2, Bias: -5.034853, T: 209500, Avg. loss: 4.670547\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 420\n",
      "Norm: 2004.62, NNZs: 2, Bias: -4.997553, T: 210000, Avg. loss: 4.701473\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 421\n",
      "Norm: 2004.60, NNZs: 2, Bias: -4.959395, T: 210500, Avg. loss: 4.683264\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 422\n",
      "Norm: 2004.61, NNZs: 2, Bias: -4.920837, T: 211000, Avg. loss: 4.680317\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 423\n",
      "Norm: 2004.62, NNZs: 2, Bias: -4.882828, T: 211500, Avg. loss: 4.664868\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 424\n",
      "Norm: 2004.65, NNZs: 2, Bias: -4.843985, T: 212000, Avg. loss: 4.505056\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 425\n",
      "Norm: 2004.66, NNZs: 2, Bias: -4.804219, T: 212500, Avg. loss: 4.451891\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 426\n",
      "Norm: 2004.64, NNZs: 2, Bias: -4.768427, T: 213000, Avg. loss: 4.534150\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 427\n",
      "Norm: 2004.62, NNZs: 2, Bias: -4.732039, T: 213500, Avg. loss: 4.478416\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 428\n",
      "Norm: 2004.66, NNZs: 2, Bias: -4.694448, T: 214000, Avg. loss: 4.455841\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 429\n",
      "Norm: 2004.63, NNZs: 2, Bias: -4.659044, T: 214500, Avg. loss: 4.449219\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 430\n",
      "Norm: 2004.64, NNZs: 2, Bias: -4.622896, T: 215000, Avg. loss: 4.420905\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 431\n",
      "Norm: 2004.65, NNZs: 2, Bias: -4.586996, T: 215500, Avg. loss: 4.441761\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 432\n",
      "Norm: 2004.63, NNZs: 2, Bias: -4.550915, T: 216000, Avg. loss: 4.308989\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 433\n",
      "Norm: 2004.65, NNZs: 2, Bias: -4.513324, T: 216500, Avg. loss: 4.238677\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 434\n",
      "Norm: 2004.64, NNZs: 2, Bias: -4.477985, T: 217000, Avg. loss: 4.249267\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 435\n",
      "Norm: 2004.68, NNZs: 2, Bias: -4.441621, T: 217500, Avg. loss: 4.193910\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 436\n",
      "Norm: 2004.68, NNZs: 2, Bias: -4.406146, T: 218000, Avg. loss: 4.143229\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 437\n",
      "Norm: 2004.68, NNZs: 2, Bias: -4.370880, T: 218500, Avg. loss: 4.237337\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 438\n",
      "Norm: 2004.62, NNZs: 2, Bias: -4.336673, T: 219000, Avg. loss: 4.044322\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 439\n",
      "Norm: 2004.67, NNZs: 2, Bias: -4.301399, T: 219500, Avg. loss: 4.013948\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 440\n",
      "Norm: 2004.66, NNZs: 2, Bias: -4.267489, T: 220000, Avg. loss: 4.085985\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 441\n",
      "Norm: 2004.69, NNZs: 2, Bias: -4.232271, T: 220500, Avg. loss: 4.072936\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 442\n",
      "Norm: 2004.66, NNZs: 2, Bias: -4.199059, T: 221000, Avg. loss: 3.996898\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 443\n",
      "Norm: 2004.65, NNZs: 2, Bias: -4.166030, T: 221500, Avg. loss: 4.012391\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 444\n",
      "Norm: 2004.69, NNZs: 2, Bias: -4.131256, T: 222000, Avg. loss: 3.948129\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 445\n",
      "Norm: 2004.65, NNZs: 2, Bias: -4.097861, T: 222500, Avg. loss: 3.930706\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 446\n",
      "Norm: 2004.64, NNZs: 2, Bias: -4.064423, T: 223000, Avg. loss: 3.894517\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 447\n",
      "Norm: 2004.65, NNZs: 2, Bias: -4.030057, T: 223500, Avg. loss: 3.886944\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 448\n",
      "Norm: 2004.67, NNZs: 2, Bias: -3.994732, T: 224000, Avg. loss: 3.728492\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 449\n",
      "Norm: 2004.68, NNZs: 2, Bias: -3.961941, T: 224500, Avg. loss: 3.787959\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 450\n",
      "Norm: 2004.69, NNZs: 2, Bias: -3.929120, T: 225000, Avg. loss: 3.783275\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 451\n",
      "Norm: 2004.66, NNZs: 2, Bias: -3.896342, T: 225500, Avg. loss: 3.737965\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 452\n",
      "Norm: 2004.67, NNZs: 2, Bias: -3.863690, T: 226000, Avg. loss: 3.746602\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 453\n",
      "Norm: 2004.65, NNZs: 2, Bias: -3.831871, T: 226500, Avg. loss: 3.671574\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 454\n",
      "Norm: 2004.64, NNZs: 2, Bias: -3.799190, T: 227000, Avg. loss: 3.661697\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 455\n",
      "Norm: 2004.69, NNZs: 2, Bias: -3.766003, T: 227500, Avg. loss: 3.558320\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 456\n",
      "Norm: 2004.68, NNZs: 2, Bias: -3.734313, T: 228000, Avg. loss: 3.638207\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 457\n",
      "Norm: 2004.68, NNZs: 2, Bias: -3.702214, T: 228500, Avg. loss: 3.558772\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 458\n",
      "Norm: 2004.68, NNZs: 2, Bias: -3.670769, T: 229000, Avg. loss: 3.545094\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 459\n",
      "Norm: 2004.71, NNZs: 2, Bias: -3.638823, T: 229500, Avg. loss: 3.546973\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 460\n",
      "Norm: 2004.67, NNZs: 2, Bias: -3.608305, T: 230000, Avg. loss: 3.473688\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 461\n",
      "Norm: 2004.69, NNZs: 2, Bias: -3.577312, T: 230500, Avg. loss: 3.506053\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 462\n",
      "Norm: 2004.68, NNZs: 2, Bias: -3.547647, T: 231000, Avg. loss: 3.561882\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 463\n",
      "Norm: 2004.70, NNZs: 2, Bias: -3.515448, T: 231500, Avg. loss: 3.394571\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 464\n",
      "Norm: 2004.68, NNZs: 2, Bias: -3.485147, T: 232000, Avg. loss: 3.419145\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 465\n",
      "Norm: 2004.70, NNZs: 2, Bias: -3.455699, T: 232500, Avg. loss: 3.440013\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 466\n",
      "Norm: 2004.71, NNZs: 2, Bias: -3.426175, T: 233000, Avg. loss: 3.374024\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 467\n",
      "Norm: 2004.73, NNZs: 2, Bias: -3.395533, T: 233500, Avg. loss: 3.304433\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 468\n",
      "Norm: 2004.68, NNZs: 2, Bias: -3.365699, T: 234000, Avg. loss: 3.254721\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 469\n",
      "Norm: 2004.70, NNZs: 2, Bias: -3.336918, T: 234500, Avg. loss: 3.339342\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 470\n",
      "Norm: 2004.73, NNZs: 2, Bias: -3.307415, T: 235000, Avg. loss: 3.296491\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 471\n",
      "Norm: 2004.72, NNZs: 2, Bias: -3.276837, T: 235500, Avg. loss: 3.189942\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 472\n",
      "Norm: 2004.69, NNZs: 2, Bias: -3.247976, T: 236000, Avg. loss: 3.233701\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 473\n",
      "Norm: 2004.68, NNZs: 2, Bias: -3.218632, T: 236500, Avg. loss: 3.215650\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 474\n",
      "Norm: 2004.72, NNZs: 2, Bias: -3.188247, T: 237000, Avg. loss: 3.132980\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 475\n",
      "Norm: 2004.70, NNZs: 2, Bias: -3.159265, T: 237500, Avg. loss: 3.094942\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 476\n",
      "Norm: 2004.72, NNZs: 2, Bias: -3.129914, T: 238000, Avg. loss: 3.141986\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 477\n",
      "Norm: 2004.69, NNZs: 2, Bias: -3.102316, T: 238500, Avg. loss: 3.121338\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 478\n",
      "Norm: 2004.70, NNZs: 2, Bias: -3.073447, T: 239000, Avg. loss: 3.038880\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 479\n",
      "Norm: 2004.69, NNZs: 2, Bias: -3.046008, T: 239500, Avg. loss: 3.086626\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 480\n",
      "Norm: 2004.74, NNZs: 2, Bias: -3.017801, T: 240000, Avg. loss: 3.059483\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 481\n",
      "Norm: 2004.71, NNZs: 2, Bias: -2.991156, T: 240500, Avg. loss: 3.101904\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 482\n",
      "Norm: 2004.70, NNZs: 2, Bias: -2.963022, T: 241000, Avg. loss: 2.994043\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 483\n",
      "Norm: 2004.68, NNZs: 2, Bias: -2.935260, T: 241500, Avg. loss: 2.992014\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 484\n",
      "Norm: 2004.70, NNZs: 2, Bias: -2.907968, T: 242000, Avg. loss: 3.004420\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 485\n",
      "Norm: 2004.69, NNZs: 2, Bias: -2.881489, T: 242500, Avg. loss: 2.986650\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 486\n",
      "Norm: 2004.72, NNZs: 2, Bias: -2.853794, T: 243000, Avg. loss: 2.983830\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 487\n",
      "Norm: 2004.69, NNZs: 2, Bias: -2.828557, T: 243500, Avg. loss: 2.957357\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 488\n",
      "Norm: 2004.71, NNZs: 2, Bias: -2.800221, T: 244000, Avg. loss: 2.898099\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 489\n",
      "Norm: 2004.72, NNZs: 2, Bias: -2.773650, T: 244500, Avg. loss: 2.890921\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 490\n",
      "Norm: 2004.71, NNZs: 2, Bias: -2.747187, T: 245000, Avg. loss: 2.831101\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 491\n",
      "Norm: 2004.70, NNZs: 2, Bias: -2.720678, T: 245500, Avg. loss: 2.805931\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 492\n",
      "Norm: 2004.70, NNZs: 2, Bias: -2.694858, T: 246000, Avg. loss: 2.796981\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 493\n",
      "Norm: 2004.73, NNZs: 2, Bias: -2.667871, T: 246500, Avg. loss: 2.804461\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 494\n",
      "Norm: 2004.70, NNZs: 2, Bias: -2.642299, T: 247000, Avg. loss: 2.819408\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 495\n",
      "Norm: 2004.72, NNZs: 2, Bias: -2.616052, T: 247500, Avg. loss: 2.828566\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 496\n",
      "Norm: 2004.70, NNZs: 2, Bias: -2.590356, T: 248000, Avg. loss: 2.771771\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 497\n",
      "Norm: 2004.73, NNZs: 2, Bias: -2.564740, T: 248500, Avg. loss: 2.791386\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 498\n",
      "Norm: 2004.72, NNZs: 2, Bias: -2.539053, T: 249000, Avg. loss: 2.692913\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 499\n",
      "Norm: 2004.72, NNZs: 2, Bias: -2.513481, T: 249500, Avg. loss: 2.730534\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 500\n",
      "Norm: 2004.75, NNZs: 2, Bias: -2.488563, T: 250000, Avg. loss: 2.735781\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 501\n",
      "Norm: 2004.74, NNZs: 2, Bias: -2.463935, T: 250500, Avg. loss: 2.702437\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 502\n",
      "Norm: 2004.73, NNZs: 2, Bias: -2.439098, T: 251000, Avg. loss: 2.761844\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 503\n",
      "Norm: 2004.74, NNZs: 2, Bias: -2.413818, T: 251500, Avg. loss: 2.700074\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 504\n",
      "Norm: 2004.73, NNZs: 2, Bias: -2.388987, T: 252000, Avg. loss: 2.630614\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 505\n",
      "Norm: 2004.73, NNZs: 2, Bias: -2.363456, T: 252500, Avg. loss: 2.589719\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 506\n",
      "Norm: 2004.74, NNZs: 2, Bias: -2.339690, T: 253000, Avg. loss: 2.637637\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 507\n",
      "Norm: 2004.72, NNZs: 2, Bias: -2.314344, T: 253500, Avg. loss: 2.561877\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 508\n",
      "Norm: 2004.75, NNZs: 2, Bias: -2.289783, T: 254000, Avg. loss: 2.578027\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 509\n",
      "Norm: 2004.73, NNZs: 2, Bias: -2.264907, T: 254500, Avg. loss: 2.546005\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 510\n",
      "Norm: 2004.72, NNZs: 2, Bias: -2.240328, T: 255000, Avg. loss: 2.560101\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 511\n",
      "Norm: 2004.73, NNZs: 2, Bias: -2.217164, T: 255500, Avg. loss: 2.510300\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 512\n",
      "Norm: 2004.72, NNZs: 2, Bias: -2.193403, T: 256000, Avg. loss: 2.510073\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 513\n",
      "Norm: 2004.72, NNZs: 2, Bias: -2.170487, T: 256500, Avg. loss: 2.560475\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 514\n",
      "Norm: 2004.72, NNZs: 2, Bias: -2.147241, T: 257000, Avg. loss: 2.469947\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 515\n",
      "Norm: 2004.74, NNZs: 2, Bias: -2.123899, T: 257500, Avg. loss: 2.463829\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 516\n",
      "Norm: 2004.75, NNZs: 2, Bias: -2.100886, T: 258000, Avg. loss: 2.466879\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 517\n",
      "Norm: 2004.74, NNZs: 2, Bias: -2.079020, T: 258500, Avg. loss: 2.524172\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 518\n",
      "Norm: 2004.75, NNZs: 2, Bias: -2.055090, T: 259000, Avg. loss: 2.418785\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 519\n",
      "Norm: 2004.75, NNZs: 2, Bias: -2.031857, T: 259500, Avg. loss: 2.440180\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 520\n",
      "Norm: 2004.73, NNZs: 2, Bias: -2.008909, T: 260000, Avg. loss: 2.391598\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 521\n",
      "Norm: 2004.73, NNZs: 2, Bias: -1.984967, T: 260500, Avg. loss: 2.388802\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 522\n",
      "Norm: 2004.75, NNZs: 2, Bias: -1.962601, T: 261000, Avg. loss: 2.402881\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 523\n",
      "Norm: 2004.74, NNZs: 2, Bias: -1.941218, T: 261500, Avg. loss: 2.390678\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 524\n",
      "Norm: 2004.74, NNZs: 2, Bias: -1.918742, T: 262000, Avg. loss: 2.367802\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 525\n",
      "Norm: 2004.76, NNZs: 2, Bias: -1.897001, T: 262500, Avg. loss: 2.370666\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 526\n",
      "Norm: 2004.74, NNZs: 2, Bias: -1.875074, T: 263000, Avg. loss: 2.374444\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 527\n",
      "Norm: 2004.73, NNZs: 2, Bias: -1.852588, T: 263500, Avg. loss: 2.297707\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 528\n",
      "Norm: 2004.74, NNZs: 2, Bias: -1.830899, T: 264000, Avg. loss: 2.337516\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 529\n",
      "Norm: 2004.75, NNZs: 2, Bias: -1.808367, T: 264500, Avg. loss: 2.276666\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 530\n",
      "Norm: 2004.76, NNZs: 2, Bias: -1.786763, T: 265000, Avg. loss: 2.228753\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 531\n",
      "Norm: 2004.74, NNZs: 2, Bias: -1.765397, T: 265500, Avg. loss: 2.228259\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 532\n",
      "Norm: 2004.76, NNZs: 2, Bias: -1.742183, T: 266000, Avg. loss: 2.209787\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 533\n",
      "Norm: 2004.78, NNZs: 2, Bias: -1.720167, T: 266500, Avg. loss: 2.256409\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 534\n",
      "Norm: 2004.76, NNZs: 2, Bias: -1.699198, T: 267000, Avg. loss: 2.214062\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 535\n",
      "Norm: 2004.75, NNZs: 2, Bias: -1.679057, T: 267500, Avg. loss: 2.260928\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 536\n",
      "Norm: 2004.73, NNZs: 2, Bias: -1.658376, T: 268000, Avg. loss: 2.115009\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 537\n",
      "Norm: 2004.74, NNZs: 2, Bias: -1.637064, T: 268500, Avg. loss: 2.152254\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 538\n",
      "Norm: 2004.75, NNZs: 2, Bias: -1.616261, T: 269000, Avg. loss: 2.219299\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 539\n",
      "Norm: 2004.75, NNZs: 2, Bias: -1.596064, T: 269500, Avg. loss: 2.125292\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 540\n",
      "Norm: 2004.76, NNZs: 2, Bias: -1.575766, T: 270000, Avg. loss: 2.228866\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 541\n",
      "Norm: 2004.75, NNZs: 2, Bias: -1.554643, T: 270500, Avg. loss: 2.149514\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 542\n",
      "Norm: 2004.76, NNZs: 2, Bias: -1.534312, T: 271000, Avg. loss: 2.154917\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 543\n",
      "Norm: 2004.77, NNZs: 2, Bias: -1.515173, T: 271500, Avg. loss: 2.121506\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 544\n",
      "Norm: 2004.74, NNZs: 2, Bias: -1.495284, T: 272000, Avg. loss: 2.163813\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 545\n",
      "Norm: 2004.76, NNZs: 2, Bias: -1.474655, T: 272500, Avg. loss: 2.121658\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 546\n",
      "Norm: 2004.75, NNZs: 2, Bias: -1.454577, T: 273000, Avg. loss: 2.045260\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 547\n",
      "Norm: 2004.75, NNZs: 2, Bias: -1.433660, T: 273500, Avg. loss: 2.095074\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 548\n",
      "Norm: 2004.75, NNZs: 2, Bias: -1.413637, T: 274000, Avg. loss: 2.089824\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 549\n",
      "Norm: 2004.76, NNZs: 2, Bias: -1.394412, T: 274500, Avg. loss: 2.129003\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 550\n",
      "Norm: 2004.75, NNZs: 2, Bias: -1.375473, T: 275000, Avg. loss: 2.109095\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 551\n",
      "Norm: 2004.75, NNZs: 2, Bias: -1.355875, T: 275500, Avg. loss: 2.014407\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 552\n",
      "Norm: 2004.76, NNZs: 2, Bias: -1.336665, T: 276000, Avg. loss: 2.072230\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 553\n",
      "Norm: 2004.76, NNZs: 2, Bias: -1.317719, T: 276500, Avg. loss: 1.985448\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 554\n",
      "Norm: 2004.78, NNZs: 2, Bias: -1.298330, T: 277000, Avg. loss: 2.030441\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 555\n",
      "Norm: 2004.75, NNZs: 2, Bias: -1.279360, T: 277500, Avg. loss: 2.015979\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 556\n",
      "Norm: 2004.77, NNZs: 2, Bias: -1.260195, T: 278000, Avg. loss: 2.021877\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 557\n",
      "Norm: 2004.73, NNZs: 2, Bias: -1.242606, T: 278500, Avg. loss: 1.991321\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 558\n",
      "Norm: 2004.79, NNZs: 2, Bias: -1.221441, T: 279000, Avg. loss: 2.000987\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 2004.75, NNZs: 2, Bias: -1.204036, T: 279500, Avg. loss: 1.969064\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 560\n",
      "Norm: 2004.77, NNZs: 2, Bias: -1.184208, T: 280000, Avg. loss: 1.917576\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 561\n",
      "Norm: 2004.77, NNZs: 2, Bias: -1.165717, T: 280500, Avg. loss: 1.972345\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 562\n",
      "Norm: 2004.79, NNZs: 2, Bias: -1.146689, T: 281000, Avg. loss: 1.917507\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 563\n",
      "Norm: 2004.79, NNZs: 2, Bias: -1.128243, T: 281500, Avg. loss: 1.907594\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 564\n",
      "Norm: 2004.77, NNZs: 2, Bias: -1.110382, T: 282000, Avg. loss: 1.962328\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 565\n",
      "Norm: 2004.75, NNZs: 2, Bias: -1.091268, T: 282500, Avg. loss: 1.883180\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 566\n",
      "Norm: 2004.77, NNZs: 2, Bias: -1.073368, T: 283000, Avg. loss: 1.959379\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 567\n",
      "Norm: 2004.76, NNZs: 2, Bias: -1.055096, T: 283500, Avg. loss: 1.929218\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 568\n",
      "Norm: 2004.76, NNZs: 2, Bias: -1.037244, T: 284000, Avg. loss: 1.874795\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 569\n",
      "Norm: 2004.81, NNZs: 2, Bias: -1.018979, T: 284500, Avg. loss: 1.899931\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 570\n",
      "Norm: 2004.75, NNZs: 2, Bias: -1.002537, T: 285000, Avg. loss: 1.903684\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 571\n",
      "Norm: 2004.76, NNZs: 2, Bias: -0.984361, T: 285500, Avg. loss: 1.838915\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 572\n",
      "Norm: 2004.77, NNZs: 2, Bias: -0.967679, T: 286000, Avg. loss: 1.937477\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 573\n",
      "Norm: 2004.78, NNZs: 2, Bias: -0.950252, T: 286500, Avg. loss: 1.866344\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 574\n",
      "Norm: 2004.76, NNZs: 2, Bias: -0.932940, T: 287000, Avg. loss: 1.847071\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 575\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.915239, T: 287500, Avg. loss: 1.836360\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 576\n",
      "Norm: 2004.77, NNZs: 2, Bias: -0.899414, T: 288000, Avg. loss: 1.859364\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 577\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.882267, T: 288500, Avg. loss: 1.817263\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 578\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.864179, T: 289000, Avg. loss: 1.832871\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 579\n",
      "Norm: 2004.77, NNZs: 2, Bias: -0.848513, T: 289500, Avg. loss: 1.811483\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 580\n",
      "Norm: 2004.77, NNZs: 2, Bias: -0.831148, T: 290000, Avg. loss: 1.817638\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 581\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.814929, T: 290500, Avg. loss: 1.799183\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 582\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.799512, T: 291000, Avg. loss: 1.788547\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 583\n",
      "Norm: 2004.78, NNZs: 2, Bias: -0.784063, T: 291500, Avg. loss: 1.815711\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 584\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.767996, T: 292000, Avg. loss: 1.768936\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 585\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.752259, T: 292500, Avg. loss: 1.806231\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 586\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.737399, T: 293000, Avg. loss: 1.817468\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 587\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.721584, T: 293500, Avg. loss: 1.785443\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 588\n",
      "Norm: 2004.78, NNZs: 2, Bias: -0.704947, T: 294000, Avg. loss: 1.785289\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 589\n",
      "Norm: 2004.78, NNZs: 2, Bias: -0.689341, T: 294500, Avg. loss: 1.782360\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 590\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.673428, T: 295000, Avg. loss: 1.784887\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 591\n",
      "Norm: 2004.78, NNZs: 2, Bias: -0.657596, T: 295500, Avg. loss: 1.780329\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 592\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.640789, T: 296000, Avg. loss: 1.734359\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 593\n",
      "Norm: 2004.78, NNZs: 2, Bias: -0.626107, T: 296500, Avg. loss: 1.766509\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 594\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.609883, T: 297000, Avg. loss: 1.692059\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 595\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.594383, T: 297500, Avg. loss: 1.715567\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 596\n",
      "Norm: 2004.81, NNZs: 2, Bias: -0.578256, T: 298000, Avg. loss: 1.696963\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 597\n",
      "Norm: 2004.81, NNZs: 2, Bias: -0.562459, T: 298500, Avg. loss: 1.692530\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 598\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.547408, T: 299000, Avg. loss: 1.691797\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 599\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.531427, T: 299500, Avg. loss: 1.695672\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 600\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.518164, T: 300000, Avg. loss: 1.723060\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 601\n",
      "Norm: 2004.78, NNZs: 2, Bias: -0.503792, T: 300500, Avg. loss: 1.647509\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 602\n",
      "Norm: 2004.81, NNZs: 2, Bias: -0.488400, T: 301000, Avg. loss: 1.658046\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 603\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.473605, T: 301500, Avg. loss: 1.713599\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 604\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.459866, T: 302000, Avg. loss: 1.671925\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 605\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.444625, T: 302500, Avg. loss: 1.671940\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 606\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.430494, T: 303000, Avg. loss: 1.657118\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 607\n",
      "Norm: 2004.81, NNZs: 2, Bias: -0.415724, T: 303500, Avg. loss: 1.637043\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 608\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.401596, T: 304000, Avg. loss: 1.680025\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 609\n",
      "Norm: 2004.81, NNZs: 2, Bias: -0.386849, T: 304500, Avg. loss: 1.635278\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 610\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.372118, T: 305000, Avg. loss: 1.638148\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 611\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.357396, T: 305500, Avg. loss: 1.587835\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 612\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.343744, T: 306000, Avg. loss: 1.617378\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 613\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.330084, T: 306500, Avg. loss: 1.616112\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 614\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.316283, T: 307000, Avg. loss: 1.607740\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 615\n",
      "Norm: 2004.82, NNZs: 2, Bias: -0.301705, T: 307500, Avg. loss: 1.623936\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 616\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.287689, T: 308000, Avg. loss: 1.606475\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 617\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.273585, T: 308500, Avg. loss: 1.612293\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 618\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.260493, T: 309000, Avg. loss: 1.598910\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 619\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.246412, T: 309500, Avg. loss: 1.587874\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 620\n",
      "Norm: 2004.81, NNZs: 2, Bias: -0.232922, T: 310000, Avg. loss: 1.645414\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 621\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.219095, T: 310500, Avg. loss: 1.578519\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 622\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.205795, T: 311000, Avg. loss: 1.566260\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 623\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.192524, T: 311500, Avg. loss: 1.572938\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 624\n",
      "Norm: 2004.81, NNZs: 2, Bias: -0.178894, T: 312000, Avg. loss: 1.588505\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 625\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.165734, T: 312500, Avg. loss: 1.508874\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 626\n",
      "Norm: 2004.83, NNZs: 2, Bias: -0.151566, T: 313000, Avg. loss: 1.606977\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 627\n",
      "Norm: 2004.81, NNZs: 2, Bias: -0.139338, T: 313500, Avg. loss: 1.582268\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 628\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.125925, T: 314000, Avg. loss: 1.541424\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 629\n",
      "Norm: 2004.83, NNZs: 2, Bias: -0.112406, T: 314500, Avg. loss: 1.553391\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 630\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.098877, T: 315000, Avg. loss: 1.500045\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 631\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.086253, T: 315500, Avg. loss: 1.586250\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 632\n",
      "Norm: 2004.81, NNZs: 2, Bias: -0.072850, T: 316000, Avg. loss: 1.532182\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 633\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.060991, T: 316500, Avg. loss: 1.575061\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 634\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.048165, T: 317000, Avg. loss: 1.546964\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 635\n",
      "Norm: 2004.79, NNZs: 2, Bias: -0.036404, T: 317500, Avg. loss: 1.586368\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 636\n",
      "Norm: 2004.80, NNZs: 2, Bias: -0.023964, T: 318000, Avg. loss: 1.562659\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 637\n",
      "Norm: 2004.81, NNZs: 2, Bias: -0.010779, T: 318500, Avg. loss: 1.511833\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 638\n",
      "Norm: 2004.78, NNZs: 2, Bias: 0.001161, T: 319000, Avg. loss: 1.475996\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 639\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.013647, T: 319500, Avg. loss: 1.506803\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 640\n",
      "Norm: 2004.81, NNZs: 2, Bias: 0.025909, T: 320000, Avg. loss: 1.469057\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 641\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.037786, T: 320500, Avg. loss: 1.476540\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 642\n",
      "Norm: 2004.81, NNZs: 2, Bias: 0.049992, T: 321000, Avg. loss: 1.491980\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 643\n",
      "Norm: 2004.81, NNZs: 2, Bias: 0.061728, T: 321500, Avg. loss: 1.488687\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 644\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.073439, T: 322000, Avg. loss: 1.480765\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 645\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.085510, T: 322500, Avg. loss: 1.454120\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 646\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.097606, T: 323000, Avg. loss: 1.473959\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 647\n",
      "Norm: 2004.80, NNZs: 2, Bias: 0.109300, T: 323500, Avg. loss: 1.490286\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 648\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.120420, T: 324000, Avg. loss: 1.473711\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 649\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.132177, T: 324500, Avg. loss: 1.483206\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 650\n",
      "Norm: 2004.81, NNZs: 2, Bias: 0.142724, T: 325000, Avg. loss: 1.476077\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 651\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.154859, T: 325500, Avg. loss: 1.503528\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 652\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.166524, T: 326000, Avg. loss: 1.443969\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 653\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.179165, T: 326500, Avg. loss: 1.465466\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 654\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.190358, T: 327000, Avg. loss: 1.453971\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 655\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.201306, T: 327500, Avg. loss: 1.422069\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 656\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.213048, T: 328000, Avg. loss: 1.476585\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 657\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.223447, T: 328500, Avg. loss: 1.433065\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 658\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.234434, T: 329000, Avg. loss: 1.475036\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 659\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.245680, T: 329500, Avg. loss: 1.443430\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 660\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.256911, T: 330000, Avg. loss: 1.434672\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 661\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.268798, T: 330500, Avg. loss: 1.448254\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 662\n",
      "Norm: 2004.80, NNZs: 2, Bias: 0.279584, T: 331000, Avg. loss: 1.441171\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 663\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.290922, T: 331500, Avg. loss: 1.422136\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 664\n",
      "Norm: 2004.81, NNZs: 2, Bias: 0.301795, T: 332000, Avg. loss: 1.408365\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 665\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.312619, T: 332500, Avg. loss: 1.401988\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 666\n",
      "Norm: 2004.81, NNZs: 2, Bias: 0.323621, T: 333000, Avg. loss: 1.417966\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 667\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.334226, T: 333500, Avg. loss: 1.385675\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 668\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.345765, T: 334000, Avg. loss: 1.361604\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 669\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.355869, T: 334500, Avg. loss: 1.411998\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 670\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.367050, T: 335000, Avg. loss: 1.417090\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 671\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.376602, T: 335500, Avg. loss: 1.377705\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 672\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.387644, T: 336000, Avg. loss: 1.360341\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 673\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.397536, T: 336500, Avg. loss: 1.389449\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 674\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.407488, T: 337000, Avg. loss: 1.414144\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 675\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.417504, T: 337500, Avg. loss: 1.375315\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 676\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.427855, T: 338000, Avg. loss: 1.368219\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 677\n",
      "Norm: 2004.80, NNZs: 2, Bias: 0.437078, T: 338500, Avg. loss: 1.392509\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 678\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.447754, T: 339000, Avg. loss: 1.352073\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 679\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.457910, T: 339500, Avg. loss: 1.370591\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 680\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.467450, T: 340000, Avg. loss: 1.370391\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 681\n",
      "Norm: 2004.81, NNZs: 2, Bias: 0.477135, T: 340500, Avg. loss: 1.394555\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 682\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.487228, T: 341000, Avg. loss: 1.348315\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 683\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.497390, T: 341500, Avg. loss: 1.354555\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 684\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.506694, T: 342000, Avg. loss: 1.397989\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 685\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.515888, T: 342500, Avg. loss: 1.345772\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 686\n",
      "Norm: 2004.85, NNZs: 2, Bias: 0.526240, T: 343000, Avg. loss: 1.390580\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 687\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.535029, T: 343500, Avg. loss: 1.402118\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 688\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.544460, T: 344000, Avg. loss: 1.348511\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 689\n",
      "Norm: 2004.86, NNZs: 2, Bias: 0.554529, T: 344500, Avg. loss: 1.340268\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 690\n",
      "Norm: 2004.85, NNZs: 2, Bias: 0.564051, T: 345000, Avg. loss: 1.327283\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 691\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.573023, T: 345500, Avg. loss: 1.334188\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 692\n",
      "Norm: 2004.85, NNZs: 2, Bias: 0.582446, T: 346000, Avg. loss: 1.309962\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 693\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.591168, T: 346500, Avg. loss: 1.379942\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 694\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.600517, T: 347000, Avg. loss: 1.305240\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 695\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.610164, T: 347500, Avg. loss: 1.328794\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 696\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.619894, T: 348000, Avg. loss: 1.322572\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 697\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.628284, T: 348500, Avg. loss: 1.304026\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 698\n",
      "Norm: 2004.81, NNZs: 2, Bias: 0.636989, T: 349000, Avg. loss: 1.362786\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 699\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.646331, T: 349500, Avg. loss: 1.337142\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 700\n",
      "Norm: 2004.81, NNZs: 2, Bias: 0.655309, T: 350000, Avg. loss: 1.328765\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 701\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.666067, T: 350500, Avg. loss: 1.344830\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 702\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.674036, T: 351000, Avg. loss: 1.315785\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 703\n",
      "Norm: 2004.85, NNZs: 2, Bias: 0.682723, T: 351500, Avg. loss: 1.363623\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 704\n",
      "Norm: 2004.85, NNZs: 2, Bias: 0.690893, T: 352000, Avg. loss: 1.262045\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 705\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.699798, T: 352500, Avg. loss: 1.312119\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 706\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.709115, T: 353000, Avg. loss: 1.309508\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 707\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.719025, T: 353500, Avg. loss: 1.302133\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 708\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.727812, T: 354000, Avg. loss: 1.343182\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 709\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.735894, T: 354500, Avg. loss: 1.289897\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 710\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.743737, T: 355000, Avg. loss: 1.326905\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 711\n",
      "Norm: 2004.85, NNZs: 2, Bias: 0.751802, T: 355500, Avg. loss: 1.335918\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 712\n",
      "Norm: 2004.85, NNZs: 2, Bias: 0.759999, T: 356000, Avg. loss: 1.320618\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 713\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.767592, T: 356500, Avg. loss: 1.336307\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 714\n",
      "Norm: 2004.85, NNZs: 2, Bias: 0.775721, T: 357000, Avg. loss: 1.298964\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 715\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.783667, T: 357500, Avg. loss: 1.310450\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 716\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.792092, T: 358000, Avg. loss: 1.327102\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 717\n",
      "Norm: 2004.86, NNZs: 2, Bias: 0.800346, T: 358500, Avg. loss: 1.285385\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 718\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.809120, T: 359000, Avg. loss: 1.316287\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 719\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.818169, T: 359500, Avg. loss: 1.241110\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 720\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.826552, T: 360000, Avg. loss: 1.264875\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 721\n",
      "Norm: 2004.85, NNZs: 2, Bias: 0.834291, T: 360500, Avg. loss: 1.300997\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 722\n",
      "Norm: 2004.86, NNZs: 2, Bias: 0.841783, T: 361000, Avg. loss: 1.257475\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 723\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.849331, T: 361500, Avg. loss: 1.285665\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 724\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.857433, T: 362000, Avg. loss: 1.284310\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 725\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.864805, T: 362500, Avg. loss: 1.289476\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 726\n",
      "Norm: 2004.85, NNZs: 2, Bias: 0.873196, T: 363000, Avg. loss: 1.265586\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 727\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.879192, T: 363500, Avg. loss: 1.270544\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 728\n",
      "Norm: 2004.85, NNZs: 2, Bias: 0.887621, T: 364000, Avg. loss: 1.313263\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 729\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.895649, T: 364500, Avg. loss: 1.217879\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 730\n",
      "Norm: 2004.85, NNZs: 2, Bias: 0.902972, T: 365000, Avg. loss: 1.292003\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 731\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.910302, T: 365500, Avg. loss: 1.246637\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 732\n",
      "Norm: 2004.85, NNZs: 2, Bias: 0.918804, T: 366000, Avg. loss: 1.281912\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 733\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.926220, T: 366500, Avg. loss: 1.276742\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 734\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.933339, T: 367000, Avg. loss: 1.277166\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 735\n",
      "Norm: 2004.82, NNZs: 2, Bias: 0.940109, T: 367500, Avg. loss: 1.267271\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 736\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.947779, T: 368000, Avg. loss: 1.307963\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 737\n",
      "Norm: 2004.83, NNZs: 2, Bias: 0.955679, T: 368500, Avg. loss: 1.257712\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 738\n",
      "Norm: 2004.87, NNZs: 2, Bias: 0.963142, T: 369000, Avg. loss: 1.230831\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 739\n",
      "Norm: 2004.86, NNZs: 2, Bias: 0.969967, T: 369500, Avg. loss: 1.291322\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 740\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.976613, T: 370000, Avg. loss: 1.267960\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 741\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.984280, T: 370500, Avg. loss: 1.246310\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 742\n",
      "Norm: 2004.84, NNZs: 2, Bias: 0.991633, T: 371000, Avg. loss: 1.265517\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 743\n",
      "Norm: 2004.86, NNZs: 2, Bias: 0.999309, T: 371500, Avg. loss: 1.236884\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 744\n",
      "Norm: 2004.83, NNZs: 2, Bias: 1.005754, T: 372000, Avg. loss: 1.219144\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 745\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.012289, T: 372500, Avg. loss: 1.280977\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 746\n",
      "Norm: 2004.84, NNZs: 2, Bias: 1.019141, T: 373000, Avg. loss: 1.228872\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 747\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.026095, T: 373500, Avg. loss: 1.278875\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 748\n",
      "Norm: 2004.83, NNZs: 2, Bias: 1.032143, T: 374000, Avg. loss: 1.234160\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 749\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.039694, T: 374500, Avg. loss: 1.274330\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 750\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.046487, T: 375000, Avg. loss: 1.243728\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 751\n",
      "Norm: 2004.83, NNZs: 2, Bias: 1.053349, T: 375500, Avg. loss: 1.223586\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 2004.87, NNZs: 2, Bias: 1.060621, T: 376000, Avg. loss: 1.287707\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 753\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.067248, T: 376500, Avg. loss: 1.243783\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 754\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.074030, T: 377000, Avg. loss: 1.232833\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 755\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.081294, T: 377500, Avg. loss: 1.264187\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 756\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.087407, T: 378000, Avg. loss: 1.242126\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 757\n",
      "Norm: 2004.84, NNZs: 2, Bias: 1.094895, T: 378500, Avg. loss: 1.190232\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 758\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.102170, T: 379000, Avg. loss: 1.253499\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 759\n",
      "Norm: 2004.82, NNZs: 2, Bias: 1.107727, T: 379500, Avg. loss: 1.247513\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 760\n",
      "Norm: 2004.83, NNZs: 2, Bias: 1.114121, T: 380000, Avg. loss: 1.250486\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 761\n",
      "Norm: 2004.83, NNZs: 2, Bias: 1.119680, T: 380500, Avg. loss: 1.252229\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 762\n",
      "Norm: 2004.84, NNZs: 2, Bias: 1.126649, T: 381000, Avg. loss: 1.245308\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 763\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.133279, T: 381500, Avg. loss: 1.269569\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 764\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.140227, T: 382000, Avg. loss: 1.239020\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 765\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.146663, T: 382500, Avg. loss: 1.223179\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 766\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.152724, T: 383000, Avg. loss: 1.243264\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 767\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.159535, T: 383500, Avg. loss: 1.198828\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 768\n",
      "Norm: 2004.84, NNZs: 2, Bias: 1.164829, T: 384000, Avg. loss: 1.227316\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 769\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.171547, T: 384500, Avg. loss: 1.212705\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 770\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.177645, T: 385000, Avg. loss: 1.187846\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 771\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.183453, T: 385500, Avg. loss: 1.260124\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 772\n",
      "Norm: 2004.84, NNZs: 2, Bias: 1.189189, T: 386000, Avg. loss: 1.193945\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 773\n",
      "Norm: 2004.84, NNZs: 2, Bias: 1.195670, T: 386500, Avg. loss: 1.196867\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 774\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.201204, T: 387000, Avg. loss: 1.250516\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 775\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.207326, T: 387500, Avg. loss: 1.240236\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 776\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.213377, T: 388000, Avg. loss: 1.264303\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 777\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.219908, T: 388500, Avg. loss: 1.225436\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 778\n",
      "Norm: 2004.84, NNZs: 2, Bias: 1.225336, T: 389000, Avg. loss: 1.245118\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 779\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.232434, T: 389500, Avg. loss: 1.204886\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 780\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.238012, T: 390000, Avg. loss: 1.227143\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 781\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.243738, T: 390500, Avg. loss: 1.211531\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 782\n",
      "Norm: 2004.84, NNZs: 2, Bias: 1.249580, T: 391000, Avg. loss: 1.197023\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 783\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.255578, T: 391500, Avg. loss: 1.247040\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 784\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.261163, T: 392000, Avg. loss: 1.265128\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 785\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.267364, T: 392500, Avg. loss: 1.173764\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 786\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.273181, T: 393000, Avg. loss: 1.200565\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 787\n",
      "Norm: 2004.84, NNZs: 2, Bias: 1.279002, T: 393500, Avg. loss: 1.226073\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 788\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.284666, T: 394000, Avg. loss: 1.220780\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 789\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.290062, T: 394500, Avg. loss: 1.193960\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 790\n",
      "Norm: 2004.84, NNZs: 2, Bias: 1.295832, T: 395000, Avg. loss: 1.213884\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 791\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.302295, T: 395500, Avg. loss: 1.192803\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 792\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.306789, T: 396000, Avg. loss: 1.195434\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 793\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.312240, T: 396500, Avg. loss: 1.160693\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 794\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.317594, T: 397000, Avg. loss: 1.196158\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 795\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.322386, T: 397500, Avg. loss: 1.236780\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 796\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.326442, T: 398000, Avg. loss: 1.208042\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 797\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.331481, T: 398500, Avg. loss: 1.191333\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 798\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.337742, T: 399000, Avg. loss: 1.177276\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 799\n",
      "Norm: 2004.84, NNZs: 2, Bias: 1.342565, T: 399500, Avg. loss: 1.195994\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 800\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.348075, T: 400000, Avg. loss: 1.182033\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 801\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.354311, T: 400500, Avg. loss: 1.198829\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 802\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.360104, T: 401000, Avg. loss: 1.209219\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 803\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.364807, T: 401500, Avg. loss: 1.200186\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 804\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.369987, T: 402000, Avg. loss: 1.177911\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 805\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.375373, T: 402500, Avg. loss: 1.177227\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 806\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.380895, T: 403000, Avg. loss: 1.185063\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 807\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.385935, T: 403500, Avg. loss: 1.198239\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 808\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.391708, T: 404000, Avg. loss: 1.191155\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 809\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.396271, T: 404500, Avg. loss: 1.226360\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 810\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.400674, T: 405000, Avg. loss: 1.182607\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 811\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.405088, T: 405500, Avg. loss: 1.183064\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 812\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.410058, T: 406000, Avg. loss: 1.178478\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 813\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.415561, T: 406500, Avg. loss: 1.186197\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 814\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.419882, T: 407000, Avg. loss: 1.151689\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 815\n",
      "Norm: 2004.89, NNZs: 2, Bias: 1.425075, T: 407500, Avg. loss: 1.201494\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 816\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.429746, T: 408000, Avg. loss: 1.161397\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 817\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.434141, T: 408500, Avg. loss: 1.186977\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 818\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.438327, T: 409000, Avg. loss: 1.204819\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 819\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.443646, T: 409500, Avg. loss: 1.183676\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 820\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.447682, T: 410000, Avg. loss: 1.212260\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 821\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.452546, T: 410500, Avg. loss: 1.182796\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 822\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.457568, T: 411000, Avg. loss: 1.114203\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 823\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.462491, T: 411500, Avg. loss: 1.188271\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 824\n",
      "Norm: 2004.84, NNZs: 2, Bias: 1.467805, T: 412000, Avg. loss: 1.190050\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 825\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.472545, T: 412500, Avg. loss: 1.199614\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 826\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.477234, T: 413000, Avg. loss: 1.198133\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 827\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.481537, T: 413500, Avg. loss: 1.167706\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 828\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.485824, T: 414000, Avg. loss: 1.151888\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 829\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.491108, T: 414500, Avg. loss: 1.182161\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 830\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.495720, T: 415000, Avg. loss: 1.176116\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 831\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.499719, T: 415500, Avg. loss: 1.185933\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 832\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.504806, T: 416000, Avg. loss: 1.179670\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 833\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.508982, T: 416500, Avg. loss: 1.206191\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 834\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.513103, T: 417000, Avg. loss: 1.177249\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 835\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.517288, T: 417500, Avg. loss: 1.202731\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 836\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.522349, T: 418000, Avg. loss: 1.191032\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 837\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.526482, T: 418500, Avg. loss: 1.141978\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 838\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.530313, T: 419000, Avg. loss: 1.196714\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 839\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.534358, T: 419500, Avg. loss: 1.151558\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 840\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.537874, T: 420000, Avg. loss: 1.142524\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 841\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.541793, T: 420500, Avg. loss: 1.187127\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 842\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.546025, T: 421000, Avg. loss: 1.152873\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 843\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.550956, T: 421500, Avg. loss: 1.116264\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 844\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.554966, T: 422000, Avg. loss: 1.149825\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 845\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.559301, T: 422500, Avg. loss: 1.147364\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 846\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.563153, T: 423000, Avg. loss: 1.189896\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 847\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.568500, T: 423500, Avg. loss: 1.142850\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 848\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.572477, T: 424000, Avg. loss: 1.172874\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 849\n",
      "Norm: 2004.89, NNZs: 2, Bias: 1.577198, T: 424500, Avg. loss: 1.175191\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 850\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.580427, T: 425000, Avg. loss: 1.156081\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 851\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.583842, T: 425500, Avg. loss: 1.183058\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 852\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.588344, T: 426000, Avg. loss: 1.153017\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 853\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.592195, T: 426500, Avg. loss: 1.148839\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 854\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.597241, T: 427000, Avg. loss: 1.159807\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 855\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.601166, T: 427500, Avg. loss: 1.161445\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 856\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.603909, T: 428000, Avg. loss: 1.201648\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 857\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.608157, T: 428500, Avg. loss: 1.135445\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 858\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.611802, T: 429000, Avg. loss: 1.200732\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 859\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.615449, T: 429500, Avg. loss: 1.192359\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 860\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.619473, T: 430000, Avg. loss: 1.144999\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 861\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.623589, T: 430500, Avg. loss: 1.198062\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 862\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.627445, T: 431000, Avg. loss: 1.173049\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 863\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.631364, T: 431500, Avg. loss: 1.165755\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 864\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.635173, T: 432000, Avg. loss: 1.205937\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 865\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.639000, T: 432500, Avg. loss: 1.149138\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 866\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.642707, T: 433000, Avg. loss: 1.173609\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 867\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.646495, T: 433500, Avg. loss: 1.130313\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 868\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.650354, T: 434000, Avg. loss: 1.149448\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 869\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.653872, T: 434500, Avg. loss: 1.142411\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 870\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.657105, T: 435000, Avg. loss: 1.163634\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 871\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.660009, T: 435500, Avg. loss: 1.181947\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 872\n",
      "Norm: 2004.89, NNZs: 2, Bias: 1.664953, T: 436000, Avg. loss: 1.189858\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 873\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.668612, T: 436500, Avg. loss: 1.156711\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 874\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.672301, T: 437000, Avg. loss: 1.176062\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 875\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.675877, T: 437500, Avg. loss: 1.164119\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 876\n",
      "Norm: 2004.89, NNZs: 2, Bias: 1.679319, T: 438000, Avg. loss: 1.143018\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 877\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.682546, T: 438500, Avg. loss: 1.157259\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 878\n",
      "Norm: 2004.89, NNZs: 2, Bias: 1.687426, T: 439000, Avg. loss: 1.161766\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 879\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.690360, T: 439500, Avg. loss: 1.163265\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 880\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.693988, T: 440000, Avg. loss: 1.150847\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 881\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.698109, T: 440500, Avg. loss: 1.165762\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 882\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.701101, T: 441000, Avg. loss: 1.153170\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 883\n",
      "Norm: 2004.89, NNZs: 2, Bias: 1.705962, T: 441500, Avg. loss: 1.113783\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 884\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.709022, T: 442000, Avg. loss: 1.176457\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 885\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.712246, T: 442500, Avg. loss: 1.144637\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 886\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.714927, T: 443000, Avg. loss: 1.215344\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 887\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.717970, T: 443500, Avg. loss: 1.177248\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 888\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.721362, T: 444000, Avg. loss: 1.143049\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 889\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.725058, T: 444500, Avg. loss: 1.131109\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 890\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.728086, T: 445000, Avg. loss: 1.150660\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 891\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.731274, T: 445500, Avg. loss: 1.142160\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 892\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.735236, T: 446000, Avg. loss: 1.207688\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 893\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.738299, T: 446500, Avg. loss: 1.114963\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 894\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.741560, T: 447000, Avg. loss: 1.156995\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 895\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.744222, T: 447500, Avg. loss: 1.175708\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 896\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.746163, T: 448000, Avg. loss: 1.145492\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 897\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.749046, T: 448500, Avg. loss: 1.178122\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 898\n",
      "Norm: 2004.89, NNZs: 2, Bias: 1.751679, T: 449000, Avg. loss: 1.123069\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 899\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.755020, T: 449500, Avg. loss: 1.201840\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 900\n",
      "Norm: 2004.90, NNZs: 2, Bias: 1.758480, T: 450000, Avg. loss: 1.118973\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 901\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.761217, T: 450500, Avg. loss: 1.118768\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 902\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.765045, T: 451000, Avg. loss: 1.164705\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 903\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.768595, T: 451500, Avg. loss: 1.182573\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 904\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.772084, T: 452000, Avg. loss: 1.170869\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 905\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.774405, T: 452500, Avg. loss: 1.152225\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 906\n",
      "Norm: 2004.89, NNZs: 2, Bias: 1.778173, T: 453000, Avg. loss: 1.114314\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 907\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.781257, T: 453500, Avg. loss: 1.169759\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 908\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.784348, T: 454000, Avg. loss: 1.134376\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 909\n",
      "Norm: 2004.89, NNZs: 2, Bias: 1.787659, T: 454500, Avg. loss: 1.140241\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 910\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.790611, T: 455000, Avg. loss: 1.164006\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 911\n",
      "Norm: 2004.89, NNZs: 2, Bias: 1.794343, T: 455500, Avg. loss: 1.138753\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 912\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.797060, T: 456000, Avg. loss: 1.164351\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 913\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.800089, T: 456500, Avg. loss: 1.148265\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 914\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.801905, T: 457000, Avg. loss: 1.149429\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 915\n",
      "Norm: 2004.86, NNZs: 2, Bias: 1.804651, T: 457500, Avg. loss: 1.145332\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 916\n",
      "Norm: 2004.88, NNZs: 2, Bias: 1.807865, T: 458000, Avg. loss: 1.152038\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 917\n",
      "Norm: 2004.89, NNZs: 2, Bias: 1.811496, T: 458500, Avg. loss: 1.135049\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 918\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.813375, T: 459000, Avg. loss: 1.124381\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 919\n",
      "Norm: 2004.87, NNZs: 2, Bias: 1.815733, T: 459500, Avg. loss: 1.190245\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 920\n",
      "Norm: 2004.85, NNZs: 2, Bias: 1.817937, T: 460000, Avg. loss: 1.154564\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 921\n",
      "Norm: 2004.90, NNZs: 2, Bias: 1.821768, T: 460500, Avg. loss: 1.156842\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 922\n",
      "Norm: 2004.90, NNZs: 2, Bias: 1.825625, T: 461000, Avg. loss: 1.174630\n",
      "Total training time: 0.96 seconds.\n",
      "Convergence after 922 epochs took 0.96 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;sgdregressor&#x27;,\n",
       "                 SGDRegressor(eta0=0.0001, learning_rate=&#x27;constant&#x27;,\n",
       "                              n_iter_no_change=100, verbose=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;sgdregressor&#x27;,\n",
       "                 SGDRegressor(eta0=0.0001, learning_rate=&#x27;constant&#x27;,\n",
       "                              n_iter_no_change=100, verbose=1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SGDRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.SGDRegressor.html\">?<span>Documentation for SGDRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SGDRegressor(eta0=0.0001, learning_rate=&#x27;constant&#x27;, n_iter_no_change=100,\n",
       "             verbose=1)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('sgdregressor',\n",
       "                 SGDRegressor(eta0=0.0001, learning_rate='constant',\n",
       "                              n_iter_no_change=100, verbose=1))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = make_pipeline(\n",
    "    SGDRegressor(\n",
    "    max_iter=1000,\n",
    "    n_iter_no_change=100, \n",
    "    penalty='l2', \n",
    "    verbose=1, \n",
    "    learning_rate='constant', eta0=0.0001, \n",
    "    tol=0.001\n",
    "    )\n",
    ")\n",
    "    \n",
    "m.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c72848f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   5.61081179, 2004.88725643])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[0].coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
