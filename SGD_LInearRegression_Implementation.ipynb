{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55fa8fd",
   "metadata": {},
   "source": [
    "# Learning Implementation for Stochastic Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22de211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b171ba73",
   "metadata": {},
   "source": [
    "# Observations:\n",
    "* Reacts better to large bias than BatchGD\n",
    "* Faster maybe\n",
    "* If features have noncompareable sizes then bigger feature gets more weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195ef49",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8150986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_update(i,X,y,y_,W,b,alpha):\n",
    "    m,n = X.shape\n",
    "    dJ_dW = np.zeros(n)\n",
    "    for j in range(n):\n",
    "        dJ_dW[j] += (y[i]-y_[i])*X[i][j]\n",
    "    dJ_db = y[i]-y_[i]\n",
    "    \n",
    "    W += dJ_dW*alpha\n",
    "    b += dJ_db*alpha\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1820eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_LinearRegression(X,y, iterations = 100,alpha = 0.000001):\n",
    "    \"\"\"Returns W,b after updating iterations times\"\"\"\n",
    "    m,n = X.shape\n",
    "    W = np.zeros(n)\n",
    "    b = 0\n",
    "    y_ = np.matmul(X,W) +b\n",
    "    \n",
    "    for k in range(iterations+1):\n",
    "        if k % (iterations//10) == 0:\n",
    "            print(f\"Iteration: {k}\", f\"Cost: {mean_squared_error(y,y_)}\", f\"Weights: {W}\",f\"Bias: {b}\")\n",
    "        #print(f\"Iteration: {k}\", f\"Cost: {mean_squared_error(y,y_)}\", f\"Weights: {W}\",f\"Bias: {b}\")\n",
    "        for i in range(m):\n",
    "            W,b = single_update(i,X,y,y_,W,b,alpha)\n",
    "            y_ = np.matmul(X,W) + b\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eba465",
   "metadata": {},
   "source": [
    "## Running Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a62bdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Cost: 525663.0650666667 Weights: [0.] Bias: 0\n",
      "Iteration: 1000 Cost: 28351.593950798517 Weights: [2.35935707] Bias: -693.0439172436983\n",
      "Iteration: 2000 Cost: 2859.6709774316355 Weights: [4.57079835] Bias: -913.0769410247393\n",
      "Iteration: 3000 Cost: 288.4394476500768 Weights: [5.27313399] Bias: -982.9576272002469\n",
      "Iteration: 4000 Cost: 29.093317244268164 Weights: [5.49619003] Bias: -1005.1511607728299\n",
      "Iteration: 5000 Cost: 2.934484569189197 Weights: [5.5670308] Bias: -1012.1996452596633\n",
      "Iteration: 6000 Cost: 0.2959854874800522 Weights: [5.58952925] Bias: -1014.4381862021597\n",
      "Iteration: 7000 Cost: 0.029854445212339927 Weights: [5.59667458] Bias: -1015.1491284707672\n",
      "Iteration: 8000 Cost: 0.0030112554046548092 Weights: [5.59894387] Bias: -1015.3749179123181\n",
      "Iteration: 9000 Cost: 0.00030372894382764697 Weights: [5.59966458] Bias: -1015.4466267896253\n",
      "Iteration: 10000 Cost: 3.063548551088833e-05 Weights: [5.59989347] Bias: -1015.4694009417278\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[x] for x in np.arange(10,100)])\n",
    "y = np.array([ -1015.48 + x*5.6  for x in np.arange(10,100)])\n",
    "W,b = SGD_LinearRegression(X,y,10000,0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "963ae765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.5998936] -1015.4694130917545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.0565288968276583e-05"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(W,b)\n",
    "pred = np.dot(X ,W) + b\n",
    "mean_squared_error(pred,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd3ce84",
   "metadata": {},
   "source": [
    "! One run after last function output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dead1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Cost: 4556927.95 Weights: [0. 0.] Bias: 0\n",
      "Iteration: 1000 Cost: 5.917599975618974 Weights: [ 4.72036959 -1.99174961] Bias: 0.36172562394409785\n",
      "Iteration: 2000 Cost: 0.030286528972296573 Weights: [ 4.95905841 -1.99912605] Bias: 0.3782625586360989\n",
      "Iteration: 3000 Cost: 0.013238641625326316 Weights: [ 4.97108741 -1.99949613] Bias: 0.37748054865035857\n",
      "Iteration: 4000 Cost: 0.012967020516365448 Weights: [ 4.97180743 -1.99951665] Bias: 0.375841637556848\n",
      "Iteration: 5000 Cost: 0.012845631084885704 Weights: [ 4.9719627  -1.99951972] Bias: 0.37416711201826414\n",
      "Iteration: 6000 Cost: 0.012730976690940038 Weights: [ 4.97208926 -1.99952191] Bias: 0.3724979155435511\n",
      "Iteration: 7000 Cost: 0.012617619697543736 Weights: [ 4.97221385 -1.99952404] Bias: 0.3708360591698918\n",
      "Iteration: 8000 Cost: 0.01250528563967721 Weights: [ 4.97233782 -1.99952616] Bias: 0.36918161167031477\n",
      "Iteration: 9000 Cost: 0.012393952362097005 Weights: [ 4.97246123 -1.99952828] Bias: 0.3675345450558697\n",
      "Iteration: 10000 Cost: 0.012283610306844092 Weights: [ 4.97258409 -1.99953038] Bias: 0.3658948266501949\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[x, x**2] for x in np.random.randint(1,50,100)])\n",
    "y = np.array([5*x - 2*y  for (x,y) in X])\n",
    "W,b = SGD_LinearRegression(X,y,10000,0.0000005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f473abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Cost: 35141.7675 Weights: [0.] Bias: 0\n",
      "Iteration: 1000 Cost: 34.29916708379966 Weights: [5.85342511] Bias: 30.440406820159744\n",
      "Iteration: 2000 Cost: 2.6244709913565423 Weights: [5.59776345] Bias: 38.80241828648585\n",
      "Iteration: 3000 Cost: 0.20081677107949367 Weights: [5.52704305] Bias: 41.11549406146569\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[x] for x in np.random.randint(1,50,100)])\n",
    "y = np.array([5.5*x + 42 for (x,) in X])\n",
    "W,b = SGD_LinearRegression(X,y,10000,0.00005)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
