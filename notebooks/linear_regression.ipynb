{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55fa8fd",
   "metadata": {},
   "source": [
    "# Improved Implementation for Stochastic Linear Regression\n",
    "with regularization.\\\n",
    "with efficiency improvements.\\\n",
    "Recommended to check cost after convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b585703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e22de211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195ef49",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec60f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \"\"\"Linear regression model with L2 regularization.\"\"\"\n",
    "    \n",
    "    DEFAULT_EPOCHS = 1000\n",
    "    DEFAULT_ALPHA = 0.01\n",
    "    DEFAULT_LAMBDA = 0.0001\n",
    "    DEFAULT_ERROR_THRESHOLD = 0.001\n",
    "    DEFAULT_VALIDATION_SIZE = 0.2\n",
    "\n",
    "\n",
    "    def compute_cost(self, y, y_, Lambda, W, m):\n",
    "        \"\"\"Compute cost function with L2 regularization.\"\"\"\n",
    "        return np.mean((y-y_)**2) + ((np.sum(W**2)) * Lambda/(2*m))\n",
    "    \n",
    "    \n",
    "    def validation_split(self, X, y, validation_size=DEFAULT_VALIDATION_SIZE):\n",
    "        \"\"\"Splits X and y into train and validatation set\"\"\"\n",
    "        val = int(X.shape[0] * (1 - validation_size))\n",
    "        return X[:val], y[:val], X[val:], y[val:]\n",
    "    \n",
    "    \n",
    "    def log_current(self, k, num_out, output_limit,cost, vcost, alter=False):\n",
    "        \"\"\"Log current training information. Alter for exit print.\"\"\"\n",
    "        if alter: # For printing at arbitrary epoch, w vCost only\n",
    "            print(f\"       > Epoch: {k}\",\n",
    "                  f\"vCost: {vcost:.8f}\")\n",
    "            return None\n",
    "            \n",
    "        print(f\"({k//num_out}/{output_limit}) > Epoch: {k}\",\n",
    "              f\"cost: {cost:.8f}\",\n",
    "              f\"vCost: {vcost:.8f}\")\n",
    "        \n",
    "    \n",
    "    def convergence_test(self, current_cost, past_cost, error_threshold, k):\n",
    "        # Simple convergence test\n",
    "        if  (past_cost - current_cost <= error_threshold):\n",
    "            self.c+=1\n",
    "            if self.c >= 10:\n",
    "                self.log_current(k=k, num_out=0, output_limit=0, cost=0, vcost=current_cost, alter=True)\n",
    "                print(f\"\\nEpoch {k} > vCost Converged with threshold {error_threshold}. OR Performance degraded.\")\n",
    "                self.EXIT = True # Also returns in case of validation perf degradation (overfit)\n",
    "                \n",
    "        else: \n",
    "            self.c=0 # For counting consecutive iterations of convergence\n",
    "\n",
    "    def single_step(self, Xi, yi, m, W, b, alpha, Lambda):\n",
    "        \"\"\"Perform a single step of gradient descent.\"\"\"\n",
    "        \n",
    "        y_i = np.dot(Xi, W) + b \n",
    "        res = yi - y_i\n",
    "        \n",
    "        dJ_dW = np.dot(res, Xi)  - Lambda * W\n",
    "        dJ_db = res.mean()\n",
    "\n",
    "        W += dJ_dW * alpha / m\n",
    "        b += dJ_db * alpha\n",
    "\n",
    "        return W,b\n",
    "    \n",
    "    def fit(self, X, y,\n",
    "            epochs = DEFAULT_EPOCHS,\n",
    "            alpha = DEFAULT_ALPHA,\n",
    "            Lambda=DEFAULT_LAMBDA,\n",
    "            error_threshold = DEFAULT_ERROR_THRESHOLD,\n",
    "            validation_size = DEFAULT_VALIDATION_SIZE,\n",
    "            output_limit=10):\n",
    "        \"\"\"Fit the linear regression model to the given data.\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        epochs: int, default=1000\n",
    "            Number of complete iterations through X\n",
    "\n",
    "        alpha : float, default=0.01\n",
    "            Constant Learning Rate\n",
    "\n",
    "        Lambda : float, default=0.0001\n",
    "            Rate for l2 Regularization\n",
    "        \n",
    "        error_threshold: float, default=0.001\n",
    "            Threshold for vCost convergence\n",
    "        \n",
    "        validation_size: float, default=0.2\n",
    "            Percent of data for validation, 0 <= vs < 1\n",
    "\n",
    "        output_limit : int, default=10\n",
    "            Number of iterations to show\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        W : numpy.ndarray\n",
    "            The optimized weights.\n",
    "        b : numpy.longdouble\n",
    "            The optimized itercept.\n",
    "        \"\"\"\n",
    " \n",
    "        if output_limit<=0:\n",
    "            raise ValueError(\"Output limit should be greater than 0\")\n",
    "        \n",
    "        num_out = epochs//output_limit\n",
    "        np.set_printoptions(precision=4)\n",
    "        \n",
    "        X, y, X_val, y_val = self.validation_split(X,y, validation_size)\n",
    "        m,n = X.shape\n",
    "        \n",
    "        W = np.random.rand(n)\n",
    "        b = np.random.rand()\n",
    "        \n",
    "        y_ = np.dot(X,W) + b\n",
    "        y_val_ = np.dot(X_val,W) + b\n",
    "\n",
    "        cost = self.compute_cost(y,y_,Lambda,W,m)\n",
    "        past_cost = self.compute_cost(y_val,y_val_,Lambda,W,m)\n",
    "        \n",
    "        self.c=0 # to count convergence for consecutive iterations\n",
    "        self.EXIT = False # Exit flag for convergence\n",
    "        \n",
    "        self.log_current(0, num_out, output_limit, cost, past_cost) # Initial Out\n",
    "\n",
    "        try:\n",
    "            for k in range(1, epochs+1):\n",
    "                # SGD\n",
    "                for i in range(m):\n",
    "                    W,b = self.single_step(X[i], y[i], m, W, b, alpha, Lambda)\n",
    "                # SGD\n",
    "                \n",
    "                \n",
    "                # LOG OUTPUT\n",
    "                if k % num_out == 0:\n",
    "                    y_ = np.dot(X,W) + b\n",
    "                    y_val_ = np.dot(X_val,W) + b\n",
    "                    \n",
    "                    cost = self.compute_cost(y,y_,Lambda,W,m)\n",
    "                    vcost = self.compute_cost(y_val,y_val_,Lambda,W,m)\n",
    "                    \n",
    "                    self.log_current(k, num_out, output_limit, cost, vcost)\n",
    "                # LOG OUTPUT\n",
    "                \n",
    "                \n",
    "                # CONVERGENCE\n",
    "                y_val_ = np.dot(X_val,W) + b\n",
    "                current_cost = self.compute_cost(y_val,y_val_,Lambda,W,m) # vCost\n",
    "                \n",
    "                self.convergence_test(current_cost, past_cost, error_threshold, k)\n",
    "                \n",
    "                if self.EXIT:\n",
    "                    return (W, b)\n",
    "                \n",
    "                past_cost = current_cost\n",
    "                # CONVERGENCE\n",
    "\n",
    "                    \n",
    "        # CTRL C            \n",
    "        except KeyboardInterrupt:\n",
    "            self.log_current(k=k, num_out=0, output_limit=0, cost=0, vcost=current_cost, alter=True)\n",
    "            print(f\"\\nTerminated! Returned: Weights: {W}, Bias: {b}\")\n",
    "            return (W, b)\n",
    "        # CTRL C\n",
    "        \n",
    "        \n",
    "        return (W, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef81f4c",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dce968dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0/10) > Epoch: 0 cost: 3321.12922313 vCost: 3313.17398696\n",
      "(1/10) > Epoch: 100 cost: 0.42088014 vCost: 0.45458323\n",
      "(2/10) > Epoch: 200 cost: 0.01643032 vCost: 0.01774087\n",
      "(3/10) > Epoch: 300 cost: 0.00080804 vCost: 0.00087143\n",
      "       > Epoch: 339 vCost: 0.00031887\n",
      "\n",
      "Epoch 339 > vCost Converged with threshold 1e-05. OR Performance degraded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 5.5352, 11.1625]), 50.036011338322)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LinearRegression()\n",
    "X = np.random.rand(1000,2)\n",
    "y = 5.55*X[:,0] + 11.22*X[:,1] + 50\n",
    "m.fit(X, y ,epochs= 1000, alpha = 0.2, error_threshold = 0.00001, output_limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df39efae",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3213784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17f50fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0/10) > Epoch: 0 cost: 69740.02828327 vCost: 73192.81481812\n",
      "(1/10) > Epoch: 10 cost: 5.38961859 vCost: 6.36190649\n",
      "(2/10) > Epoch: 20 cost: 0.00800590 vCost: 0.00874449\n",
      "       > Epoch: 28 vCost: 0.00509619\n",
      "\n",
      "Epoch 28 > vCost Converged with threshold 0.01. OR Performance degraded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([74.2808,  3.8328, 59.6396,  9.0241, 79.6588, 73.3384, 99.199 ,\n",
       "        21.1876, 29.7783, 39.7521, 85.9187, 16.5606, 93.8983, 90.0927,\n",
       "        35.1949, 69.8429, 30.6432,  7.2502,  7.8456, 63.0211]),\n",
       " 0.002001552437994436)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_regression(n_samples=1000,n_features=20, n_informative=20)\n",
    "m = LinearRegression()\n",
    "m.fit(X, y ,epochs= 100, alpha = 0.5, error_threshold = 0.01, output_limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ef96b0",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7070fa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "488a8b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = fetch_california_housing(return_X_y=True)\n",
    "X = X[:1000]\n",
    "y = y[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19fca112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0/10) > Epoch: 0 cost: 714311.95952983 vCost: 2277008.25312139\n",
      "(1/10) > Epoch: 100 cost: 6.95963769 vCost: 9.48829066\n",
      "(2/10) > Epoch: 200 cost: 3.52168257 vCost: 4.92413118\n",
      "(3/10) > Epoch: 300 cost: 2.55081789 vCost: 3.42121042\n",
      "(4/10) > Epoch: 400 cost: 2.22878181 vCost: 2.83760587\n",
      "(5/10) > Epoch: 500 cost: 2.07992179 vCost: 2.55591369\n",
      "(6/10) > Epoch: 600 cost: 1.97967397 vCost: 2.38571419\n",
      "(7/10) > Epoch: 700 cost: 1.89528935 vCost: 2.26252746\n",
      "       > Epoch: 761 vCost: 2.19934425\n",
      "\n",
      "Epoch 761 > vCost Converged with threshold 0.001. OR Performance degraded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([8.7617e-01, 3.7969e-03, 2.7513e-01, 4.0998e-01, 2.1620e-04,\n",
       "        2.7794e-01, 8.2371e-01, 3.1061e-01]),\n",
       " 2.92644336959984)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LinearRegression()\n",
    "m.fit(X, y ,epochs= 1000, alpha = 0.0001, error_threshold = 1/1000, validation_size=1/3 ,output_limit=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
