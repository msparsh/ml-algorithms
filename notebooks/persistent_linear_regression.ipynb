{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55fa8fd",
   "metadata": {},
   "source": [
    "# Improved Implementation for Stochastic Linear Regression\n",
    "with regularization.\\\n",
    "with efficiency improvements.\\\n",
    "Recommended to check cost after convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22de211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d86b69",
   "metadata": {},
   "source": [
    "* parameter assignment reduced performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195ef49",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec60f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \"\"\"Linear regression model with L2 regularization.\"\"\"\n",
    "    \n",
    "    DEFAULT_EPOCHS = 1000\n",
    "    DEFAULT_ALPHA = 0.01\n",
    "    DEFAULT_LAMBDA = 0.0001\n",
    "    DEFAULT_ERROR_THRESHOLD = 0.001\n",
    "    DEFAULT_VALIDATION_SIZE = 0.2\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def compute_cost(self, y, y_):\n",
    "        \"\"\"Compute cost function with L2 regularization.\"\"\"\n",
    "        return np.mean((y - y_) ** 2) + ((np.sum(self.W ** 2)) * self.Lambda / (2 * self.m))\n",
    "    \n",
    "    \n",
    "    def validation_split(self, X, y):\n",
    "        \"\"\"Splits X and y into train and validatation set\"\"\"\n",
    "        val = int(X.shape[0] * (1 - self.validation_size))\n",
    "        return X[:val], y[:val], X[val:], y[val:]\n",
    "    \n",
    "    \n",
    "    def log_current(self, k, alter=False):\n",
    "        \"\"\"Log current training information. Alter for exit print.\"\"\"\n",
    "        \n",
    "        if alter: # For printing at arbitrary epoch, w vCost only\n",
    "            print(f\"       * Epoch: {k}\",\n",
    "                  f\"vCost: {self.vcost:.8f}\")\n",
    "            return None\n",
    "            \n",
    "        print(f\"({k//self.num_out}/{self.output_limit}) > Epoch: {k}\",\n",
    "              f\"cost: {self.cost:.8f}\",\n",
    "              f\"vCost: {self.vcost:.8f}\")\n",
    "        \n",
    "    \n",
    "    def convergence_test(self, k):\n",
    "        # Simple convergence test\n",
    "        if  (self.last_vcost - self.vcost <= self.error_threshold):\n",
    "            self.c+=1\n",
    "            if self.c >= 10:\n",
    "                self.log_current(k=k, alter=True)\n",
    "                print(f\"\\nEpoch {k} > vCost Converged with threshold {self.error_threshold}. OR Performance degraded.\")\n",
    "                self.EXIT = True # Also returns in case of validation perf degradation (overfit)\n",
    "                \n",
    "        else: # elif c!=0\n",
    "            self.c=0 # For counting consecutive iterations of convergence\n",
    "\n",
    "    def single_step(self, Xi, yi):\n",
    "        \"\"\"Perform a single step of gradient descent.\"\"\"\n",
    "        \n",
    "        y_i = np.dot(Xi, self.W) + self.b \n",
    "        res = yi - y_i\n",
    "        \n",
    "        dJ_dW = np.dot(res, Xi)  - self.Lambda * self.W\n",
    "        dJ_db = res.mean()\n",
    "\n",
    "        self.W += dJ_dW * self.alpha / self.m\n",
    "        self.b += dJ_db * self.alpha\n",
    "        \n",
    "        \n",
    "    \n",
    "    def fit(self, X, y,\n",
    "            epochs = DEFAULT_EPOCHS,\n",
    "            alpha = DEFAULT_ALPHA,\n",
    "            Lambda=DEFAULT_LAMBDA,\n",
    "            error_threshold = DEFAULT_ERROR_THRESHOLD,\n",
    "            val_size = DEFAULT_VALIDATION_SIZE,\n",
    "            output_limit=10):\n",
    "        \"\"\"Fit the linear regression model to the given data.\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        epochs: int, default=1000\n",
    "            Number of complete iterations through X\n",
    "\n",
    "        alpha : float, default=0.01\n",
    "            Constant Learning Rate\n",
    "\n",
    "        Lambda : float, default=0.0001\n",
    "            Rate for l2 Regularization\n",
    "        \n",
    "        error_threshold: float, default=0.001\n",
    "            Threshold for vCost convergence\n",
    "        \n",
    "        validation_size: float, default=0.2\n",
    "            Percent of data for validation, 0 <= vs < 1\n",
    "\n",
    "        output_limit : int, default=10\n",
    "            Number of iterations to show\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        W : numpy.ndarray\n",
    "            The optimized weights.\n",
    "        b : numpy.longdouble\n",
    "            The optimized itercept.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.Lambda = Lambda\n",
    "        self.validation_size = val_size\n",
    "        self.error_threshold = error_threshold\n",
    " \n",
    "        \n",
    "        self.epochs = epochs\n",
    "        self.output_limit = output_limit\n",
    "        if self.output_limit<=0:\n",
    "            raise ValueError(\"Output limit should be greater than 0\")\n",
    "            \n",
    "        self.num_out = self.epochs//self.output_limit\n",
    "        \n",
    "        np.set_printoptions(precision=4)\n",
    "        \n",
    "        X, y, X_val, y_val = self.validation_split(X, y)\n",
    "        self.m, self.n = X.shape\n",
    "        \n",
    "        self.W = np.random.rand(self.n)\n",
    "        self.b = np.random.rand()\n",
    "        \n",
    "        y_ = np.dot(X, self.W) + self.b\n",
    "        y_val_ = np.dot(X_val, self.W) + self.b\n",
    "\n",
    "        self.cost = self.compute_cost(y, y_)\n",
    "        self.vcost = self.compute_cost(y_val, y_val_)\n",
    "        self.last_vcost = self.vcost\n",
    "        \n",
    "        self.c=0 # to count convergence for consecutive iterations\n",
    "        self.EXIT = False # Exit flag for convergence\n",
    "        \n",
    "        self.log_current(0) # Initial Out\n",
    "\n",
    "        try:\n",
    "            for k in range(1, self.epochs+1):\n",
    "                # SGD\n",
    "                for i in range(self.m):\n",
    "                    self.single_step(X[i], y[i])\n",
    "                # SGD\n",
    "                \n",
    "                \n",
    "                # LOG OUTPUT\n",
    "                if k % self.num_out == 0:\n",
    "                    y_ = np.dot(X, self.W) + self.b\n",
    "                    y_val_ = np.dot(X_val, self.W) + self.b\n",
    "                    \n",
    "                    self.cost = self.compute_cost(y, y_)\n",
    "                    self.vcost = self.compute_cost(y_val, y_val_)\n",
    "                    \n",
    "                    self.log_current(k)\n",
    "                # LOG OUTPUT\n",
    "                \n",
    "                \n",
    "                # CONVERGENCE\n",
    "                y_val_ = np.dot(X_val, self.W) + self.b\n",
    "                self.vcost = self.compute_cost(y_val, y_val_) # vCost\n",
    "                \n",
    "                self.convergence_test(k)\n",
    "                \n",
    "                if self.EXIT:\n",
    "                    return (self.W, self.b)\n",
    "                \n",
    "                self.last_vcost = self.vcost\n",
    "                # CONVERGENCE\n",
    "\n",
    "                    \n",
    "        # CTRL C            \n",
    "        except KeyboardInterrupt:\n",
    "            self.log_current(k=k, alter=True)\n",
    "            print(f\"\\nTerminated! Returned: Weights: {self.W}, Bias: {self.b}\")\n",
    "            return (self.W, self.b)\n",
    "        # CTRL C\n",
    "        \n",
    "        \n",
    "        return (self.W, self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef81f4c",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dce968dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0/10) > Epoch: 0 cost: 3328.33567934 vCost: 3344.31967759\n",
      "(1/10) > Epoch: 100 cost: 0.49500454 vCost: 0.44454954\n",
      "       * Epoch: 191 vCost: 0.02196689\n",
      "\n",
      "Epoch 191 > vCost Converged with threshold 0.001. OR Performance degraded.\n",
      "(0/10) > Epoch: 0 cost: 3316.70215377 vCost: 3331.49244356\n",
      "(1/10) > Epoch: 100 cost: 0.42706651 vCost: 0.38301200\n",
      "       * Epoch: 186 vCost: 0.02237819\n",
      "\n",
      "Epoch 186 > vCost Converged with threshold 0.001. OR Performance degraded.\n",
      "(0/10) > Epoch: 0 cost: 3377.06099678 vCost: 3393.11899922\n",
      "(1/10) > Epoch: 100 cost: 0.47524958 vCost: 0.42839274\n",
      "       * Epoch: 190 vCost: 0.02179729\n",
      "\n",
      "Epoch 190 > vCost Converged with threshold 0.001. OR Performance degraded.\n",
      "(0/10) > Epoch: 0 cost: 3386.84113269 vCost: 3402.78754242\n",
      "       * Epoch: 77 vCost: 0.96790565\n",
      "\n",
      "Terminated! Returned: Weights: [3.9028 8.246 ], Bias: 52.415040479616344\n",
      "(0/10) > Epoch: 0 cost: 3320.27924196 vCost: 3335.66159563\n",
      "(1/10) > Epoch: 100 cost: 0.46465453 vCost: 0.41665345\n",
      "       * Epoch: 189 vCost: 0.02204288\n",
      "\n",
      "Epoch 189 > vCost Converged with threshold 0.001. OR Performance degraded.\n",
      "(0/10) > Epoch: 0 cost: 3302.80939686 vCost: 3317.75490814\n",
      "(1/10) > Epoch: 100 cost: 0.42504010 vCost: 0.38243853\n",
      "       * Epoch: 113 vCost: 0.25625923\n",
      "\n",
      "Terminated! Returned: Weights: [4.6853 9.6845], Bias: 50.96643766406227\n",
      "(0/10) > Epoch: 0 cost: 3235.47505903 vCost: 3249.91124714\n",
      "       * Epoch: 7 vCost: 8.42042880\n",
      "\n",
      "Terminated! Returned: Weights: [1.4099 2.045 ], Bias: 58.22041941627149\n",
      "(0/10) > Epoch: 0 cost: 3247.69461184 vCost: 3262.36748137\n",
      "       * Epoch: 8 vCost: 8.64370053\n",
      "\n",
      "Terminated! Returned: Weights: [0.9947 2.0914], Bias: 56.780601887287396\n",
      "The slowest run took 27.93 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "4.47 s ± 3.02 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "m = LinearRegression()\n",
    "X = np.random.rand(1000,2)\n",
    "y = 5.55*X[:,0] + 11.22*X[:,1] + 50\n",
    "%timeit m.fit(X, y ,epochs= 1000, alpha = 0.2, error_threshold = 0.001, output_limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df39efae",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3213784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17f50fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0/10) > Epoch: 0 cost: 11845.98233804 vCost: 11608.66898195\n",
      "(1/10) > Epoch: 10 cost: 130.99993674 vCost: 131.44726339\n",
      "(2/10) > Epoch: 20 cost: 1.00056007 vCost: 1.00491690\n",
      "(3/10) > Epoch: 30 cost: 0.00985083 vCost: 0.00989963\n",
      "       * Epoch: 38 vCost: 0.00073651\n",
      "\n",
      "Epoch 38 > vCost Converged with threshold 0.01. OR Performance degraded.\n",
      "(0/10) > Epoch: 0 cost: 11946.96998784 vCost: 11707.40429251\n",
      "(1/10) > Epoch: 10 cost: 132.38022888 vCost: 132.85210995\n",
      "(2/10) > Epoch: 20 cost: 1.01139236 vCost: 1.01594832\n",
      "(3/10) > Epoch: 30 cost: 0.00994652 vCost: 0.00999712\n",
      "       * Epoch: 38 vCost: 0.00074011\n",
      "\n",
      "Epoch 38 > vCost Converged with threshold 0.01. OR Performance degraded.\n",
      "(0/10) > Epoch: 0 cost: 11852.69574842 vCost: 11613.16591518\n",
      "(1/10) > Epoch: 10 cost: 131.09052969 vCost: 131.53894900\n",
      "(2/10) > Epoch: 20 cost: 1.00126004 vCost: 1.00562592\n",
      "(3/10) > Epoch: 30 cost: 0.00985693 vCost: 0.00990582\n",
      "       * Epoch: 38 vCost: 0.00073674\n",
      "\n",
      "Epoch 38 > vCost Converged with threshold 0.01. OR Performance degraded.\n",
      "(0/10) > Epoch: 0 cost: 11832.33287637 vCost: 11591.44567968\n",
      "(1/10) > Epoch: 10 cost: 130.66339332 vCost: 131.09497245\n",
      "(2/10) > Epoch: 20 cost: 0.99771022 vCost: 1.00194288\n",
      "(3/10) > Epoch: 30 cost: 0.00982411 vCost: 0.00987182\n",
      "       * Epoch: 38 vCost: 0.00073546\n",
      "\n",
      "Epoch 38 > vCost Converged with threshold 0.01. OR Performance degraded.\n",
      "(0/10) > Epoch: 0 cost: 11818.52298936 vCost: 11581.41275103\n",
      "(1/10) > Epoch: 10 cost: 131.02477773 vCost: 131.49683983\n",
      "(2/10) > Epoch: 20 cost: 1.00127148 vCost: 1.00582009\n",
      "(3/10) > Epoch: 30 cost: 0.00986086 vCost: 0.00991134\n",
      "       * Epoch: 38 vCost: 0.00073699\n",
      "\n",
      "Epoch 38 > vCost Converged with threshold 0.01. OR Performance degraded.\n",
      "(0/10) > Epoch: 0 cost: 11912.64055298 vCost: 11670.86287039\n",
      "(1/10) > Epoch: 10 cost: 131.79242719 vCost: 132.24624119\n",
      "(2/10) > Epoch: 20 cost: 1.00661773 vCost: 1.01102995\n",
      "(3/10) > Epoch: 30 cost: 0.00990317 vCost: 0.00995250\n",
      "       * Epoch: 38 vCost: 0.00073845\n",
      "\n",
      "Epoch 38 > vCost Converged with threshold 0.01. OR Performance degraded.\n",
      "(0/10) > Epoch: 0 cost: 11881.81671485 vCost: 11642.95762432\n",
      "(1/10) > Epoch: 10 cost: 131.68161360 vCost: 132.15263674\n",
      "(2/10) > Epoch: 20 cost: 1.00615585 vCost: 1.01070065\n",
      "(3/10) > Epoch: 30 cost: 0.00990205 vCost: 0.00995253\n",
      "       * Epoch: 38 vCost: 0.00073849\n",
      "\n",
      "Epoch 38 > vCost Converged with threshold 0.01. OR Performance degraded.\n",
      "(0/10) > Epoch: 0 cost: 11768.36116012 vCost: 11532.03567321\n",
      "(1/10) > Epoch: 10 cost: 130.35065700 vCost: 130.81126522\n",
      "(2/10) > Epoch: 20 cost: 0.99599268 vCost: 1.00044820\n",
      "(3/10) > Epoch: 30 cost: 0.00981430 vCost: 0.00986394\n",
      "       * Epoch: 38 vCost: 0.00073524\n",
      "\n",
      "Epoch 38 > vCost Converged with threshold 0.01. OR Performance degraded.\n",
      "5.61 s ± 297 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_regression(n_samples=10000,n_features=2, n_informative=2, random_state=0)\n",
    "m = LinearRegression()\n",
    "%timeit m.fit(X, y ,epochs= 100, alpha = 0.25, error_threshold = 0.01, output_limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ef96b0",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7070fa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "488a8b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = fetch_california_housing(return_X_y=True)\n",
    "X = X[:1000]\n",
    "y = y[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19fca112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0/10) > Epoch: 0 cost: 23277.33947452 vCost: 92554.16385094\n",
      "(1/10) > Epoch: 100 cost: 11.24434409 vCost: 14.00525613\n",
      "(2/10) > Epoch: 200 cost: 3.98412860 vCost: 5.28210467\n",
      "(3/10) > Epoch: 300 cost: 2.03675686 vCost: 2.67244059\n",
      "(4/10) > Epoch: 400 cost: 1.49958577 vCost: 1.81804002\n",
      "(5/10) > Epoch: 500 cost: 1.34182463 vCost: 1.50244786\n",
      "       * Epoch: 595 vCost: 1.37304108\n",
      "\n",
      "Epoch 595 > vCost Converged with threshold 0.001. OR Performance degraded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 3.0799e-01, -3.0867e-03,  2.3938e-01,  5.0303e-01,  2.9250e-04,\n",
       "         9.7142e-01,  7.8337e-01,  2.9349e-01]),\n",
       " 2.9273326806109066)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LinearRegression()\n",
    "m.fit(X, y ,epochs= 1000, alpha = 0.0001, error_threshold = 1/1000, val_size=1/3 ,output_limit=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
