{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55fa8fd",
   "metadata": {},
   "source": [
    "# Learning Implementation for Stochastic Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22de211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b171ba73",
   "metadata": {},
   "source": [
    "# Observations:\n",
    "* Reacts better to large bias than BatchGD\n",
    "* If features have noncompareable sizes then bigger feature gets more weight -> slow convergence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195ef49",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8150986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_update(i,X,y,y_,W,b,alpha,m):\n",
    "    \"\"\"Returns W and b after training for a single datapoint.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Todo: Efficiency improvement if passed on y_i and X_i\n",
    "    res = y_[i] - y[i]\n",
    "\n",
    "    dJ_dW = np.dot(res, X[i]) / m\n",
    "    dJ_db = res.mean()\n",
    "    \n",
    "    W -= dJ_dW*alpha\n",
    "    b -= dJ_db*alpha\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1820eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_LinearRegression(X,y, iterations = 100,alpha = 0.000001):\n",
    "    \"\"\"Returns W,b after training lr using stochastic gradient descent.\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    iterations: int, default=100\n",
    "        Number of complete iterations through X.\n",
    "        \n",
    "    alpha: float, default=0.000001\n",
    "        Constant Learning Rate.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    W: ndarray\n",
    "        Optimized weights.\n",
    "    b: float\n",
    "        Optimized intercept.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    m,n = X.shape\n",
    "    W = np.zeros(n)\n",
    "    b = 0\n",
    "    \n",
    "    for k in range(iterations+1):\n",
    "        y_ = np.matmul(X,W) +b\n",
    "        \n",
    "        if k % (iterations//10) == 0:\n",
    "            print(f\"Iteration: {k}\", f\"Cost: {mean_squared_error(y,y_)}\", f\"Weights: {W}\",f\"Bias: {b}\")\n",
    "            \n",
    "        for i in range(m):\n",
    "            W,b = single_update(i,X,y,y_,W,b,alpha,m)\n",
    "\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eba465",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a62bdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Cost: 566441.1104519763 Weights: [0. 0.] Bias: 0\n",
      "Iteration: 100 Cost: 34970.45670656444 Weights: [ 1.28261715 -4.37286569] Bias: -523.0091347036166\n",
      "Iteration: 200 Cost: 10003.604123442168 Weights: [ 3.31143082 -2.35998188] Bias: -752.0840543660826\n",
      "Iteration: 300 Cost: 2861.839481385017 Weights: [ 4.37619889 -1.26255324] Bias: -874.5987850609321\n",
      "Iteration: 400 Cost: 818.7174851131421 Weights: [ 4.94543495 -0.67529962] Bias: -940.1275329363285\n",
      "Iteration: 500 Cost: 234.21939798177308 Weights: [ 5.24989594 -0.36119436] Bias: -975.1765825401166\n",
      "Iteration: 600 Cost: 67.0056855855875 Weights: [ 5.4127415  -0.19319032] Bias: -993.9231018235174\n",
      "Iteration: 700 Cost: 19.16904380882192 Weights: [ 5.49984193 -0.10333079] Bias: -1003.9499638818513\n",
      "Iteration: 800 Cost: 5.48389643856094 Weights: [ 5.54642893 -0.05526805] Bias: -1009.3129841428122\n",
      "Iteration: 900 Cost: 1.5688377807831386 Weights: [ 5.57134669 -0.02956096] Bias: -1012.1814774114297\n",
      "Iteration: 1000 Cost: 0.4488144533641591 Weights: [ 5.58467434 -0.01581113] Bias: -1013.7157348320168\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(1000,2)*100\n",
    "y = -1015.48 + 5.6*X[:,0]\n",
    "W,b = SGD_LinearRegression(X,y,1000,0.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd3ce84",
   "metadata": {},
   "source": [
    "! One run after last function print output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
