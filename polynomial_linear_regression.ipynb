{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55fa8fd",
   "metadata": {},
   "source": [
    "# Polynomial Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22de211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e164d9e5",
   "metadata": {},
   "source": [
    "Using vstack. Consider slicing alternatives np.c_ and np.r_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b64b9d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86893246, 0.85881848, 0.7449646 , 1.        ],\n",
       "       [0.73157778, 0.23722782, 0.41669987, 1.        ],\n",
       "       [0.22570504, 0.57166107, 0.72474354, 1.        ],\n",
       "       [0.44163795, 0.13843437, 0.01036889, 1.        ],\n",
       "       [0.74823972, 0.10319125, 0.42968581, 1.        ],\n",
       "       [0.13535405, 0.9805224 , 0.41215072, 1.        ],\n",
       "       [0.35313843, 0.33267638, 0.46843338, 1.        ],\n",
       "       [0.61806931, 0.23979303, 0.89898248, 1.        ],\n",
       "       [0.75999336, 0.33004741, 0.79163501, 1.        ],\n",
       "       [0.93619084, 0.23866027, 0.95366558, 1.        ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.rand(10,3)\n",
    "np.c_[X, np.ones(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd98d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyX(X, degree):\n",
    "    # Dynamic prog\n",
    "    # Powers, for x,y,z features: x**2, y**2, z**2, x**3, y**3, z**3, ...\n",
    "    newX = X.copy()\n",
    "    for i in range(2, degree+1):\n",
    "        newX = np.c_[newX, X**i]\n",
    "    # Combinations, xy, xz, yz, xyz, x2y, xy2, x2z, xz2, y2z, yz2, ...\n",
    "    # TODO\n",
    "    \n",
    "    return newX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195ef49",
   "metadata": {},
   "source": [
    "## Implementation (No changes yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec60f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialLinearRegression:\n",
    "    \"\"\"Linear regression model with L2 regularization.\"\"\"\n",
    "    \n",
    "    DEFAULT_EPOCHS = 1000\n",
    "    DEFAULT_ALPHA = 0.01\n",
    "    DEFAULT_LAMBDA = 0.0001\n",
    "\n",
    "    def compute_cost(self, y, y_, Lambda, W, m):\n",
    "        \"\"\"Compute cost function with L2 regularization.\"\"\"\n",
    "        \n",
    "        return np.mean((y-y_)**2) + ((np.sum(W**2)) * Lambda/(2*m))\n",
    "    \n",
    "    def log_current(self, k, num_out, output_limit, y, y_, Lambda, W, m, b):\n",
    "        \"\"\"Log current training information.\"\"\"\n",
    "        \n",
    "        print(f\"({k//num_out}/{output_limit}) > Epoch: {k}\",\n",
    "              f\"Cost: {self.compute_cost(y,y_,Lambda,W,m):.8f}\",\n",
    "              f\"W: {W}\",\n",
    "              f\"b: {b:.4f}\")\n",
    "        \n",
    "    \n",
    "    def single_step(self, Xi, yi, m, W, b, alpha, Lambda):\n",
    "        \"\"\"Perform a single step of gradient descent.\"\"\"\n",
    "        \n",
    "        y_i = np.dot(Xi, W) + b \n",
    "        res = yi - y_i\n",
    "        \n",
    "        dJ_dW = np.dot(res, Xi)  - Lambda * W\n",
    "        dJ_db = res.mean()\n",
    "\n",
    "        W += dJ_dW * alpha / m\n",
    "        b += dJ_db * alpha\n",
    "\n",
    "        return W,b\n",
    "    \n",
    "    def fit(self, X, y,\n",
    "            epochs = DEFAULT_EPOCHS,\n",
    "            alpha = DEFAULT_ALPHA,\n",
    "            Lambda=DEFAULT_LAMBDA,\n",
    "            degree = 4,\n",
    "            output_limit=10):\n",
    "        \"\"\"Fit the linear regression model to the given data.\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        epochs: int, default=1000\n",
    "            Number of complete iterations through X\n",
    "\n",
    "        alpha : float, default=0.01\n",
    "            Constant Learning Rate\n",
    "\n",
    "        Lambda : float, default=0.0001\n",
    "            Rate for l2 Regularization\n",
    "\n",
    "        output_limit : int, default=10\n",
    "            Number of iterations to show\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        W : numpy.ndarray\n",
    "            The optimized weights.\n",
    "        b : numpy.longdouble\n",
    "            The optimized itercept.\n",
    "        \"\"\"\n",
    " \n",
    "        if output_limit<=0:\n",
    "            raise ValueError(\"Output limit should be greater than 0\")\n",
    "        \n",
    "        num_out = epochs//output_limit\n",
    "        np.set_printoptions(precision=4)\n",
    "        \n",
    "        \n",
    "        m,n = X.shape\n",
    "        \n",
    "        W = np.random.rand(n)\n",
    "        b = np.random.rand()\n",
    "        y_ = np.dot(X,W) + b\n",
    "        self.log_current(0, num_out, output_limit, y, y_, Lambda, W, m, b) # Initial Out\n",
    "\n",
    "        try:\n",
    "            for k in range(1, epochs+1):\n",
    "                for i in range(m):\n",
    "                    W,b = self.single_step(X[i], y[i], m, W, b, alpha, Lambda)\n",
    "\n",
    "                if k % num_out == 0:\n",
    "                    y_ = np.dot(X,W) + b\n",
    "                    self.log_current(k, num_out, output_limit, y, y_, Lambda, W, m, b)\n",
    "                    \n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"\\nTerminated! Returned: Weights: {W}, Bias: {b}\")\n",
    "            return (W,b)\n",
    "        return (W,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef81f4c",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dce968dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = PolynomialLinearRegression()\n",
    "X = np.array([x for x in np.random.rand(100,2)]) + 5\n",
    "y  = X[:,0] + 4 * (X[:,0]**2) + 2 * X[:,1] + 5 * (X[:,1]**2) # y = x + 4xsq + 2y + 5ysq\n",
    "X = polyX(X,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40cafd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0/10) > Epoch: 0 Cost: 60535.43639483 W: [0.8035 0.4124 0.7532 0.5024] b: 0.9489\n",
      "(1/10) > Epoch: 500 Cost: 0.00011790 W: [1.1433 0.877  3.9874 5.102 ] b: 2.6852\n",
      "(2/10) > Epoch: 1000 Cost: 0.00011750 W: [1.1413 0.8773 3.9876 5.1019] b: 2.6900\n",
      "(3/10) > Epoch: 1500 Cost: 0.00011707 W: [1.1392 0.8776 3.9878 5.1019] b: 2.6947\n",
      "(4/10) > Epoch: 2000 Cost: 0.00011665 W: [1.1372 0.8779 3.988  5.1019] b: 2.6995\n",
      "(5/10) > Epoch: 2500 Cost: 0.00011623 W: [1.1351 0.8783 3.9882 5.1018] b: 2.7042\n",
      "(6/10) > Epoch: 3000 Cost: 0.00011581 W: [1.1331 0.8786 3.9884 5.1018] b: 2.7089\n",
      "(7/10) > Epoch: 3500 Cost: 0.00011540 W: [1.131  0.8789 3.9885 5.1018] b: 2.7136\n",
      "(8/10) > Epoch: 4000 Cost: 0.00011499 W: [1.129  0.8793 3.9887 5.1018] b: 2.7182\n",
      "(9/10) > Epoch: 4500 Cost: 0.00011459 W: [1.127  0.8796 3.9889 5.1017] b: 2.7229\n",
      "(10/10) > Epoch: 5000 Cost: 0.00011418 W: [1.125  0.8799 3.9891 5.1017] b: 2.7275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.125 , 0.8799, 3.9891, 5.1017]), 2.7275165723930828)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(X, y,epochs=1000*5 ,alpha=0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
