{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55fa8fd",
   "metadata": {},
   "source": [
    "# Learning Implementation for Stochastic Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22de211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b171ba73",
   "metadata": {},
   "source": [
    "# Observations:\n",
    "* Reacts better to large bias than BatchGD\n",
    "* If features have noncompareable sizes then bigger feature gets more weight -> slow convergence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195ef49",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8150986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_update(i,X,y,y_,W,b,alpha,m):\n",
    "    \"\"\"Returns W and b after training for a single datapoint.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Todo: Efficiency improvement if passed on y_i and X_i\n",
    "    res = y_[i] - y[i]\n",
    "\n",
    "    dJ_dW = np.dot(res, X[i]) / m\n",
    "    dJ_db = res.mean()\n",
    "    \n",
    "    W -= dJ_dW*alpha\n",
    "    b -= dJ_db*alpha\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1820eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_LinearRegression(X,y, iterations = 100,alpha = 0.000001):\n",
    "    \"\"\"Returns W,b after training lr using stochastic gradient descent.\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    iterations: int, default=100\n",
    "        Number of complete iterations through X.\n",
    "        \n",
    "    alpha: float, default=0.000001\n",
    "        Constant Learning Rate.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    W: ndarray\n",
    "        Optimized weights.\n",
    "    b: float\n",
    "        Optimized intercept.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    m,n = X.shape\n",
    "    W = np.zeros(n)\n",
    "    b = 0\n",
    "    \n",
    "    for k in range(iterations+1):\n",
    "        y_ = np.matmul(X,W) +b\n",
    "        \n",
    "        if k % (iterations//10) == 0:\n",
    "            print(f\"Iteration: {k}\", f\"Cost: {mean_squared_error(y,y_)}\", f\"Weights: {W}\",f\"Bias: {b}\")\n",
    "            \n",
    "        for i in range(m):\n",
    "            W,b = single_update(i,X,y,y_,W,b,alpha,m)\n",
    "\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eba465",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a62bdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Cost: 559710.6861976474 Weights: [0. 0.] Bias: 0\n",
      "Iteration: 100 Cost: 35253.245053790706 Weights: [ 1.04392205 -4.01799696] Bias: -521.0663335982424\n",
      "Iteration: 200 Cost: 10030.2223612286 Weights: [ 3.18488349 -2.15872164] Bias: -751.740323260276\n",
      "Iteration: 300 Cost: 2853.9100869474023 Weights: [ 4.31193003 -1.15168566] Bias: -874.7972639310219\n",
      "Iteration: 400 Cost: 812.0261622153131 Weights: [ 4.91292706 -0.61432829] Bias: -940.4377780586516\n",
      "Iteration: 500 Cost: 231.04669314771084 Weights: [ 5.23350532 -0.32769168] Bias: -975.4513860211425\n",
      "Iteration: 600 Cost: 65.73996860993654 Weights: [ 5.4045064  -0.17479552] Bias: -994.1281544029422\n",
      "Iteration: 700 Cost: 18.70506525741931 Weights: [ 5.49572087 -0.09323847] Bias: -1004.0906146309361\n",
      "Iteration: 800 Cost: 5.322172700750929 Weights: [ 5.54437599 -0.04973476] Bias: -1009.4047359908395\n",
      "Iteration: 900 Cost: 1.514323626605504 Weights: [ 5.57032934 -0.02652925] Bias: -1012.2393657089541\n",
      "Iteration: 1000 Cost: 0.43087215974437837 Weights: [ 5.58417324 -0.01415109] Bias: -1013.7513984787345\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(1000,2)*100\n",
    "y = -1015.48 + 5.6*X[:,0]\n",
    "W,b = SGD_LinearRegression(X,y,1000,0.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd3ce84",
   "metadata": {},
   "source": [
    "! One run after last function print output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
