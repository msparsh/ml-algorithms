{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58cc05bf",
   "metadata": {},
   "source": [
    "# Logistic Regression (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e60a231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23a72321",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \"\"\"Logistic Regression implementation.\n",
    "\n",
    "    This class provides functionalities to perform logistic regression. Check the fit method.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"To add globals if required to make model persistent.\"\"\"\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def sigmoid_dot(self, X, W, b):\n",
    "        \"\"\"Returns sigmoid of (W.X + b)\"\"\"\n",
    "        \n",
    "        return 1 / (1 + np.exp(-(np.dot(X, W) + b)))\n",
    "    \n",
    "    def update(self, X, y, y_, W, b, alpha, m):\n",
    "        \"\"\"Updates W, b stochastically for each datapoint.\"\"\"\n",
    "        \n",
    "        res = y-y_\n",
    "        for i in range(m):\n",
    "\n",
    "            dJ_dW = np.dot(res[i],X[i]) / m\n",
    "            dJ_db = np.mean(res)\n",
    "            \n",
    "            W += alpha * dJ_dW\n",
    "            b += alpha * dJ_db\n",
    "        return W, b \n",
    "    \n",
    "    def cost(self, y, y_):\n",
    "        \"\"\"Returns logistic cost between predicted values and true labels.\"\"\"\n",
    "        \n",
    "        m = y.shape[0]\n",
    "        c = 0\n",
    "        \n",
    "        for i in range(m):\n",
    "            c += y[i] * np.log(y_[i]) + (1 - y[i]) * np.log(1 - y_[i])\n",
    "        return c / (-m)\n",
    "    \n",
    "    def fit(self, X, y, iterations=1000, alpha=0.000001):\n",
    "        \"\"\"\n",
    "        Fits the logistic regression model to the training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Input data of shape (m, n).\n",
    "        y : np.ndarray\n",
    "            True labels of shape (m,).\n",
    "        iterations : int, optional\n",
    "            Number of iterations for training. Default is 1000.\n",
    "        alpha : float, optional\n",
    "            Learning rate. Default is 0.000001\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            Trained model parameters W and b.\n",
    "        \"\"\"\n",
    "        \n",
    "        m, n = X.shape\n",
    "        W = np.random.rand(n)\n",
    "        b = 0\n",
    "        \n",
    "        for k in range(iterations):\n",
    "            y_ = self.sigmoid_dot(X, W, b)\n",
    "            W, b = self.update(X, y, y_, W, b, alpha,m)\n",
    "            print(f\"Iteration: {k}\",\n",
    "                  f\"Cost: {self.cost(y, y_)}\",\n",
    "                  f\"Acc: {accuracy_score(y, y_.round())}\")\n",
    "        return W, b\n",
    "    \n",
    "    def predict(self, X, W, b):\n",
    "        \"\"\"Generates predictions for input data X using trained model parameters W and b.\n",
    "        \n",
    "        Returns rounded predictions. Might need to fix.\n",
    "        \"\"\"\n",
    "        \n",
    "        s = self.sigmoid_dot(X, W, b)\n",
    "        return s.round()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2a4513",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b00a7",
   "metadata": {},
   "source": [
    "Multilabel Dataset. Using 2 targets at a time as Model is Binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4569395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ddfcd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Cost: 0.6810392254190654 Acc: 0.5\n",
      "Iteration: 1 Cost: 0.6605455546683778 Acc: 0.5\n",
      "Iteration: 2 Cost: 0.6477584497702533 Acc: 0.5\n",
      "Iteration: 3 Cost: 0.6398759412138559 Acc: 0.5\n",
      "Iteration: 4 Cost: 0.6350331499062908 Acc: 0.57\n",
      "Iteration: 5 Cost: 0.6320429055822937 Acc: 0.6\n",
      "Iteration: 6 Cost: 0.6301700023566245 Acc: 0.65\n",
      "Iteration: 7 Cost: 0.6289667439033088 Acc: 0.78\n",
      "Iteration: 8 Cost: 0.6281632868653658 Acc: 0.84\n",
      "Iteration: 9 Cost: 0.6275979907278775 Acc: 0.84\n",
      "Iteration: 10 Cost: 0.6271743917338936 Acc: 0.92\n",
      "Iteration: 11 Cost: 0.6268350521855562 Acc: 0.92\n",
      "Iteration: 12 Cost: 0.6265458184323885 Acc: 0.92\n",
      "Iteration: 13 Cost: 0.6262863987389538 Acc: 0.92\n",
      "Iteration: 14 Cost: 0.626044743145763 Acc: 0.94\n",
      "Iteration: 15 Cost: 0.6258136980751462 Acc: 0.94\n",
      "Iteration: 16 Cost: 0.6255890174666678 Acc: 0.94\n",
      "Iteration: 17 Cost: 0.625368181274303 Acc: 0.94\n",
      "Iteration: 18 Cost: 0.6251496939054877 Acc: 0.94\n",
      "Iteration: 19 Cost: 0.6249326677584581 Acc: 0.94\n",
      "Iteration: 20 Cost: 0.6247165760411992 Acc: 0.94\n",
      "Iteration: 21 Cost: 0.6245011060773149 Acc: 0.94\n",
      "Iteration: 22 Cost: 0.6242860722522667 Acc: 0.94\n",
      "Iteration: 23 Cost: 0.6240713643537245 Acc: 0.94\n",
      "Iteration: 24 Cost: 0.6238569169157819 Acc: 0.94\n",
      "Iteration: 25 Cost: 0.6236426910271948 Acc: 0.94\n",
      "Iteration: 26 Cost: 0.6234286635358655 Acc: 0.94\n",
      "Iteration: 27 Cost: 0.6232148206423859 Acc: 0.94\n",
      "Iteration: 28 Cost: 0.6230011540981072 Acc: 0.94\n",
      "Iteration: 29 Cost: 0.622787658948842 Acc: 0.94\n",
      "Iteration: 30 Cost: 0.6225743321957772 Acc: 0.94\n",
      "Iteration: 31 Cost: 0.622361172000749 Acc: 0.94\n",
      "Iteration: 32 Cost: 0.622148177214542 Acc: 0.94\n",
      "Iteration: 33 Cost: 0.6219353470969373 Acc: 0.94\n",
      "Iteration: 34 Cost: 0.6217226811505341 Acc: 0.94\n",
      "Iteration: 35 Cost: 0.6215101790221119 Acc: 0.94\n",
      "Iteration: 36 Cost: 0.6212978404440898 Acc: 0.94\n",
      "Iteration: 37 Cost: 0.6210856651997627 Acc: 0.94\n",
      "Iteration: 38 Cost: 0.6208736531026691 Acc: 0.94\n",
      "Iteration: 39 Cost: 0.6206618039843458 Acc: 0.94\n",
      "Iteration: 40 Cost: 0.6204501176870557 Acc: 0.94\n",
      "Iteration: 41 Cost: 0.6202385940594629 Acc: 0.94\n",
      "Iteration: 42 Cost: 0.6200272329540794 Acc: 0.94\n",
      "Iteration: 43 Cost: 0.6198160342257338 Acc: 0.94\n",
      "Iteration: 44 Cost: 0.6196049977306743 Acc: 0.94\n",
      "Iteration: 45 Cost: 0.6193941233260254 Acc: 0.94\n",
      "Iteration: 46 Cost: 0.6191834108694712 Acc: 0.94\n",
      "Iteration: 47 Cost: 0.6189728602190723 Acc: 0.94\n",
      "Iteration: 48 Cost: 0.6187624712331412 Acc: 0.94\n",
      "Iteration: 49 Cost: 0.6185522437701854 Acc: 0.94\n",
      "Iteration: 50 Cost: 0.618342177688863 Acc: 0.94\n",
      "Iteration: 51 Cost: 0.6181322728479597 Acc: 0.94\n",
      "Iteration: 52 Cost: 0.6179225291063782 Acc: 0.94\n",
      "Iteration: 53 Cost: 0.6177129463231218 Acc: 0.94\n",
      "Iteration: 54 Cost: 0.6175035243572989 Acc: 0.94\n",
      "Iteration: 55 Cost: 0.6172942630681156 Acc: 0.94\n",
      "Iteration: 56 Cost: 0.6170851623148724 Acc: 0.94\n",
      "Iteration: 57 Cost: 0.6168762219569632 Acc: 0.94\n",
      "Iteration: 58 Cost: 0.6166674418538816 Acc: 0.94\n",
      "Iteration: 59 Cost: 0.616458821865213 Acc: 0.94\n",
      "Iteration: 60 Cost: 0.6162503618506348 Acc: 0.94\n",
      "Iteration: 61 Cost: 0.616042061669921 Acc: 0.94\n",
      "Iteration: 62 Cost: 0.615833921182941 Acc: 0.94\n",
      "Iteration: 63 Cost: 0.6156259402496533 Acc: 0.94\n",
      "Iteration: 64 Cost: 0.6154181187301143 Acc: 0.94\n",
      "Iteration: 65 Cost: 0.6152104564844741 Acc: 0.94\n",
      "Iteration: 66 Cost: 0.6150029533729772 Acc: 0.94\n",
      "Iteration: 67 Cost: 0.6147956092559599 Acc: 0.94\n",
      "Iteration: 68 Cost: 0.6145884239938545 Acc: 0.94\n",
      "Iteration: 69 Cost: 0.614381397447188 Acc: 0.94\n",
      "Iteration: 70 Cost: 0.6141745294765822 Acc: 0.94\n",
      "Iteration: 71 Cost: 0.6139678199427506 Acc: 0.94\n",
      "Iteration: 72 Cost: 0.613761268706505 Acc: 0.94\n",
      "Iteration: 73 Cost: 0.6135548756287478 Acc: 0.94\n",
      "Iteration: 74 Cost: 0.6133486405704783 Acc: 0.94\n",
      "Iteration: 75 Cost: 0.6131425633927922 Acc: 0.94\n",
      "Iteration: 76 Cost: 0.6129366439568751 Acc: 0.94\n",
      "Iteration: 77 Cost: 0.6127308821240113 Acc: 0.94\n",
      "Iteration: 78 Cost: 0.612525277755579 Acc: 0.94\n",
      "Iteration: 79 Cost: 0.6123198307130508 Acc: 0.94\n",
      "Iteration: 80 Cost: 0.612114540857995 Acc: 0.94\n",
      "Iteration: 81 Cost: 0.6119094080520727 Acc: 0.94\n",
      "Iteration: 82 Cost: 0.6117044321570445 Acc: 0.94\n",
      "Iteration: 83 Cost: 0.6114996130347612 Acc: 0.94\n",
      "Iteration: 84 Cost: 0.6112949505471716 Acc: 0.94\n",
      "Iteration: 85 Cost: 0.6110904445563189 Acc: 0.94\n",
      "Iteration: 86 Cost: 0.6108860949243425 Acc: 0.94\n",
      "Iteration: 87 Cost: 0.6106819015134747 Acc: 0.94\n",
      "Iteration: 88 Cost: 0.6104778641860469 Acc: 0.94\n",
      "Iteration: 89 Cost: 0.610273982804483 Acc: 0.94\n",
      "Iteration: 90 Cost: 0.6100702572313031 Acc: 0.94\n",
      "Iteration: 91 Cost: 0.609866687329122 Acc: 0.94\n",
      "Iteration: 92 Cost: 0.6096632729606524 Acc: 0.94\n",
      "Iteration: 93 Cost: 0.6094600139887008 Acc: 0.94\n",
      "Iteration: 94 Cost: 0.6092569102761709 Acc: 0.94\n",
      "Iteration: 95 Cost: 0.6090539616860601 Acc: 0.94\n",
      "Iteration: 96 Cost: 0.608851168081463 Acc: 0.94\n",
      "Iteration: 97 Cost: 0.6086485293255678 Acc: 0.94\n",
      "Iteration: 98 Cost: 0.6084460452816635 Acc: 0.94\n",
      "Iteration: 99 Cost: 0.6082437158131294 Acc: 0.94\n"
     ]
    }
   ],
   "source": [
    "X = load_iris()[\"data\"][50:150,3:4]\n",
    "y = load_iris()[\"target\"][50:150] - 1\n",
    "m = LogisticRegression()\n",
    "W,b = m.fit(X,y,100, 0.009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c357bef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Cost: 0.5398749316241829 Acc: 0.5\n",
      "Iteration: 1 Cost: 0.5191350329038569 Acc: 0.55\n",
      "Iteration: 2 Cost: 0.5056580955125702 Acc: 0.84\n",
      "Iteration: 3 Cost: 0.49696960110357324 Acc: 0.91\n",
      "Iteration: 4 Cost: 0.49136823833242893 Acc: 0.98\n",
      "Iteration: 5 Cost: 0.4877284152282435 Acc: 0.99\n",
      "Iteration: 6 Cost: 0.4853234461873965 Acc: 0.99\n",
      "Iteration: 7 Cost: 0.48369137159280134 Acc: 1.0\n",
      "Iteration: 8 Cost: 0.4825413485077577 Acc: 1.0\n",
      "Iteration: 9 Cost: 0.48169136705289545 Acc: 1.0\n",
      "Iteration: 10 Cost: 0.4810279496052282 Acc: 1.0\n",
      "Iteration: 11 Cost: 0.4804805084009422 Acc: 1.0\n",
      "Iteration: 12 Cost: 0.4800051960136771 Acc: 1.0\n",
      "Iteration: 13 Cost: 0.4795747979787126 Acc: 1.0\n",
      "Iteration: 14 Cost: 0.47917243124267855 Acc: 1.0\n",
      "Iteration: 15 Cost: 0.4787876246223995 Acc: 1.0\n",
      "Iteration: 16 Cost: 0.4784138843386407 Acc: 1.0\n",
      "Iteration: 17 Cost: 0.4780471832295688 Acc: 1.0\n",
      "Iteration: 18 Cost: 0.4776850236430354 Acc: 1.0\n",
      "Iteration: 19 Cost: 0.47732585632304575 Acc: 1.0\n",
      "Iteration: 20 Cost: 0.4769687200973137 Acc: 1.0\n",
      "Iteration: 21 Cost: 0.47661301847714765 Acc: 1.0\n",
      "Iteration: 22 Cost: 0.4762583811419671 Acc: 1.0\n",
      "Iteration: 23 Cost: 0.4759045780498253 Acc: 1.0\n",
      "Iteration: 24 Cost: 0.47555146617526484 Acc: 1.0\n",
      "Iteration: 25 Cost: 0.4751989564768218 Acc: 1.0\n",
      "Iteration: 26 Cost: 0.4748469934084269 Acc: 1.0\n",
      "Iteration: 27 Cost: 0.47449554220971657 Acc: 1.0\n",
      "Iteration: 28 Cost: 0.47414458102086043 Acc: 1.0\n",
      "Iteration: 29 Cost: 0.4737940959899266 Acc: 1.0\n",
      "Iteration: 30 Cost: 0.47344407823668005 Acc: 1.0\n",
      "Iteration: 31 Cost: 0.47309452196816615 Acc: 1.0\n",
      "Iteration: 32 Cost: 0.47274542330899066 Acc: 1.0\n",
      "Iteration: 33 Cost: 0.4723967795751407 Acc: 1.0\n",
      "Iteration: 34 Cost: 0.4720485888230914 Acc: 1.0\n",
      "Iteration: 35 Cost: 0.471700849569807 Acc: 1.0\n",
      "Iteration: 36 Cost: 0.47135356061883693 Acc: 1.0\n",
      "Iteration: 37 Cost: 0.47100672095229074 Acc: 1.0\n",
      "Iteration: 38 Cost: 0.47066032966372434 Acc: 1.0\n",
      "Iteration: 39 Cost: 0.470314385916436 Acc: 1.0\n",
      "Iteration: 40 Cost: 0.46996888891754707 Acc: 1.0\n",
      "Iteration: 41 Cost: 0.46962383790189416 Acc: 1.0\n",
      "Iteration: 42 Cost: 0.4692792321220115 Acc: 1.0\n",
      "Iteration: 43 Cost: 0.4689350708418982 Acc: 1.0\n",
      "Iteration: 44 Cost: 0.4685913533331476 Acc: 1.0\n",
      "Iteration: 45 Cost: 0.46824807887253356 Acc: 1.0\n",
      "Iteration: 46 Cost: 0.4679052467405099 Acc: 1.0\n",
      "Iteration: 47 Cost: 0.46756285622027605 Acc: 1.0\n",
      "Iteration: 48 Cost: 0.4672209065971935 Acc: 1.0\n",
      "Iteration: 49 Cost: 0.46687939715842214 Acc: 1.0\n",
      "Iteration: 50 Cost: 0.46653832719269295 Acc: 1.0\n",
      "Iteration: 51 Cost: 0.4661976959901656 Acc: 1.0\n",
      "Iteration: 52 Cost: 0.46585750284234206 Acc: 1.0\n",
      "Iteration: 53 Cost: 0.4655177470420036 Acc: 1.0\n",
      "Iteration: 54 Cost: 0.4651784278831833 Acc: 1.0\n",
      "Iteration: 55 Cost: 0.4648395446611358 Acc: 1.0\n",
      "Iteration: 56 Cost: 0.4645010966723252 Acc: 1.0\n",
      "Iteration: 57 Cost: 0.46416308321441774 Acc: 1.0\n",
      "Iteration: 58 Cost: 0.46382550358627045 Acc: 1.0\n",
      "Iteration: 59 Cost: 0.46348835708792985 Acc: 1.0\n",
      "Iteration: 60 Cost: 0.46315164302062667 Acc: 1.0\n",
      "Iteration: 61 Cost: 0.46281536068677126 Acc: 1.0\n",
      "Iteration: 62 Cost: 0.46247950938995436 Acc: 1.0\n",
      "Iteration: 63 Cost: 0.46214408843494453 Acc: 1.0\n",
      "Iteration: 64 Cost: 0.4618090971276845 Acc: 1.0\n",
      "Iteration: 65 Cost: 0.46147453477529105 Acc: 1.0\n",
      "Iteration: 66 Cost: 0.46114040068605205 Acc: 1.0\n",
      "Iteration: 67 Cost: 0.4608066941694269 Acc: 1.0\n",
      "Iteration: 68 Cost: 0.4604734145360409 Acc: 1.0\n",
      "Iteration: 69 Cost: 0.4601405610976893 Acc: 1.0\n",
      "Iteration: 70 Cost: 0.45980813316733254 Acc: 1.0\n",
      "Iteration: 71 Cost: 0.45947613005909393 Acc: 1.0\n",
      "Iteration: 72 Cost: 0.45914455108826036 Acc: 1.0\n",
      "Iteration: 73 Cost: 0.45881339557127837 Acc: 1.0\n",
      "Iteration: 74 Cost: 0.4584826628257529 Acc: 1.0\n",
      "Iteration: 75 Cost: 0.4581523521704496 Acc: 1.0\n",
      "Iteration: 76 Cost: 0.45782246292528916 Acc: 1.0\n",
      "Iteration: 77 Cost: 0.45749299441134694 Acc: 1.0\n",
      "Iteration: 78 Cost: 0.45716394595085375 Acc: 1.0\n",
      "Iteration: 79 Cost: 0.4568353168671882 Acc: 1.0\n",
      "Iteration: 80 Cost: 0.456507106484882 Acc: 1.0\n",
      "Iteration: 81 Cost: 0.4561793141296138 Acc: 1.0\n",
      "Iteration: 82 Cost: 0.455851939128212 Acc: 1.0\n",
      "Iteration: 83 Cost: 0.4555249808086467 Acc: 1.0\n",
      "Iteration: 84 Cost: 0.4551984385000383 Acc: 1.0\n",
      "Iteration: 85 Cost: 0.45487231153264285 Acc: 1.0\n",
      "Iteration: 86 Cost: 0.4545465992378621 Acc: 1.0\n",
      "Iteration: 87 Cost: 0.45422130094823643 Acc: 1.0\n",
      "Iteration: 88 Cost: 0.4538964159974423 Acc: 1.0\n",
      "Iteration: 89 Cost: 0.45357194372029475 Acc: 1.0\n",
      "Iteration: 90 Cost: 0.4532478834527432 Acc: 1.0\n",
      "Iteration: 91 Cost: 0.4529242345318715 Acc: 1.0\n",
      "Iteration: 92 Cost: 0.45260099629589334 Acc: 1.0\n",
      "Iteration: 93 Cost: 0.4522781680841539 Acc: 1.0\n",
      "Iteration: 94 Cost: 0.4519557492371257 Acc: 1.0\n",
      "Iteration: 95 Cost: 0.45163373909641125 Acc: 1.0\n",
      "Iteration: 96 Cost: 0.4513121370047361 Acc: 1.0\n",
      "Iteration: 97 Cost: 0.45099094230595205 Acc: 1.0\n",
      "Iteration: 98 Cost: 0.45067015434503205 Acc: 1.0\n",
      "Iteration: 99 Cost: 0.4503497724680703 Acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "X = load_iris()[\"data\"][0:100,3:4]\n",
    "y = load_iris()[\"target\"][0:100]\n",
    "\n",
    "m = LogisticRegression()\n",
    "W,b = m.fit(X,y,100, 0.009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d79ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(1000, 5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af09cc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Cost: 0.28777558158298233 Acc: 0.921\n",
      "Iteration: 1 Cost: 0.286943454229056 Acc: 0.924\n",
      "Iteration: 2 Cost: 0.2866625538369118 Acc: 0.924\n",
      "Iteration: 3 Cost: 0.2863898674221144 Acc: 0.924\n",
      "Iteration: 4 Cost: 0.2861185693981546 Acc: 0.924\n",
      "Iteration: 5 Cost: 0.2858485648927204 Acc: 0.924\n",
      "Iteration: 6 Cost: 0.28557984358863686 Acc: 0.924\n",
      "Iteration: 7 Cost: 0.2853123963023754 Acc: 0.925\n",
      "Iteration: 8 Cost: 0.28504621394571694 Acc: 0.925\n",
      "Iteration: 9 Cost: 0.2847812875129227 Acc: 0.925\n",
      "Iteration: 10 Cost: 0.2845176080796554 Acc: 0.925\n",
      "Iteration: 11 Cost: 0.2842551668021377 Acc: 0.927\n",
      "Iteration: 12 Cost: 0.2839939549163109 Acc: 0.927\n",
      "Iteration: 13 Cost: 0.28373396373700455 Acc: 0.927\n",
      "Iteration: 14 Cost: 0.28347518465711774 Acc: 0.927\n",
      "Iteration: 15 Cost: 0.28321760914680594 Acc: 0.927\n",
      "Iteration: 16 Cost: 0.2829612287526797 Acc: 0.927\n",
      "Iteration: 17 Cost: 0.28270603509701125 Acc: 0.927\n",
      "Iteration: 18 Cost: 0.28245201987695084 Acc: 0.927\n",
      "Iteration: 19 Cost: 0.2821991748637516 Acc: 0.927\n",
      "Iteration: 20 Cost: 0.2819474919020023 Acc: 0.927\n",
      "Iteration: 21 Cost: 0.28169696290886764 Acc: 0.927\n",
      "Iteration: 22 Cost: 0.2814475798733445 Acc: 0.927\n",
      "Iteration: 23 Cost: 0.2811993348555144 Acc: 0.927\n",
      "Iteration: 24 Cost: 0.28095221998581527 Acc: 0.927\n",
      "Iteration: 25 Cost: 0.28070622746431506 Acc: 0.927\n",
      "Iteration: 26 Cost: 0.28046134955999685 Acc: 0.927\n",
      "Iteration: 27 Cost: 0.2802175786100489 Acc: 0.927\n",
      "Iteration: 28 Cost: 0.2799749070191673 Acc: 0.927\n",
      "Iteration: 29 Cost: 0.27973332725885897 Acc: 0.927\n",
      "Iteration: 30 Cost: 0.27949283186676355 Acc: 0.927\n",
      "Iteration: 31 Cost: 0.2792534134459712 Acc: 0.927\n",
      "Iteration: 32 Cost: 0.27901506466435505 Acc: 0.927\n",
      "Iteration: 33 Cost: 0.2787777782539109 Acc: 0.928\n",
      "Iteration: 34 Cost: 0.27854154701009937 Acc: 0.928\n",
      "Iteration: 35 Cost: 0.27830636379120377 Acc: 0.928\n",
      "Iteration: 36 Cost: 0.27807222151768574 Acc: 0.928\n",
      "Iteration: 37 Cost: 0.2778391131715557 Acc: 0.928\n",
      "Iteration: 38 Cost: 0.2776070317957458 Acc: 0.928\n",
      "Iteration: 39 Cost: 0.27737597049349244 Acc: 0.928\n",
      "Iteration: 40 Cost: 0.277145922427724 Acc: 0.929\n",
      "Iteration: 41 Cost: 0.2769168808204557 Acc: 0.93\n",
      "Iteration: 42 Cost: 0.27668883895219304 Acc: 0.93\n",
      "Iteration: 43 Cost: 0.27646179016133954 Acc: 0.93\n",
      "Iteration: 44 Cost: 0.27623572784361106 Acc: 0.93\n",
      "Iteration: 45 Cost: 0.27601064545146026 Acc: 0.93\n",
      "Iteration: 46 Cost: 0.27578653649350165 Acc: 0.93\n",
      "Iteration: 47 Cost: 0.27556339453394957 Acc: 0.93\n",
      "Iteration: 48 Cost: 0.27534121319205557 Acc: 0.93\n",
      "Iteration: 49 Cost: 0.27511998614155797 Acc: 0.93\n",
      "Iteration: 50 Cost: 0.2748997071101352 Acc: 0.93\n",
      "Iteration: 51 Cost: 0.27468036987886413 Acc: 0.93\n",
      "Iteration: 52 Cost: 0.2744619682816841 Acc: 0.93\n",
      "Iteration: 53 Cost: 0.2742444962048726 Acc: 0.931\n",
      "Iteration: 54 Cost: 0.274027947586518 Acc: 0.932\n",
      "Iteration: 55 Cost: 0.273812316416004 Acc: 0.932\n",
      "Iteration: 56 Cost: 0.2735975967334999 Acc: 0.932\n",
      "Iteration: 57 Cost: 0.2733837826294524 Acc: 0.932\n",
      "Iteration: 58 Cost: 0.2731708682440869 Acc: 0.933\n",
      "Iteration: 59 Cost: 0.27295884776691265 Acc: 0.934\n",
      "Iteration: 60 Cost: 0.2727477154362344 Acc: 0.934\n",
      "Iteration: 61 Cost: 0.27253746553866803 Acc: 0.933\n",
      "Iteration: 62 Cost: 0.27232809240866196 Acc: 0.933\n",
      "Iteration: 63 Cost: 0.2721195904280251 Acc: 0.934\n",
      "Iteration: 64 Cost: 0.2719119540254564 Acc: 0.934\n",
      "Iteration: 65 Cost: 0.2717051776760873 Acc: 0.934\n",
      "Iteration: 66 Cost: 0.27149925590101925 Acc: 0.934\n",
      "Iteration: 67 Cost: 0.2712941832668712 Acc: 0.934\n",
      "Iteration: 68 Cost: 0.27108995438533656 Acc: 0.934\n",
      "Iteration: 69 Cost: 0.2708865639127363 Acc: 0.934\n",
      "Iteration: 70 Cost: 0.2706840065495828 Acc: 0.934\n",
      "Iteration: 71 Cost: 0.27048227704014655 Acc: 0.934\n",
      "Iteration: 72 Cost: 0.27028137017202636 Acc: 0.934\n",
      "Iteration: 73 Cost: 0.2700812807757287 Acc: 0.934\n",
      "Iteration: 74 Cost: 0.26988200372424764 Acc: 0.934\n",
      "Iteration: 75 Cost: 0.26968353393264816 Acc: 0.934\n",
      "Iteration: 76 Cost: 0.26948586635765986 Acc: 0.934\n",
      "Iteration: 77 Cost: 0.26928899599726874 Acc: 0.934\n",
      "Iteration: 78 Cost: 0.26909291789031814 Acc: 0.934\n",
      "Iteration: 79 Cost: 0.2688976271161111 Acc: 0.934\n",
      "Iteration: 80 Cost: 0.2687031187940182 Acc: 0.934\n",
      "Iteration: 81 Cost: 0.2685093880830907 Acc: 0.934\n",
      "Iteration: 82 Cost: 0.268316430181674 Acc: 0.935\n",
      "Iteration: 83 Cost: 0.26812424032703114 Acc: 0.935\n",
      "Iteration: 84 Cost: 0.26793281379496503 Acc: 0.936\n",
      "Iteration: 85 Cost: 0.26774214589944956 Acc: 0.936\n",
      "Iteration: 86 Cost: 0.267552231992258 Acc: 0.936\n",
      "Iteration: 87 Cost: 0.26736306746260374 Acc: 0.936\n",
      "Iteration: 88 Cost: 0.2671746477367784 Acc: 0.936\n",
      "Iteration: 89 Cost: 0.26698696827779766 Acc: 0.936\n",
      "Iteration: 90 Cost: 0.26680002458504765 Acc: 0.936\n",
      "Iteration: 91 Cost: 0.2666138121939396 Acc: 0.936\n",
      "Iteration: 92 Cost: 0.26642832667556265 Acc: 0.936\n",
      "Iteration: 93 Cost: 0.26624356363634544 Acc: 0.936\n",
      "Iteration: 94 Cost: 0.2660595187177169 Acc: 0.937\n",
      "Iteration: 95 Cost: 0.26587618759577725 Acc: 0.937\n",
      "Iteration: 96 Cost: 0.2656935659809629 Acc: 0.937\n",
      "Iteration: 97 Cost: 0.26551164961772505 Acc: 0.937\n",
      "Iteration: 98 Cost: 0.2653304342842048 Acc: 0.937\n",
      "Iteration: 99 Cost: 0.26514991579191366 Acc: 0.937\n"
     ]
    }
   ],
   "source": [
    "m = LogisticRegression()\n",
    "W,b = m.fit(X,y,100, 0.008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a59792c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.063\n",
      "Mean Squared Error (MSE): 0.063\n",
      "Root Mean Squared Error (RMSE): 0.25099800796022265\n",
      "R-squared: 0.747998991995968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "m.predict(X, W,b) \n",
    "y_true = y\n",
    "y_pred = m.predict(X, W,b) \n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_true, y_pred)\n",
    "print(f'R-squared: {r_squared}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
