{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d24fbd",
   "metadata": {},
   "source": [
    "# Learning Implementation for Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3809c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb16050",
   "metadata": {},
   "source": [
    "### Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e9ba64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_update(X, y, y_, W, b, alpha,m):\n",
    "    \"\"\"Returns W and b after training once through the dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    res = y - y_ # Residuals\n",
    "\n",
    "    dJ_dW = np.dot(X.T, res) / m\n",
    "    dJ_db = np.mean(res)\n",
    "\n",
    "    W += alpha * dJ_dW\n",
    "    b += alpha * dJ_db\n",
    "\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cd4fa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD_LinearRegression(X, y, iterations = 100, alpha = 0.001):\n",
    "    \"\"\"Returns W,b after training lr using full batch gradient descent.\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    iterations: int, default=100\n",
    "        Number of complete iterations through X.\n",
    "        \n",
    "    alpha: float, default=0.000001\n",
    "        Constant Learning Rate.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    W: ndarray\n",
    "        Optimized weights.\n",
    "    b: float\n",
    "        Optimized intercept.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    m, n = X.shape\n",
    "    W = np.zeros(n) # Zero Initialization\n",
    "    b = 0\n",
    "    \n",
    "    for k in range(iterations+1): # +1 for printing facilitation\n",
    "        y_ = np.dot(X, W) + b\n",
    "            \n",
    "        if k % (iterations//10) == 0:\n",
    "            print(f\"Iteration: {k} > \",\n",
    "                  f\"Cost: {mean_squared_error(y, y_)}\",\n",
    "                  f\" Weights:{W}\",\n",
    "                  f\"Bias: {b}\")\n",
    "\n",
    "        W,b = single_update(X,y,y_, W, b,alpha,m)\n",
    "        \n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d04444",
   "metadata": {},
   "source": [
    "### Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76b6fdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 >  Cost: 421.4565116053958  Weights:[0. 0.] Bias: 0\n",
      "Iteration: 50 >  Cost: 3.017846223001017  Weights:[6.5555 1.8221] Bias: 16.12455906149543\n",
      "Iteration: 100 >  Cost: 0.9193569760104219  Weights:[ 6.1029 -0.8772] Bias: 17.78204195923754\n",
      "Iteration: 150 >  Cost: 0.2858890945419459  Weights:[ 5.7239 -2.3081] Bias: 18.732802162255872\n",
      "Iteration: 200 >  Cost: 0.09011624395480997  Weights:[ 5.4544 -3.0753] Bias: 19.276958842639747\n",
      "Iteration: 250 >  Cost: 0.028654289954405242  Weights:[ 5.2773 -3.4909] Bias: 19.58786624574116\n",
      "Iteration: 300 >  Cost: 0.009161335218302391  Weights:[ 5.166 -3.718] Bias: 19.765269686079215\n",
      "Iteration: 350 >  Cost: 0.0029390837938868116  Weights:[ 5.0981 -3.843 ] Bias: 19.866391954313357\n",
      "Iteration: 400 >  Cost: 0.0009448936429752958  Weights:[ 5.0574 -3.9123] Bias: 19.923987016778195\n",
      "Iteration: 450 >  Cost: 0.00030417177344535605  Weights:[ 5.0333 -3.9508] Bias: 19.956770454054663\n",
      "Iteration: 500 >  Cost: 9.799452056248919e-05  Weights:[ 5.0193 -3.9723] Bias: 19.97542197146757\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(1000, 2)\n",
    "y = 5*X[:,0] - 4*X[:,1] + 20\n",
    "with np.printoptions(precision=4):\n",
    "    GD_LinearRegression(X,y,500, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1124aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 >  Cost: 3182.6390476828487  Weights:[0. 0.] Bias: 0\n",
      "Iteration: 100 >  Cost: 0.0090592787330044  Weights:[41.0888 40.0554] Bias: 9.995484684435944\n",
      "Iteration: 200 >  Cost: 0.0090592787330044  Weights:[41.0888 40.0554] Bias: 9.995484684435944\n",
      "Iteration: 300 >  Cost: 0.0090592787330044  Weights:[41.0888 40.0554] Bias: 9.995484684435944\n",
      "Iteration: 400 >  Cost: 0.0090592787330044  Weights:[41.0888 40.0554] Bias: 9.995484684435944\n",
      "Iteration: 500 >  Cost: 0.0090592787330044  Weights:[41.0888 40.0554] Bias: 9.995484684435944\n",
      "Iteration: 600 >  Cost: 0.0090592787330044  Weights:[41.0888 40.0554] Bias: 9.995484684435944\n",
      "Iteration: 700 >  Cost: 0.0090592787330044  Weights:[41.0888 40.0554] Bias: 9.995484684435944\n",
      "Iteration: 800 >  Cost: 0.0090592787330044  Weights:[41.0888 40.0554] Bias: 9.995484684435944\n",
      "Iteration: 900 >  Cost: 0.0090592787330044  Weights:[41.0888 40.0554] Bias: 9.995484684435944\n",
      "Iteration: 1000 >  Cost: 0.0090592787330044  Weights:[41.0888 40.0554] Bias: 9.995484684435944\n"
     ]
    }
   ],
   "source": [
    "X, y = make_regression(n_samples=1000, n_features=2, noise=0.1, random_state=0)\n",
    "with np.printoptions(precision=4):\n",
    "    GD_LinearRegression(X,y+10,1000, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6988f001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
